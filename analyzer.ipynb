{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'find_llinearibrary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-282-19658d149e66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0melina_lincons0\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind_llinearibrary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgurobipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'find_llinearibrary'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../ELINA/python_interface/')\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "from elina_box import *\n",
    "from elina_interval import *\n",
    "from elina_abstract0 import *\n",
    "from elina_manager import *\n",
    "from elina_dimension import *\n",
    "from elina_scalar import *\n",
    "from elina_interval import *\n",
    "from elina_linexpr0 import *\n",
    "from elina_lincons0 import *\n",
    "import ctypes\n",
    "from ctypes.util import find_llinearibrary\n",
    "from gurobipy import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for debugging in jupyter notebook\n",
    "from IPython.core.debugger import set_trace #TODO remove at end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libc = CDLL(find_library('c'))\n",
    "cstdout = c_void_p.in_dll(libc, 'stdout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layers:\n",
    "    def __init__(self):\n",
    "        self.layertypes = []\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.numlayer = 0\n",
    "        self.ffn_counter = 0\n",
    "        self.rank = []\n",
    "        self.use_LP = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bias(text):\n",
    "    if len(text) < 1 or text[0] != '[':\n",
    "        raise Exception(\"expected '['\")\n",
    "    if text[-1] != ']':\n",
    "        raise Exception(\"expected ']'\")\n",
    "    v = np.array([*map(lambda x: np.double(x.strip()), text[1:-1].split(','))])\n",
    "    #return v.reshape((v.size,1))\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_vector(text):\n",
    "    if len(text) < 1 or text[0] != '[':\n",
    "        raise Exception(\"expected '['\")\n",
    "    if text[-1] != ']':\n",
    "        raise Exception(\"expected ']'\")\n",
    "    v = np.array([*map(lambda x: np.double(x.strip()), text[1:-1].split(','))])\n",
    "    return v.reshape((v.size,1))\n",
    "    #return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_split(text):\n",
    "    i = 0\n",
    "    bal = 0\n",
    "    start = 0\n",
    "    result = []\n",
    "    while i < len(text):\n",
    "        if text[i] == '[':\n",
    "            bal += 1\n",
    "        elif text[i] == ']':\n",
    "            bal -= 1\n",
    "        elif text[i] == ',' and bal == 0:\n",
    "            result.append(text[start:i])\n",
    "            start = i+1\n",
    "        i += 1\n",
    "    if start < i:\n",
    "        result.append(text[start:i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_matrix(text):\n",
    "    i = 0\n",
    "    if len(text) < 1 or text[0] != '[':\n",
    "        raise Exception(\"expected '['\")\n",
    "    if text[-1] != ']':\n",
    "        raise Exception(\"expected ']'\")\n",
    "    return np.array([*map(lambda x: parse_vector(x.strip()).flatten(), balanced_split(text[1:-1]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_net(text):\n",
    "    lines = [*filter(lambda x: len(x) != 0, text.split('\\n'))]\n",
    "    i = 0\n",
    "    res = layers()\n",
    "    while i < len(lines):\n",
    "        if lines[i] in ['ReLU', 'Affine']:\n",
    "            W = parse_matrix(lines[i+1])\n",
    "            b = parse_bias(lines[i+2])\n",
    "            res.layertypes.append(lines[i])\n",
    "            res.weights.append(W)\n",
    "            res.biases.append(b)\n",
    "            res.numlayer+= 1\n",
    "            res.rank.append(np.zeros((W.shape[0],1)))\n",
    "            res.use_LP.append(np.full((W.shape[0],1), False))\n",
    "            i += 3\n",
    "        else:\n",
    "            raise Exception('parse error: '+lines[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_spec(text):\n",
    "    text = text.replace(\"[\", \"\")\n",
    "    text = text.replace(\"]\", \"\")\n",
    "    with open('dummy', 'w') as my_file:\n",
    "        my_file.write(text)\n",
    "    data = np.genfromtxt('dummy', delimiter=',',dtype=np.double)\n",
    "    low = np.copy(data[:,0])\n",
    "    high = np.copy(data[:,1])\n",
    "    return low,high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perturbed_image(x, epsilon):\n",
    "    image = x[1:len(x)]\n",
    "    num_pixels = len(image)\n",
    "    LB_N0 = image - epsilon\n",
    "    UB_N0 = image + epsilon\n",
    "     \n",
    "    for i in range(num_pixels):\n",
    "        if(LB_N0[i] < 0):\n",
    "            LB_N0[i] = 0\n",
    "        if(UB_N0[i] > 1):\n",
    "            UB_N0[i] = 1\n",
    "    return LB_N0, UB_N0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_linexpr0(weights, bias, size):\n",
    "    linexpr0 = elina_linexpr0_alloc(ElinaLinexprDiscr.ELINA_LINEXPR_DENSE, size)\n",
    "    cst = pointer(linexpr0.contents.cst)\n",
    "    elina_scalar_set_double(cst.contents.val.scalar, bias)\n",
    "    for i in range(size):\n",
    "        elina_linexpr0_set_coeff_scalar_double(linexpr0,i,weights[i])\n",
    "    return linexpr0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(nn, LB_N0, UB_N0, label):   \n",
    "    num_pixels = len(LB_N0)\n",
    "    nn.ffn_counter = 0\n",
    "    numlayer = nn.numlayer \n",
    "    man = elina_box_manager_alloc()\n",
    "    itv = elina_interval_array_alloc(num_pixels)\n",
    "    for i in range(num_pixels):\n",
    "        elina_interval_set_double(itv[i],LB_N0[i],UB_N0[i])\n",
    "\n",
    "    ## construct input abstraction\n",
    "    element = elina_abstract0_of_box(man, 0, num_pixels, itv)\n",
    "    elina_interval_array_free(itv,num_pixels)\n",
    "    for layerno in range(numlayer):\n",
    "        if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "            weights = nn.weights[nn.ffn_counter]\n",
    "            biases = nn.biases[nn.ffn_counter]\n",
    "            dims = elina_abstract0_dimension(man,element)\n",
    "            num_in_pixels = dims.intdim + dims.realdim\n",
    "            num_out_pixels = len(weights)\n",
    "\n",
    "            dimadd = elina_dimchange_alloc(0,num_out_pixels)    \n",
    "            for i in range(num_out_pixels):\n",
    "                dimadd.contents.dim[i] = num_in_pixels\n",
    "            elina_abstract0_add_dimensions(man, True, element, dimadd, False)\n",
    "            elina_dimchange_free(dimadd)\n",
    "            np.ascontiguousarray(weights, dtype=np.double)\n",
    "            np.ascontiguousarray(biases, dtype=np.double)\n",
    "            var = num_in_pixels\n",
    "            # handle affine layer\n",
    "            for i in range(num_out_pixels):\n",
    "                tdim= ElinaDim(var)\n",
    "                linexpr0 = generate_linexpr0(weights[i],biases[i],num_in_pixels)\n",
    "                element = elina_abstract0_assign_linexpr_array(man, True, element, tdim, linexpr0, 1, None)\n",
    "                var+=1\n",
    "            dimrem = elina_dimchange_alloc(0,num_in_pixels)\n",
    "            for i in range(num_in_pixels):\n",
    "                dimrem.contents.dim[i] = i\n",
    "            elina_abstract0_remove_dimensions(man, True, element, dimrem)\n",
    "            elina_dimchange_free(dimrem)\n",
    "            # handle ReLU layer \n",
    "            if(nn.layertypes[layerno]=='ReLU'):\n",
    "                element = relu_box_layerwise(man,True,element,0, num_out_pixels)\n",
    "            nn.ffn_counter+=1 \n",
    "\n",
    "        else:\n",
    "            print(' net type not supported')\n",
    "   \n",
    "    dims = elina_abstract0_dimension(man,element)\n",
    "    output_size = dims.intdim + dims.realdim\n",
    "    # get bounds for each output neuron\n",
    "    bounds = elina_abstract0_to_box(man,element)\n",
    "\n",
    "           \n",
    "    # if epsilon is zero, try to classify else verify robustness \n",
    "    \n",
    "    verified_flag = True\n",
    "    predicted_label = 0\n",
    "    if(LB_N0[0]==UB_N0[0]):\n",
    "        for i in range(output_size):\n",
    "            inf = bounds[i].contents.inf.contents.val.dbl\n",
    "            flag = True\n",
    "            for j in range(output_size):\n",
    "                if(j!=i):\n",
    "                    sup = bounds[j].contents.sup.contents.val.dbl\n",
    "                    if(inf<=sup):\n",
    "                        flag = False\n",
    "                        break\n",
    "            if(flag):\n",
    "                predicted_label = i\n",
    "                break    \n",
    "    else:\n",
    "        inf = bounds[label].contents.inf.contents.val.dbl\n",
    "        for j in range(output_size):\n",
    "            if(j!=label):\n",
    "                sup = bounds[j].contents.sup.contents.val.dbl\n",
    "                if(inf<=sup):\n",
    "                    predicted_label = label\n",
    "                    verified_flag = Falselse\n",
    "                    break\n",
    "\n",
    "    elina_interval_array_free(bounds,output_size)\n",
    "    elina_abstract0_free(man,element)\n",
    "    elina_manager_free(man)        \n",
    "    return predicted_label, verified_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main(netname, specname, esilon, c_label = None, method = 'box'):\n",
    "#     with open(netname, 'r') as netfile:\n",
    "#         netstring = netfile.read()\n",
    "#     with open(specname, 'r') as specfile:\n",
    "#         specstring = specfile.read()\n",
    "#     nn = parse_net(netstring)\n",
    "#     x0_low, x0_high = parse_spec(specstring)\n",
    "#     LB_N0, UB_N0 = get_perturbed_image(x0_low,0)\n",
    "    \n",
    "#     label, _ = analyze(nn,LB_N0,UB_N0,0) # Get label of unperturbed image, i.e. eps=0\n",
    "#     start = time.time()\n",
    "#     if method == 'box':\n",
    "#         if(label==int(x0_low[0])):\n",
    "#             LB_N0, UB_N0 = get_perturbed_image(x0_low,epsilon)\n",
    "#             _, verified_flag = analyze_box(nn,LB_N0,UB_N0,label)\n",
    "#             if(verified_flag):\n",
    "#                 print(\"verified\")\n",
    "#             else:\n",
    "#                 print(\"can not be verified\")  \n",
    "#         else:\n",
    "#             print(\"image not correctly classified by the network. expected label \",int(x0_low[0]), \" classified label: \", label)\n",
    "#     if method == 'linear':\n",
    "#         if(label==int(x0_low[0])):\n",
    "#             LB_N0, UB_N0 = get_perturbed_image(x0_low,epsilon)\n",
    "#             _, verified_flag = analyze_linear(nn,LB_N0,UB_N0,label)\n",
    "#             if(verified_flag):\n",
    "#                 print(\"verified\")\n",
    "#             else:\n",
    "#                 print(\"can not be verified\")  \n",
    "#         else:\n",
    "#             print(\"image not correctly classified by the network. expected label \",int(x0_low[0]), \" classified label: \", label)\n",
    "#     end = time.time()\n",
    "#     print(\"analysis time: \", (end-start), \" seconds\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_rank(nn, rank_threshold, norm=1, skip_first_layer=True, skip_last_layer=True):\n",
    "#     numlayer = nn.numlayer \n",
    "#     norms = np.zeros((nn.weights[1].shape[0], numlayer-2)) # TODO use list or similar if first and last layer are also used\n",
    "#     for layerno in range(numlayer):\n",
    "#         if skip_first_layer and layerno == 0:\n",
    "#             #TODO treat first layer\n",
    "#             continue\n",
    "#         if skip_last_layer and layerno == numlayer-1:\n",
    "#             continue\n",
    "#         if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "#             weights = nn.weights[layerno]\n",
    "#             biases = nn.biases[layerno]\n",
    "#             norms[:, layerno-1] = np.linalg.norm(weights, ord=norm, axis=1) + biases\n",
    "#         else:\n",
    "#             print(' net type not supported')\n",
    "    \n",
    "#     rank_idxs = np.argsort(-norms, axis=None)\n",
    "#     rank_idxs = rank_idxs.reshape(nn.weights[1].shape[0], int(len(rank_idxs)/ nn.weights[1].shape[0]))\n",
    "    \n",
    "#     for layerno in range(numlayer):\n",
    "#         if skip_first_layer and layerno == 0:\n",
    "#             continue\n",
    "#         if skip_last_layer and layerno == numlayer-1:\n",
    "#             continue\n",
    "#         if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "#             nn.rank[layerno] = rank_idxs[:, layerno-1]\n",
    "#             nn.use_LP[layerno] = nn.rank[layerno]  < rank_threshold\n",
    "#         else:\n",
    "#             print(' net type not supported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define operations on abstract domain using Box approximations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relu_hidden_bounds_using_box(man, weights, biases, input_LB, input_UB, num_in_pixels):\n",
    "    '''\n",
    "    This function calculates the bounds of a ReLU operation followed by a hidden layer. \n",
    "    INPUT:\n",
    "        - man: pointer to elina manager\n",
    "        - weights: weights of the hidden layer\n",
    "        - biases: biases of the hidden layer\n",
    "        - input_LB: lower bound of the inputs to the ReLU\n",
    "        - input_UB: upper bound of the inputs to the ReLU\n",
    "        - num_in_pixels: number of inputs to ReLU\n",
    "    \n",
    "    OUTPUT:\n",
    "        - output_LB: lower bound of the outputs from hidden layer\n",
    "        - output_UB: upper bound of the outputs from hidden layer\n",
    "        - num_out_pixels: number of outputs of hidden layer\n",
    "    '''\n",
    "    itv = elina_interval_array_alloc(num_in_pixels)\n",
    "\n",
    "    ## Populate the interval\n",
    "    for i in range(num_in_pixels):\n",
    "        elina_interval_set_double(itv[i], input_LB[i], input_UB[i])\n",
    "\n",
    "    ## construct input abstraction\n",
    "    element = elina_abstract0_of_box(man, 0, num_in_pixels, itv)\n",
    "    elina_interval_array_free(itv, num_in_pixels)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Handle ReLU Layer\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    element = relu_box_layerwise(man, True, element,0, num_in_pixels)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Handle Affine Layer\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    # calculate number of outputs\n",
    "    num_out_pixels = len(weights)\n",
    "    \n",
    "    print(\"[Network] Input pixels: \" + str(num_in_pixels))\n",
    "    print(\"[Network] Shape of weights: \" + str(np.shape(weights)))\n",
    "    print(\"[Network] Shape of biases: \" + str(np.shape(biases)))\n",
    "    print(\"[Network] Out pixels: \" + str(num_out_pixels))\n",
    "\n",
    "    # Create number of neurons in the layer and populate it\n",
    "    # with the number of inputs to each neuron in the layer\n",
    "    dimadd = elina_dimchange_alloc(0, num_out_pixels)    \n",
    "    for i in range(num_out_pixels):\n",
    "        dimadd.contents.dim[i] = num_in_pixels\n",
    "\n",
    "    # Add dimensions to an ElinaAbstract0 pointer i.e. element\n",
    "    elina_abstract0_add_dimensions(man, True, element, dimadd, False)\n",
    "    elina_dimchange_free(dimadd)\n",
    "\n",
    "    # Create the linear expression associated each neuron\n",
    "    var = num_in_pixels\n",
    "    for i in range(num_out_pixels):\n",
    "        tdim = ElinaDim(var)\n",
    "        linexpr0 = generate_linexpr0(weights[i], biases[i], num_in_pixels)\n",
    "        # Parallel assignment of several dimensions of an ElinaAbstract0 by using an ElinaLinexpr0Array\n",
    "        element = elina_abstract0_assign_linexpr_array(man, True, element, tdim, linexpr0, 1, None)\n",
    "        var += 1\n",
    "\n",
    "    # Pointer to which semantics we want to follow.\n",
    "    dimrem = elina_dimchange_alloc(0, num_in_pixels)\n",
    "    for i in range(num_in_pixels):\n",
    "        dimrem.contents.dim[i] = i\n",
    "        \n",
    "    # Remove dimensions from an ElinaAbstract0\n",
    "    elina_abstract0_remove_dimensions(man, True, element, dimrem)\n",
    "    elina_dimchange_free(dimrem)\n",
    "    \n",
    "    # get bounds for each output neuron\n",
    "    bounds = elina_abstract0_to_box(man,element)\n",
    "    \n",
    "    output_LB = np.zeros((num_out_pixels, 1), float)\n",
    "    output_UB = np.zeros((num_out_pixels, 1), float)\n",
    "    for j in range(num_out_pixels):\n",
    "        output_LB[j] = bounds[j].contents.inf.contents.val.dbl\n",
    "        output_UB[j] = bounds[j].contents.sup.contents.val.dbl\n",
    "    \n",
    "    # free out the memory allocations\n",
    "    elina_interval_array_free(bounds, num_out_pixels)\n",
    "    elina_abstract0_free(man, element)\n",
    "    \n",
    "    return output_LB, output_UB, num_out_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relu_bounds_using_box(man, input_LB, input_UB, num_in_pixels):\n",
    "    '''\n",
    "    This function calculates the bounds of a ReLU operation. \n",
    "    INPUT:\n",
    "        - man: pointer to elina manager\n",
    "        - input_LB: lower bound of the inputs to the ReLU\n",
    "        - input_UB: upper bound of the inputs to the ReLU\n",
    "        - num_in_pixels: number of inputs to ReLU\n",
    "    \n",
    "    OUTPUT:\n",
    "        - output_LB: lower bound of the outputs from ReLU layer\n",
    "        - output_UB: upper bound of the outputs from ReLU layer\n",
    "        - num_out_pixels: number of outputs of ReLI layer\n",
    "    '''\n",
    "    itv = elina_interval_array_alloc(num_in_pixels)\n",
    "\n",
    "    ## Populate the interval\n",
    "    for i in range(num_in_pixels):\n",
    "        elina_interval_set_double(itv[i], input_LB[i], input_UB[i])\n",
    "\n",
    "    ## construct input abstraction\n",
    "    element = elina_abstract0_of_box(man, 0, num_in_pixels, itv)\n",
    "    elina_interval_array_free(itv, num_in_pixels)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Handle ReLU Layer\n",
    "    # ------------------------------------------------------------------\n",
    "    num_out_pixels = num_in_pixels\n",
    "    \n",
    "    element = relu_box_layerwise(man, True, element,0, num_in_pixels)\n",
    "    \n",
    "    # get bounds for each output neuron\n",
    "    bounds = elina_abstract0_to_box(man,element)\n",
    "    \n",
    "    # get bounds for each output neuron\n",
    "    bounds = elina_abstract0_to_box(man,element)\n",
    "    \n",
    "    output_LB = np.zeros((num_out_pixels, 1), float)\n",
    "    output_UB = np.zeros((num_out_pixels, 1), float)\n",
    "    for j in range(num_out_pixels):\n",
    "        output_LB[j] = bounds[j].contents.inf.contents.val.dbl\n",
    "        output_UB[j] = bounds[j].contents.sup.contents.val.dbl\n",
    "    \n",
    "    # free out the memory allocations\n",
    "    elina_interval_array_free(bounds, num_out_pixels)\n",
    "    elina_abstract0_free(man, element)\n",
    "    \n",
    "    return output_LB, output_UB, num_out_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_bounds_using_box(man, weights, biases, input_LB, input_UB, num_in_pixels):\n",
    "    '''\n",
    "    This function calculates the bounds of a ReLU operation followed by a hidden layer. \n",
    "    INPUT:\n",
    "        - man: pointer to elina manager\n",
    "        - weights: weights of the hidden layer\n",
    "        - biases: biases of the hidden layer\n",
    "        - input_LB: lower bound of the inputs to the hidden layer\n",
    "        - input_UB: upper bound of the inputs to the hidden layer\n",
    "        - num_in_pixels: number of inputs to the input layer\n",
    "    \n",
    "    OUTPUT:\n",
    "        - output_LB: lower bound of the outputs from hidden layer\n",
    "        - output_UB: upper bound of the outputs from hidden layer\n",
    "        - num_out_pixels: number of outputs of hidden layer\n",
    "    '''\n",
    "    itv = elina_interval_array_alloc(num_in_pixels)\n",
    "\n",
    "    ## Populate the interval\n",
    "    for i in range(num_in_pixels):\n",
    "        elina_interval_set_double(itv[i], input_LB[i], input_UB[i])\n",
    "\n",
    "    ## construct input abstraction\n",
    "    element = elina_abstract0_of_box(man, 0, num_in_pixels, itv)\n",
    "    elina_interval_array_free(itv, num_in_pixels)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Handle Affine Layer\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    # calculate number of outputs\n",
    "    num_out_pixels = len(weights)\n",
    "    \n",
    "    print(\"[Network] Input pixels: \" + str(num_in_pixels))\n",
    "    print(\"[Network] Shape of weights: \" + str(np.shape(weights)))\n",
    "    print(\"[Network] Shape of biases: \" + str(np.shape(biases)))\n",
    "    print(\"[Network] Out pixels: \" + str(num_out_pixels))\n",
    "\n",
    "    # Create number of neurons in the layer and populate it\n",
    "    # with the number of inputs to each neuron in the layer\n",
    "    dimadd = elina_dimchange_alloc(0, num_out_pixels)    \n",
    "    for i in range(num_out_pixels):\n",
    "        dimadd.contents.dim[i] = num_in_pixels\n",
    "\n",
    "    # Add dimensions to an ElinaAbstract0 pointer i.e. element\n",
    "    elina_abstract0_add_dimensions(man, True, element, dimadd, False)\n",
    "    elina_dimchange_free(dimadd)\n",
    "\n",
    "    # Create the linear expression associated each neuron\n",
    "    var = num_in_pixels\n",
    "    for i in range(num_out_pixels):\n",
    "        tdim = ElinaDim(var)\n",
    "        linexpr0 = generate_linexpr0(weights[i], biases[i], num_in_pixels)\n",
    "        # Parallel assignment of several dimensions of an ElinaAbstract0 by using an ElinaLinexpr0Array\n",
    "        element = elina_abstract0_assign_linexpr_array(man, True, element, tdim, linexpr0, 1, None)\n",
    "        var += 1\n",
    "\n",
    "    # Pointer to which semantics we want to follow.\n",
    "    dimrem = elina_dimchange_alloc(0, num_in_pixels)\n",
    "    for i in range(num_in_pixels):\n",
    "        dimrem.contents.dim[i] = i\n",
    "        \n",
    "    # Remove dimensions from an ElinaAbstract0\n",
    "    elina_abstract0_remove_dimensions(man, True, element, dimrem)\n",
    "    elina_dimchange_free(dimrem)\n",
    "    \n",
    "    # get bounds for each output neuron\n",
    "    bounds = elina_abstract0_to_box(man,element)\n",
    "    \n",
    "    output_LB = np.zeros((num_out_pixels, 1), float)\n",
    "    output_UB = np.zeros((num_out_pixels, 1), float)\n",
    "    for j in range(num_out_pixels):\n",
    "        output_LB[j] = bounds[j].contents.inf.contents.val.dbl\n",
    "        output_UB[j] = bounds[j].contents.sup.contents.val.dbl\n",
    "    \n",
    "    \n",
    "    # free out the memory allocations\n",
    "    elina_interval_array_free(bounds, num_out_pixels)\n",
    "    elina_abstract0_free(man, element)\n",
    "    \n",
    "    return output_LB, output_UB, num_out_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Bounds using Linear Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounds_using_linear(weights, biases, prev_lb, prev_ub):\n",
    "    \"\"\"\n",
    "    RETURN: \n",
    "            - out_lb: Array of output lower bounds\n",
    "            - out_ub: Array of output upper bounds\n",
    "            - n_out: dimension of output\n",
    "    \"\"\"\n",
    "    m = Model(\"LP\")\n",
    "    # Preprocessing\n",
    "    prev_lb, prev_ub = prev_lb.squeeze(), prev_ub.squeeze()\n",
    "    # Get input and output dimensions\n",
    "    n_in, n_out = prev_lb.shape[0], weights.shape[1]\n",
    "    # Create outputs\n",
    "    out_lb, out_ub = np.zeros(n_out), np.zeros(n_out)\n",
    "\n",
    "    # Check if Relu Operation is trivial and get bounds for that\n",
    "    nontriv_relu, trivial_lb, trivial_ub, lambdas_, mus_ = relu_operation(prev_lb, prev_ub, n_in)\n",
    "    \n",
    "    # Create input Variable and constrains\n",
    "    x = m.addVars(n_in, lb=prev_lb, ub=prev_ub, vtype=GRB.CONTINUOUS)\n",
    "    \n",
    "    # Create Relu Output variable\n",
    "    relu_out = m.addVars(n_in, vtype=GRB.CONTINUOUS)\n",
    "    # Create Relu Output constrain\n",
    "    # Nontrivial cases\n",
    "    m.addConstrs(relu_out[j] >= 0 for j in range(len(relu_out)) if nontriv_relu[j])\n",
    "    m.addConstrs(relu_out[j] >= x[j] for j in range(len(relu_out)) if nontriv_relu[j])\n",
    "    m.addConstrs(relu_out[j] <= lambdas_[j] * x[j] + mus_[j] for j in range(len(relu_out))  if nontriv_relu[j])\n",
    "    # Trivial cases\n",
    "    m.addConstrs(relu_out[j] >= trivial_lb[j] for j in range(len(relu_out)) if not nontriv_relu[j])\n",
    "    m.addConstrs(relu_out[j] <= trivial_ub[j] for j in range(len(relu_out)) if not nontriv_relu[j])\n",
    "    \n",
    "    for i_out in range(n_out):\n",
    "        obj = LinExpr()\n",
    "        obj += biases[i_out]\n",
    "        for j_out in range(weights.shape[1]):\n",
    "            obj +=  relu_out[i_out]*weights[i_out,j_out]\n",
    "        \n",
    "        # Find Lower Bound\n",
    "        m.setObjective(obj, GRB.MINIMIZE)\n",
    "        m.optimize()\n",
    "        out_lb[i_out] = m.objVal\n",
    "        m.reset()\n",
    "        # Find Upper Bound\n",
    "        m.setObjective(obj, GRB.MAXIMIZE)\n",
    "        m.optimize()\n",
    "        out_ub[i_out] = m.objVal\n",
    "        m.reset() \n",
    "            \n",
    "    return out_lb, out_ub, len(out_ub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define operations on abstract domain using linear approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_operation(input_LB, input_UB, num_in_pixels):\n",
    "    \"\"\"\n",
    "    This function computes ReLU.\n",
    "    INPUT\n",
    "        - input_LB: lower bound of the inputs to the ReLU\n",
    "        - input_UB: upper bound of the inputs to the ReLU\n",
    "        - num_in_pixels: number of inputs to ReLU    \n",
    "    OUTPUT:\n",
    "        - nontriv_relu: boolean array for locations where ReLU operation is non-trivial\n",
    "        - output_LB: lower bound of outputs \n",
    "        - output_UB: upper bound of outputs\n",
    "        - lamda_linear: slope of linear approximator line when ReLU non-trivial\n",
    "        - mu_linear: y-intercept of linear approximator line when ReLU non-trivial\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    output_LB = np.zeros((num_in_pixels), float)\n",
    "    output_UB = np.zeros((num_in_pixels), float)\n",
    "    lamda_linear = np.zeros((num_in_pixels), float)\n",
    "    mu_linear = np.zeros((num_in_pixels), float)\n",
    "    nontriv_relu = np.zeros((num_in_pixels), bool)\n",
    "\n",
    "    for j in range(num_in_pixels):\n",
    "        u = input_UB[j]\n",
    "        l = input_LB[j]\n",
    "        if u <= 0:\n",
    "            output_LB[j] = 0.0\n",
    "            output_UB[j] = 0.0\n",
    "        elif l >= 0:\n",
    "            output_LB[j] = l\n",
    "            output_UB[j] = u\n",
    "        else:\n",
    "            nontriv_relu[j] = True\n",
    "            lamda_linear[j] = u / (u - l)\n",
    "            mu_linear[j] = - lamda_linear[j] * l\n",
    "\n",
    "    return nontriv_relu, output_LB, output_UB, lamda_linear, mu_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-386-cc9c5bb13feb>, line 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-386-cc9c5bb13feb>\"\u001b[0;36m, line \u001b[0;32m30\u001b[0m\n\u001b[0;31m    relu_in = m.addVars(n_in, lb=prev_lb, ub=prev_ub, vtype=GRB.CONTINUOUS)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def get_relu_hidden_bounds_using_linear(weights, biases, input_LB, input_UB, num_in_pixels):\n",
    "    '''\n",
    "    This function calculates the bounds of a ReLU operation followed by a hidden layer. \n",
    "    INPUT:\n",
    "        - man: pointer to elina manager\n",
    "        - weights: weights of the hidden layer\n",
    "        - biases: biases of the hidden layer\n",
    "        - input_LB: lower bound of the inputs to the ReLU\n",
    "        - input_UB: upper bound of the inputs to the ReLU\n",
    "        - num_in_pixels: number of inputs to ReLU\n",
    "    \n",
    "    OUTPUT:\n",
    "        - output_LB: lower bound of the outputs from hidden layer\n",
    "        - output_UB: upper bound of the outputs from hidden layer\n",
    "        - num_out_pixels: number of outputs of hidden layer\n",
    "    '''\n",
    "    \n",
    "    # Perform the ReLU operation\n",
    "    relu_nontriv, relu_LB, relu_UB, lamda_linear, mu_linear = relu_operation(input_LB, input_UB, num_in_pixels)\n",
    "    \n",
    "    # Create linear programming model \n",
    "    m = model(\"LP\")\n",
    "    \n",
    "    # Add \n",
    "    for j in range(num_in_pixels):\n",
    "        if relu_nontriv[j] == False:\n",
    "            \n",
    "    \n",
    "    # Create input Variable and constrains\n",
    "    relu_in = m.addVars(n_in, lb=prev_lb, ub=prev_ub, vtype=GRB.CONTINUOUS)\n",
    "    \n",
    "    # Create Relu Output variable\n",
    "    relu_out = m.addVars(n_in, vtype=GRB.CONTINUOUS)\n",
    "    # Create Relu Output constrain\n",
    "    m.addConstrs(relu_out\n",
    "\n",
    "    \n",
    "    m.addConstrs(\n",
    "    \n",
    "    for bound in previous_bounds:\n",
    "        m = addReluConstr(m, bound[0], bound[0])\n",
    "    \n",
    "    # Iterate over output neurons\n",
    "    for weight, bias in zip(weights, biases):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the problem variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "netname = '/home/riai2018/mnist_nets/mnist_relu_3_10.txt'\n",
    "specname = '/home/riai2018/mnist_images/img1.txt'\n",
    "epsilon = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(netname, 'r') as netfile:\n",
    "    netstring = netfile.read()\n",
    "with open(specname, 'r') as specfile:\n",
    "    specstring = specfile.read()\n",
    "nn = parse_net(netstring)\n",
    "x0_low, x0_high = parse_spec(specstring)\n",
    "LB_N0, UB_N0 = get_perturbed_image(x0_low,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU\n",
      "ReLU\n"
     ]
    }
   ],
   "source": [
    "numlayer = nn.numlayer \n",
    "\n",
    "for layerno in range(numlayer):\n",
    "    if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "        print(nn.layertypes[layerno])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get perturbed label (provided prediction for unperturbed is true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, _ = analyze(nn,LB_N0,UB_N0,0) # Get label of unperturbed image, i.e. eps=0\n",
    "\n",
    "if(label == int(x0_low[0])):\n",
    "    LB_N0, UB_N0 = get_perturbed_image(x0_low,epsilon)\n",
    "else:\n",
    "    print(\"image not correctly classified by the network. expected label \",int(x0_low[0]), \" classified label: \", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Define element for the input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pixels = len(LB_N0)\n",
    "numlayer = nn.numlayer \n",
    "man = elina_box_manager_alloc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Iterate over each layer in the network and define the neural network function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Number: 0\n",
      "HIDDEN!\n",
      "[Network] Input pixels: 784\n",
      "[Network] Shape of weights: (10, 784)\n",
      "[Network] Shape of biases: (10,)\n",
      "[Network] Out pixels: 10\n",
      "---------------\n",
      "Layer Number: 1\n",
      "RELU + HIDDEN!\n"
     ]
    },
    {
     "ename": "GurobiError",
     "evalue": "Unsupported type (<class 'numpy.ndarray'>) for LinExpr addition argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGurobiError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-383-c5da2a4ad8bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0moutput_LB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_UB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_out_pixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_relu_hidden_bounds_using_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mman\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_LB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_UB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_in_pixels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0moutput_LB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_UB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_out_pixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_bounds_using_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_LB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_UB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Iterate to next layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-375-23ba81e55769>\u001b[0m in \u001b[0;36mget_bounds_using_linear\u001b[0;34m(weights, biases, prev_lb, prev_ub)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddConstrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnontriv_relu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddConstrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnontriv_relu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddConstrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlambdas_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmus_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mif\u001b[0m \u001b[0mnontriv_relu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Trivial cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddConstrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mtrivial_lb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnontriv_relu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmodel.pxi\u001b[0m in \u001b[0;36mgurobipy.Model.addConstrs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmodel.pxi\u001b[0m in \u001b[0;36mgurobipy.Model.addConstr\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mlinexpr.pxi\u001b[0m in \u001b[0;36mgurobipy.LinExpr.__sub__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mlinexpr.pxi\u001b[0m in \u001b[0;36mgurobipy.LinExpr.__add__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mlinexpr.pxi\u001b[0m in \u001b[0;36mgurobipy.LinExpr.add\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mGurobiError\u001b[0m: Unsupported type (<class 'numpy.ndarray'>) for LinExpr addition argument"
     ]
    }
   ],
   "source": [
    "nn.ffn_counter = 0\n",
    "input_LB = LB_N0\n",
    "input_UB = UB_N0\n",
    "num_in_pixels = num_pixels\n",
    "\n",
    "for layerno in range(numlayer):\n",
    "    print(\"Layer Number: \" + str(layerno))\n",
    "    if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "        # read the layer weights and biases\n",
    "        weights = nn.weights[nn.ffn_counter]\n",
    "        biases = nn.biases[nn.ffn_counter]\n",
    "        np.ascontiguousarray(weights, dtype=np.double)\n",
    "        np.ascontiguousarray(biases, dtype=np.double)\n",
    "        \n",
    "        # only hidden layer\n",
    "        if (layerno == 0):\n",
    "            print(\"HIDDEN!\")\n",
    "            output_LB, output_UB, num_out_pixels = get_hidden_bounds_using_box(man, weights, biases, input_LB, input_UB, num_in_pixels)\n",
    "        # ReLU + hidden layer\n",
    "        else:\n",
    "            print(\"RELU + HIDDEN!\")\n",
    "            use_LP = True\n",
    "            if not use_LP:\n",
    "                output_LB, output_UB, num_out_pixels = get_relu_hidden_bounds_using_box(man, weights, biases, input_LB, input_UB, num_in_pixels)\n",
    "            else:\n",
    "                output_LB, output_UB, num_out_pixels = get_bounds_using_linear(weights, biases, input_LB, input_UB)\n",
    "\n",
    "        # Iterate to next layer\n",
    "        input_LB = output_LB\n",
    "        input_UB = output_UB\n",
    "        num_in_pixels = num_out_pixels        \n",
    "        nn.ffn_counter+=1 \n",
    "        \n",
    "        print('---------------')\n",
    "\n",
    "        # only ReLU layer\n",
    "        if(layerno + 1 == numlayer):\n",
    "            print(\"RELU!\")\n",
    "            output_LB, output_UB, num_out_pixels = get_relu_bounds_using_box(man, input_LB, input_UB, num_in_pixels)\n",
    "            print('---------------')\n",
    "            \n",
    "    else:\n",
    "        print(' net type not supported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/riai2018/analyzer/linexpr.pxi\u001b[0m(173)\u001b[0;36mgurobipy.LinExpr.add\u001b[0;34m()\u001b[0m\n",
      "\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/riai2018/analyzer/linexpr.pxi\u001b[0m(440)\u001b[0;36mgurobipy.LinExpr.__add__\u001b[0;34m()\u001b[0m\n",
      "\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/riai2018/analyzer/linexpr.pxi\u001b[0m(461)\u001b[0;36mgurobipy.LinExpr.__sub__\u001b[0;34m()\u001b[0m\n",
      "\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/riai2018/analyzer/model.pxi\u001b[0m(2968)\u001b[0;36mgurobipy.Model.addConstr\u001b[0;34m()\u001b[0m\n",
      "\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/riai2018/analyzer/model.pxi\u001b[0m(3072)\u001b[0;36mgurobipy.Model.addConstrs\u001b[0;34m()\u001b[0m\n",
      "\n",
      "ipdb> u\n",
      "> \u001b[0;32m<ipython-input-375-23ba81e55769>\u001b[0m(28)\u001b[0;36mget_bounds_using_linear\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     26 \u001b[0;31m    \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddConstrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnontriv_relu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m    \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddConstrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnontriv_relu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 28 \u001b[0;31m    \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddConstrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlambdas_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmus_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mif\u001b[0m \u001b[0mnontriv_relu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     29 \u001b[0;31m    \u001b[0;31m# Trivial cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     30 \u001b[0;31m    \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddConstrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mtrivial_lb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnontriv_relu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> lambdas_[j]\n",
      "array([0.])\n",
      "ipdb> lambdas_\n",
      "array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [0.7410044],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ]])\n",
      "ipdb> lambdas_.shape\n",
      "(10, 1)\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the verifiability of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if epsilon is zero, try to classify else verify robustness \n",
    "verified_flag = True\n",
    "predicted_label = 0\n",
    "if(LB_N0[0]==UB_N0[0]):\n",
    "    for i in range(num_out_pixels):\n",
    "        inf = output_LB[i]\n",
    "        flag = True\n",
    "        for j in range(num_out_pixels):\n",
    "            if(j!=i):\n",
    "                sup = output_UB[j]\n",
    "                if(inf<=sup):\n",
    "                    flag = False\n",
    "                    break\n",
    "        if(flag):\n",
    "            predicted_label = i\n",
    "            break    \n",
    "else:\n",
    "    inf = output_LB[label]\n",
    "    for j in range(num_out_pixels):\n",
    "        if(j!=label):\n",
    "            sup = output_UB[j]\n",
    "            if(inf<=sup):\n",
    "                predicted_label = label\n",
    "                verified_flag = False\n",
    "                break\n",
    "\n",
    "elina_manager_free(man)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verified\n"
     ]
    }
   ],
   "source": [
    "if(verified_flag):\n",
    "    print(\"verified\")\n",
    "else:\n",
    "    print(\"can not be verified\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
