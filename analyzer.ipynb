{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../ELINA/python_interface/')\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "from elina_box import *\n",
    "from elina_interval import *\n",
    "from elina_abstract0 import *\n",
    "from elina_manager import *\n",
    "from elina_dimension import *\n",
    "from elina_scalar import *\n",
    "from elina_interval import *\n",
    "from elina_linexpr0 import *\n",
    "from elina_lincons0 import *\n",
    "import ctypes\n",
    "from ctypes.util import find_library\n",
    "from gurobipy import *\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "libc = CDLL(find_library('c'))\n",
    "cstdout = c_void_p.in_dll(libc, 'stdout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for debugging in jupyter notebook\n",
    "from IPython.core.debugger import set_trace #TODO remove at end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layers:\n",
    "    def __init__(self):\n",
    "        self.layertypes = []\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.numlayer = 0\n",
    "        self.ffn_counter = 0\n",
    "        self.rank = []\n",
    "        self.use_LP = []\n",
    "        self.LB_hat = []\n",
    "        self.UB_hat = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bias(text):\n",
    "    if len(text) < 1 or text[0] != '[':\n",
    "        raise Exception(\"expected '['\")\n",
    "    if text[-1] != ']':\n",
    "        raise Exception(\"expected ']'\")\n",
    "    v = np.array([*map(lambda x: np.double(x.strip()), text[1:-1].split(','))])\n",
    "    #return v.reshape((v.size,1))\n",
    "    return v\n",
    "\n",
    "def parse_vector(text):\n",
    "    if len(text) < 1 or text[0] != '[':\n",
    "        raise Exception(\"expected '['\")\n",
    "    if text[-1] != ']':\n",
    "        raise Exception(\"expected ']'\")\n",
    "    v = np.array([*map(lambda x: np.double(x.strip()), text[1:-1].split(','))])\n",
    "    return v.reshape((v.size,1))\n",
    "    #return v\n",
    "    \n",
    "def balanced_split(text):\n",
    "    i = 0\n",
    "    bal = 0\n",
    "    start = 0\n",
    "    result = []\n",
    "    while i < len(text):\n",
    "        if text[i] == '[':\n",
    "            bal += 1\n",
    "        elif text[i] == ']':\n",
    "            bal -= 1\n",
    "        elif text[i] == ',' and bal == 0:\n",
    "            result.append(text[start:i])\n",
    "            start = i+1\n",
    "        i += 1\n",
    "    if start < i:\n",
    "        result.append(text[start:i])\n",
    "    return result\n",
    "\n",
    "def parse_matrix(text):\n",
    "    i = 0\n",
    "    if len(text) < 1 or text[0] != '[':\n",
    "        raise Exception(\"expected '['\")\n",
    "    if text[-1] != ']':\n",
    "        raise Exception(\"expected ']'\")\n",
    "    return np.array([*map(lambda x: parse_vector(x.strip()).flatten(), balanced_split(text[1:-1]))])\n",
    "\n",
    "def parse_net(text):\n",
    "    lines = [*filter(lambda x: len(x) != 0, text.split('\\n'))]\n",
    "    i = 0\n",
    "    res = layers()\n",
    "    while i < len(lines):\n",
    "        if lines[i] in ['ReLU', 'Affine']:\n",
    "            W = parse_matrix(lines[i+1])\n",
    "            b = parse_bias(lines[i+2])\n",
    "            res.layertypes.append(lines[i])\n",
    "            res.weights.append(W)\n",
    "            res.biases.append(b)\n",
    "            res.numlayer+= 1\n",
    "            res.rank.append(np.zeros((W.shape[0],1)))\n",
    "            res.use_LP.append(np.full((W.shape[0],1), False))\n",
    "            res.LB_hat.append(np.full((W.shape[0],1), np.nan))\n",
    "            res.UB_hat.append(np.full((W.shape[0],1), np.nan))\n",
    "            i += 3\n",
    "        else:\n",
    "            raise Exception('parse error: '+lines[i])\n",
    "    return res\n",
    "\n",
    "def parse_spec(text):\n",
    "    text = text.replace(\"[\", \"\")\n",
    "    text = text.replace(\"]\", \"\")\n",
    "    with open('dummy', 'w') as my_file:\n",
    "        my_file.write(text)\n",
    "    data = np.genfromtxt('dummy', delimiter=',',dtype=np.double)\n",
    "    low = copy.deepcopy(data[:,0])\n",
    "    high = copy.deepcopy(data[:,1])\n",
    "    return low,high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perturbed_image(x, epsilon):\n",
    "    image = x[1:len(x)]\n",
    "    num_pixels = len(image)\n",
    "    LB_N0 = image - epsilon\n",
    "    UB_N0 = image + epsilon\n",
    "     \n",
    "    for i in range(num_pixels):\n",
    "        if(LB_N0[i] < 0):\n",
    "            LB_N0[i] = 0\n",
    "        if(UB_N0[i] > 1):\n",
    "            UB_N0[i] = 1\n",
    "    return LB_N0, UB_N0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_linexpr0(weights, bias, size):\n",
    "    linexpr0 = elina_linexpr0_alloc(ElinaLinexprDiscr.ELINA_LINEXPR_DENSE, size)\n",
    "    cst = pointer(linexpr0.contents.cst)\n",
    "    elina_scalar_set_double(cst.contents.val.scalar, bias)\n",
    "    for i in range(size):\n",
    "        elina_linexpr0_set_coeff_scalar_double(linexpr0,i,weights[i])\n",
    "    return linexpr0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(nn, LB_N0, UB_N0, label):   \n",
    "    num_pixels = len(LB_N0)\n",
    "    nn.ffn_counter = 0\n",
    "    numlayer = nn.numlayer \n",
    "    man = elina_box_manager_alloc()\n",
    "    itv = elina_interval_array_alloc(num_pixels)\n",
    "    for i in range(num_pixels):\n",
    "        elina_interval_set_double(itv[i],LB_N0[i],UB_N0[i])\n",
    "\n",
    "    ## construct input abstraction\n",
    "    element = elina_abstract0_of_box(man, 0, num_pixels, itv)\n",
    "    elina_interval_array_free(itv,num_pixels)\n",
    "    for layerno in range(numlayer):\n",
    "        if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "           weights = nn.weights[nn.ffn_counter]\n",
    "           biases = nn.biases[nn.ffn_counter]\n",
    "           dims = elina_abstract0_dimension(man,element)\n",
    "           num_in_pixels = dims.intdim + dims.realdim\n",
    "           num_out_pixels = len(weights)\n",
    "\n",
    "           dimadd = elina_dimchange_alloc(0,num_out_pixels)    \n",
    "           for i in range(num_out_pixels):\n",
    "               dimadd.contents.dim[i] = num_in_pixels\n",
    "           elina_abstract0_add_dimensions(man, True, element, dimadd, False)\n",
    "           elina_dimchange_free(dimadd)\n",
    "           np.ascontiguousarray(weights, dtype=np.double)\n",
    "           np.ascontiguousarray(biases, dtype=np.double)\n",
    "           var = num_in_pixels\n",
    "           # handle affine layer\n",
    "           for i in range(num_out_pixels):\n",
    "               tdim= ElinaDim(var)\n",
    "               linexpr0 = generate_linexpr0(weights[i],biases[i],num_in_pixels)\n",
    "               element = elina_abstract0_assign_linexpr_array(man, True, element, tdim, linexpr0, 1, None)\n",
    "               var+=1\n",
    "           dimrem = elina_dimchange_alloc(0,num_in_pixels)\n",
    "           for i in range(num_in_pixels):\n",
    "               dimrem.contents.dim[i] = i\n",
    "           elina_abstract0_remove_dimensions(man, True, element, dimrem)\n",
    "           elina_dimchange_free(dimrem)\n",
    "           # handle ReLU layer \n",
    "           if(nn.layertypes[layerno]=='ReLU'):\n",
    "              element = relu_box_layerwise(man,True,element,0, num_out_pixels)\n",
    "           nn.ffn_counter+=1 \n",
    "\n",
    "        else:\n",
    "           print(' net type not supported')\n",
    "   \n",
    "    dims = elina_abstract0_dimension(man,element)\n",
    "    output_size = dims.intdim + dims.realdim\n",
    "    # get bounds for each output neuron\n",
    "    bounds = elina_abstract0_to_box(man,element)\n",
    "\n",
    "           \n",
    "    # if epsilon is zero, try to classify else verify robustness \n",
    "    \n",
    "    verified_flag = True\n",
    "    predicted_label = 0\n",
    "    if(LB_N0[0]==UB_N0[0]):\n",
    "        for i in range(output_size):\n",
    "            inf = bounds[i].contents.inf.contents.val.dbl\n",
    "            flag = True\n",
    "            for j in range(output_size):\n",
    "                if(j!=i):\n",
    "                   sup = bounds[j].contents.sup.contents.val.dbl\n",
    "                   if(inf<=sup):\n",
    "                      flag = False\n",
    "                      break\n",
    "            if(flag):\n",
    "                predicted_label = i\n",
    "                break    \n",
    "    else:\n",
    "        inf = bounds[label].contents.inf.contents.val.dbl\n",
    "        for j in range(output_size):\n",
    "            if(j!=label):\n",
    "                sup = bounds[j].contents.sup.contents.val.dbl\n",
    "                if(inf<=sup):\n",
    "                    predicted_label = label\n",
    "                    verified_flag = False\n",
    "                    break\n",
    "\n",
    "    elina_interval_array_free(bounds,output_size)\n",
    "    elina_abstract0_free(man,element)\n",
    "    elina_manager_free(man)        \n",
    "    return predicted_label, verified_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define operations on abstract domain using linear approximations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hidden_constraint(model, layerno, z, z_hat, weights, biases):\n",
    "    \"\"\"\n",
    "    This function computes “which side” of the ReLU the pre-ReLU activations lies on.\n",
    "    INPUT:\n",
    "        - model: gurobi model\n",
    "        - layerno: layer number from which z_hat belong\n",
    "        - z: gurobi variables for hidden layer input\n",
    "        - z_hat: gurobi variables for hidden layer output\n",
    "        - weights: weights for the hidden layer\n",
    "        - bias: bias in the hidden layer\n",
    "    OUTPUT:\n",
    "        - model: gurobi model with new hidden constrains\n",
    "   \"\"\"\n",
    "    # Sanity check!\n",
    "    assert len(z) == weights.shape[1]\n",
    "    assert len(z_hat) == weights.shape[0]\n",
    "    \n",
    "    # add constraint to model\n",
    "    for i_out in range(len(z_hat)):\n",
    "        constr = LinExpr() + np.asscalar(biases[i_out])\n",
    "        for s in range(len(z)):\n",
    "            constr += z[s] * np.asscalar(weights[i_out, s])\n",
    "\n",
    "        model.addConstr(z_hat[i_out] == constr, \\\n",
    "                    name=\"hidden_constr_\" + str(layerno) + \"_\" + str(i_out))\n",
    "    \n",
    "    model.update()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_relu_activation_constraint(model, layerno, z_hat, z, LB, UB):\n",
    "    \"\"\"\n",
    "    This function computes “which side” of the ReLU the pre-ReLU activations lies on.\n",
    "    INPUT:\n",
    "        - model: gurobi model\n",
    "        - layerno: layer number from which z_hat belong\n",
    "        - z_hat: gurobi variables for pre-relu input\n",
    "        - z: gurobi variables for relu output\n",
    "        - LB: lower bound of inputs to a relu layer\n",
    "        - UB: upper bound of inputs to a relu layer\n",
    "    OUTPUT:\n",
    "        - model: gurobi model with new ReLU constrains\n",
    "   \"\"\"\n",
    "    # Sanity check!\n",
    "    assert len(z) == len(UB)\n",
    "    \n",
    "    # iterate over each pre-relu neuron activation\n",
    "    for j in range(len(UB)):\n",
    "        u = np.asscalar(UB[j])\n",
    "        l = np.asscalar(LB[j])\n",
    "\n",
    "        if u <= 0:\n",
    "            model.addConstr(z[j] == 0, \\\n",
    "                        name=\"relu_constr_deac_\" + str(layerno) + \"_\" + str(j))\n",
    "        elif l > 0:\n",
    "            model.addConstr(z[j] == z_hat[j], \\\n",
    "                        name=\"relu_constr_deac_\" + str(layerno) + \"_\" + str(j))\n",
    "        else:\n",
    "            alpha = u/(u - l)\n",
    "            model.addConstr(z[j] >= 0 , \\\n",
    "                         name=\"relu_const_ambi_pos_\" + str(layerno) + \"_\" + str(j))\n",
    "            model.addConstr(z[j] >= z_hat[j], \\\n",
    "                         name=\"relu_const_ambi_hid_\" + str(layerno) + \"_\" + str(j))\n",
    "            model.addConstr(z[j] <= alpha * (z_hat[j] - l), \\\n",
    "                         name=\"relu_const_ambi_lin_\" + str(layerno) + \"_\" + str(j))\n",
    "    model.update()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_linear_solver(model, z_hat, lb_only=False, ub_only=False):\n",
    "    \"\"\"\n",
    "    This function computes lower and upper bound for given objective function and model\n",
    "    INPUT:\n",
    "        - model: gurobi model\n",
    "        - z_hat: gurobi variable to optimize for\n",
    "    OUTPUT:\n",
    "        - LB: lower bound of variable\n",
    "        - UB: upper bound of variable\n",
    "   \"\"\"\n",
    "    # Sanity\n",
    "    assert not lb_only*ub_only\n",
    "    LB, UB = None, None\n",
    "    \n",
    "    if not ub_only:\n",
    "        # Find Lower Bound\n",
    "        model.setObjective(z_hat, GRB.MINIMIZE)\n",
    "        model.update()\n",
    "        model.optimize()\n",
    "\n",
    "        if model.status == GRB.Status.OPTIMAL:\n",
    "            LB = model.objVal\n",
    "        else:\n",
    "            raise(RuntimeError('[Min] Error. Not Able to retrieve bound. Gurobi Model. Not Optimal.'))\n",
    "\n",
    "        # reset model \n",
    "        model.reset()\n",
    "    \n",
    "    if not lb_only:\n",
    "        # Find Upper Bound\n",
    "        model.setObjective(z_hat, GRB.MAXIMIZE)\n",
    "        model.update()\n",
    "        model.optimize()\n",
    "\n",
    "        if model.status == GRB.Status.OPTIMAL:\n",
    "            UB = model.objVal\n",
    "        else:\n",
    "            raise(RuntimeError('[Max] Error. Not Able to retrieve bound. Gurobi Model. Not Optimal.'))\n",
    "\n",
    "        # reset model \n",
    "        model.reset()\n",
    "    \n",
    "    return LB, UB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define operations on abstract domain using Box approximations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relu_bounds_using_box(man, input_LB, input_UB, num_in_pixels):\n",
    "    '''\n",
    "    This function calculates the bounds of a ReLU operation. \n",
    "    INPUT:\n",
    "        - man: pointer to elina manager\n",
    "        - input_LB: lower bound of the inputs to the ReLU\n",
    "        - input_UB: upper bound of the inputs to the ReLU\n",
    "        - num_in_pixels: number of inputs to ReLU\n",
    "    \n",
    "    OUTPUT:\n",
    "        - output_LB: lower bound of the outputs from ReLU layer\n",
    "        - output_UB: upper bound of the outputs from ReLU layer\n",
    "        - num_out_pixels: number of outputs of ReLI layer\n",
    "    '''\n",
    "    itv = elina_interval_array_alloc(num_in_pixels)\n",
    "\n",
    "    ## Populate the interval\n",
    "    for i in range(num_in_pixels):\n",
    "        elina_interval_set_double(itv[i], input_LB[i], input_UB[i])\n",
    "\n",
    "    ## construct input abstraction\n",
    "    element = elina_abstract0_of_box(man, 0, num_in_pixels, itv)\n",
    "    elina_interval_array_free(itv, num_in_pixels)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Handle ReLU Layer\n",
    "    # ------------------------------------------------------------------\n",
    "    num_out_pixels = num_in_pixels\n",
    "    \n",
    "    element = relu_box_layerwise(man, True, element,0, num_in_pixels)\n",
    "    \n",
    "    # get bounds for each output neuron\n",
    "    bounds = elina_abstract0_to_box(man,element)\n",
    "    \n",
    "    # get bounds for each output neuron\n",
    "    bounds = elina_abstract0_to_box(man,element)\n",
    "    \n",
    "    output_LB = np.zeros((num_out_pixels, 1), float)\n",
    "    output_UB = np.zeros((num_out_pixels, 1), float)\n",
    "    for j in range(num_out_pixels):\n",
    "        output_LB[j] = bounds[j].contents.inf.contents.val.dbl\n",
    "        output_UB[j] = bounds[j].contents.sup.contents.val.dbl\n",
    "    \n",
    "    # free out the memory allocations\n",
    "    elina_interval_array_free(bounds, num_out_pixels)\n",
    "    elina_abstract0_free(man, element)\n",
    "    \n",
    "    return output_LB, output_UB, num_out_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_bounds_using_box(man, weights, biases, input_LB, input_UB, num_in_pixels, verbose=False):\n",
    "    '''\n",
    "    This function calculates the bounds of a ReLU operation followed by a hidden layer. \n",
    "    INPUT:\n",
    "        - man: pointer to elina manager\n",
    "        - weights: weights of the hidden layer\n",
    "        - biases: biases of the hidden layer\n",
    "        - input_LB: lower bound of the inputs to the hidden layer\n",
    "        - input_UB: upper bound of the inputs to the hidden layer\n",
    "        - num_in_pixels: number of inputs to the input layer\n",
    "    \n",
    "    OUTPUT:\n",
    "        - output_LB: lower bound of the outputs from hidden layer\n",
    "        - output_UB: upper bound of the outputs from hidden layer\n",
    "        - num_out_pixels: number of outputs of hidden layer\n",
    "    '''\n",
    "    itv = elina_interval_array_alloc(num_in_pixels)\n",
    "\n",
    "    ## Populate the interval\n",
    "    for i in range(num_in_pixels):\n",
    "        elina_interval_set_double(itv[i], input_LB[i], input_UB[i])\n",
    "\n",
    "    ## construct input abstraction\n",
    "    element = elina_abstract0_of_box(man, 0, num_in_pixels, itv)\n",
    "    elina_interval_array_free(itv, num_in_pixels)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Handle Affine Layer\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    # calculate number of outputs\n",
    "    num_out_pixels = len(weights)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"[Network] Input pixels: \" + str(num_in_pixels))\n",
    "        print(\"[Network] Shape of weights: \" + str(np.shape(weights)))\n",
    "        print(\"[Network] Shape of biases: \" + str(np.shape(biases)))\n",
    "        print(\"[Network] Out pixels: \" + str(num_out_pixels))\n",
    "\n",
    "    # Create number of neurons in the layer and populate it\n",
    "    # with the number of inputs to each neuron in the layer\n",
    "    dimadd = elina_dimchange_alloc(0, num_out_pixels)    \n",
    "    for i in range(num_out_pixels):\n",
    "        dimadd.contents.dim[i] = num_in_pixels\n",
    "\n",
    "    # Add dimensions to an ElinaAbstract0 pointer i.e. element\n",
    "    elina_abstract0_add_dimensions(man, True, element, dimadd, False)\n",
    "    elina_dimchange_free(dimadd)\n",
    "\n",
    "    # Create the linear expression associated each neuron\n",
    "    var = num_in_pixels\n",
    "    for i in range(num_out_pixels):\n",
    "        tdim = ElinaDim(var)\n",
    "        linexpr0 = generate_linexpr0(weights[i], biases[i], num_in_pixels)\n",
    "        # Parallel assignment of several dimensions of an ElinaAbstract0 by using an ElinaLinexpr0Array\n",
    "        element = elina_abstract0_assign_linexpr_array(man, True, element, tdim, linexpr0, 1, None)\n",
    "        var += 1\n",
    "\n",
    "    # Pointer to which semantics we want to follow.\n",
    "    dimrem = elina_dimchange_alloc(0, num_in_pixels)\n",
    "    for i in range(num_in_pixels):\n",
    "        dimrem.contents.dim[i] = i\n",
    "        \n",
    "    # Remove dimensions from an ElinaAbstract0\n",
    "    elina_abstract0_remove_dimensions(man, True, element, dimrem)\n",
    "    elina_dimchange_free(dimrem)\n",
    "    \n",
    "    # get bounds for each output neuron\n",
    "    bounds = elina_abstract0_to_box(man,element)\n",
    "    \n",
    "    output_LB = np.zeros((num_out_pixels, 1), float)\n",
    "    output_UB = np.zeros((num_out_pixels, 1), float)\n",
    "    for j in range(num_out_pixels):\n",
    "        output_LB[j] = bounds[j].contents.inf.contents.val.dbl\n",
    "        output_UB[j] = bounds[j].contents.sup.contents.val.dbl    \n",
    "    \n",
    "    # free out the memory allocations\n",
    "    elina_interval_array_free(bounds, num_out_pixels)\n",
    "    elina_abstract0_free(man, element)\n",
    "    \n",
    "    return output_LB, output_UB, num_out_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function to verify the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_network(LB_N0, UB_N0, LB_NN, UB_NN, label, num_input_pixels = 784, num_out_pixels = 10):\n",
    "    '''\n",
    "    This function verifies the network given the bounds of the input layer and the final layer of the network.\n",
    "    INPUT:\n",
    "        - LB_N0: lower bounds of the preturbed input image\n",
    "        - UB_N0: unpper bounds of the preturbed input image\n",
    "        - LB_NN: lower bounds of the final layer of neural network\n",
    "        - UB_NN: upper bounds of the final layer of neural network\n",
    "        - label: true label of the input image\n",
    "        - num_input_pixels: number of pixels in the input image (for MNIST, default: 784)\n",
    "        - num_out_pixels: number of neurons in the last layer of the network  (for MNIST, default: 10)\n",
    "    \n",
    "    OUTPUT:\n",
    "        - predicted_label: label predicted by the neural network\n",
    "        - verified_flag: boolean variable, true if the network is robust to perturbation\n",
    "    '''\n",
    "    \n",
    "    # if epsilon is zero, try to classify else verify robustness \n",
    "    verified_flag = True\n",
    "    predicted_label = 0\n",
    "    if(LB_N0[0]==UB_N0[0]):\n",
    "        for i in range(num_out_pixels):\n",
    "            inf = LB_NN[i]\n",
    "            flag = True\n",
    "            for j in range(num_out_pixels):\n",
    "                if(j!=i):\n",
    "                    sup = UB_NN[j]\n",
    "                    if(inf<=sup):\n",
    "                        flag = False\n",
    "                        break\n",
    "            if(flag):\n",
    "                predicted_label = i\n",
    "                break    \n",
    "    else:\n",
    "        inf = LB_NN[label]\n",
    "        for j in range(num_out_pixels):\n",
    "            if(j!=label):\n",
    "                sup = UB_NN[j]\n",
    "                if(inf<=sup):\n",
    "                    predicted_label = label\n",
    "                    verified_flag = False\n",
    "                    break\n",
    "\n",
    "    if(verified_flag):\n",
    "        print(\"verified\")\n",
    "    else:\n",
    "        print(\"can not be verified\")  \n",
    "        \n",
    "    return predicted_label, verified_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to perform different analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform box analysis for all layers in the neural network nn\n",
    "def perform_box_analysis(nn, LB_N0, UB_N0, verbose = False):\n",
    "    # create a list to store the bounds found through box approximation\n",
    "    LB_hidden_box_list = []\n",
    "    UB_hidden_box_list = []\n",
    "\n",
    "    # create manager for Elina\n",
    "    man = elina_box_manager_alloc()\n",
    "\n",
    "    # initialize variables for the network iteration\n",
    "    numlayer = nn.numlayer \n",
    "    nn.ffn_counter = 0\n",
    "\n",
    "    # for input image\n",
    "    input_LB = LB_N0.copy()\n",
    "    input_UB = UB_N0.copy()\n",
    "    num_in_pixels = len(LB_N0)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Input Layer, size: \" + str(len(LB_N0)))\n",
    "        print('---------------')\n",
    "\n",
    "    for layerno in range(numlayer):\n",
    "        if verbose:\n",
    "            print(\"Layer Number: \" + str(layerno + 1))\n",
    "\n",
    "        if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "            if verbose:\n",
    "                print(\"Layer Type: %s\" % nn.layertypes[layerno])\n",
    "\n",
    "            # read the layer weights and biases\n",
    "            weights = nn.weights[nn.ffn_counter]\n",
    "            biases = nn.biases[nn.ffn_counter]\n",
    "            np.ascontiguousarray(weights, dtype=np.double)\n",
    "            np.ascontiguousarray(biases, dtype=np.double)\n",
    "\n",
    "            # ------------------------------------------------------------------\n",
    "            # Handle Affine Layer\n",
    "            # ------------------------------------------------------------------\n",
    "            output_LB, output_UB, num_out_pixels = get_hidden_bounds_using_box(man, weights, biases, input_LB, input_UB, num_in_pixels, verbose)\n",
    "\n",
    "            # Add bounds to the list\n",
    "            LB_hidden_box_list.append(output_LB.copy())\n",
    "            UB_hidden_box_list.append(output_UB.copy())\n",
    "            # Prepare variables for next layer\n",
    "            input_LB = output_LB.copy()\n",
    "            input_UB = output_UB.copy()\n",
    "            num_in_pixels = num_out_pixels\n",
    "            nn.ffn_counter += 1 \n",
    "\n",
    "            # ------------------------------------------------------------------\n",
    "            # Handle ReLU Layer\n",
    "            # ------------------------------------------------------------------\n",
    "            if(nn.layertypes[layerno] == \"ReLU\"):\n",
    "                output_LB, output_UB, num_out_pixels = get_relu_bounds_using_box(man, input_LB, input_UB, num_in_pixels)\n",
    "\n",
    "            # Prepare variables for next layer\n",
    "            input_LB = output_LB.copy()\n",
    "            input_UB = output_UB.copy()\n",
    "\n",
    "            if verbose:\n",
    "                print(\"[OUTPUT] Bounds: \")\n",
    "                output_LB, output_UB  = output_LB.squeeze(), output_UB.squeeze()\n",
    "                pprint(np.stack((output_LB, output_UB), axis=1))\n",
    "            \n",
    "            if verbose:\n",
    "                print('---------------')\n",
    "\n",
    "        else:\n",
    "            print(' net type not supported')\n",
    "    if verbose:\n",
    "        print(\"Output Layer, size: \" + str(len(output_LB)))\n",
    "\n",
    "    elina_manager_free(man)\n",
    "    \n",
    "    # for last layer of the netowork is ReLU\n",
    "    LB_NN = LB_hidden_box_list[-1].copy()\n",
    "    UB_NN = UB_hidden_box_list[-1].copy()\n",
    "\n",
    "    if nn.layertypes[-1] == \"ReLU\" :\n",
    "        num_out = len(LB_hidden_box_list[-1])\n",
    "        for i in range(num_out):\n",
    "            if LB_hidden_box_list[-1][i] < 0 :\n",
    "                LB_NN[i] = 0 \n",
    "            if UB_hidden_box_list[-1][i] < 0 :\n",
    "                UB_NN[i] = 0 \n",
    "            \n",
    "    return LB_hidden_box_list, UB_hidden_box_list, LB_NN.squeeze(), UB_NN.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_linear_over_box_approximation(nn, LB_N0, UB_N0, LB_hidden_box_list, UB_hidden_box_list, verbose = False):\n",
    "    # initialize variables for the network iteration\n",
    "    numlayer = nn.numlayer \n",
    "    nn.ffn_counter = 0\n",
    "    num_in_pixels = len(LB_N0)\n",
    "    \n",
    "    m = get_model()\n",
    "    \n",
    "    # We follow the following notations:\n",
    "    # z_hat_{i} = W_i * z_i + b_i, where i = {1, . . . , k}, and z_hat_{k} = y (ouput of NN)\n",
    "    # z_i = max(z_hat_{i-1} , 0),  where i = {2, . . . , k}, and z_1 = x (input to NN)\n",
    "\n",
    "    # for input layer:\n",
    "    # Variable lower bound: Note that any value less than -1e20 is treated as negative infinity. \n",
    "    num_in_pixels = len(LB_N0)\n",
    "    img_vars = m.addVars(num_in_pixels, lb=LB_N0, ub=UB_N0, \\\n",
    "                         vtype=GRB.CONTINUOUS, name=\"input_layer\")\n",
    "    \n",
    "    # for output of each ReLU\n",
    "    z = []\n",
    "    z.append(img_vars)\n",
    "    # for output of each hidden layer\n",
    "    z_hat = []\n",
    "\n",
    "    # Create variables for all layers and append to the list \n",
    "    m, z, z_hat = add_all_vars(m, numlayer, LB_N0, UB_N0, UB_hidden_box_list)\n",
    "    m.update()\n",
    "    \n",
    "    if verbose: \n",
    "        # Sanity check!\n",
    "        # Size of z should be number of relu activation layers + 1 (for input)\n",
    "        print(\"Number of relu layers: {0}\".format(len(z)))\n",
    "        # Size of z_hat should be number of hidden layers\n",
    "        print(\"Number of hidden layers: {0}\".format(len(z_hat)))\n",
    "        print(\"Size of last hidden layer: {0}\".format(len(z_hat[-1])))\n",
    "        print(\"------------------------------\")\n",
    "\n",
    "    nn.ffn_counter = 0\n",
    "\n",
    "    # Adding weights constraints for k layers\n",
    "    for layerno in range(numlayer):\n",
    "        if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "            # read the layer weights and biases\n",
    "            weights = nn.weights[nn.ffn_counter]\n",
    "            biases = nn.biases[nn.ffn_counter]\n",
    "            np.ascontiguousarray(weights, dtype=np.float)\n",
    "            np.ascontiguousarray(biases, dtype=np.float)\n",
    "\n",
    "            # add affine constraint\n",
    "            add_hidden_constraint(m, layerno, z[layerno], z_hat[layerno], weights, biases)\n",
    "        \n",
    "            # update counter for next iteration\n",
    "            nn.ffn_counter += 1\n",
    "        else:\n",
    "            raise(\"Not a valid layer!\")\n",
    "        \n",
    "    m.update()\n",
    "\n",
    "    # Adding relu constraints for (k-1) layers. The loop starts from z_2 since z_1 is input\n",
    "    for i in range(1, numlayer):        \n",
    "        # add relu constraint\n",
    "        if (nn.layertypes[layerno] in [\"ReLU\"]):\n",
    "            add_relu_activation_constraint(m, layerno, z_hat[i-1], z[i], LB_hidden_box_list[i-1], UB_hidden_box_list[i-1])\n",
    "\n",
    "    m.update()\n",
    "\n",
    "    # storing upper and lower bounds for last layer\n",
    "    UB = np.zeros_like(nn.biases[-1])\n",
    "    LB = np.zeros_like(nn.biases[-1])\n",
    "    numlayer = nn.numlayer \n",
    "\n",
    "    # Solving for each neuron in the output layer to collect bounds\n",
    "    # i.e. z_hat_{-1} where -1 denotes the last array in list\n",
    "    for i_out in range(len(UB)): \n",
    "        LB[i_out], UB[i_out] = call_linear_solver(m, z_hat[-1][i_out])\n",
    "        \n",
    "    # for last layer of the netowork is ReLU\n",
    "    LB_NN = LB\n",
    "    UB_NN = UB\n",
    "    \n",
    "    if nn.layertypes[-1] == \"ReLU\" :\n",
    "        num_out = len(UB_NN)\n",
    "\n",
    "        for i in range(num_out):\n",
    "            if LB[i] < 0 :\n",
    "                LB_NN[i] = 0 \n",
    "            if UB[i] < 0 :\n",
    "                UB_NN[i] = 0 \n",
    "                \n",
    "    return LB_NN.squeeze(), UB_NN.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(single_thread=False):\n",
    "    \"\"\"\n",
    "    Get Gurobi model\n",
    "    \"\"\"\n",
    "    m = Model(\"LP\")\n",
    "    m.setParam(\"outputflag\", False)\n",
    "\n",
    "    # disable parallel Gurobi solver\n",
    "    m.setParam(\"Method\", 1)  # dual simplex\n",
    "    if single_thread:\n",
    "        m.setParam(\"Threads\", 1) # only 1 thread\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_all_vars(m, numlayer, LB_N0, UB_N0, UB_hidden_box_list, verbose=True):\n",
    "    \"\"\"\n",
    "    Add and create all variables of neural network to gurobi model.\n",
    "    INPUT:\n",
    "        - m: Gurobi model\n",
    "        - numlayer: Number of Layers\n",
    "        - LB_N0: Lower Bound of perturbed image input\n",
    "        - UB_N0: Upper Bound of perturbed image input\n",
    "        - UB_hidden_box_list: List of upper Bounds from box approximation (needed to set upper bound of ReLU outputs)\n",
    "    OUTPUT:\n",
    "        - m: Gurobi model with newly added variables\n",
    "        - z: List of Gurobi variables corresponding to pre-ReLU Layer (hidden)\n",
    "        - z_hat: List of Gurobi variables corresponding to post-ReLU Layer\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # for output of each ReLU\n",
    "    z = []\n",
    "    # for output of each hidden layer\n",
    "    z_hat = []\n",
    "    \n",
    "    # Create variables of input image\n",
    "    num_in_pixels = len(LB_N0)\n",
    "    img_vars = m.addVars(num_in_pixels, lb=LB_N0, ub=UB_N0, \\\n",
    "                 vtype=GRB.CONTINUOUS, name=\"input_layer\")\n",
    "    z.append(img_vars)\n",
    "    \n",
    "    # Create variables for all layers and append to the list \n",
    "    for i in range(numlayer):\n",
    "        # for layers before the final layer, z_hat and z exists\n",
    "        if i < (numlayer - 1):\n",
    "\n",
    "            UB_relu = UB_hidden_box_list[i].squeeze().copy()\n",
    "            for j in range(len(UB_hidden_box_list[i])):\n",
    "                bound = UB_hidden_box_list[i][j]\n",
    "                UB_relu[j] = max(0, bound)\n",
    "            UB_relu.squeeze() \n",
    "\n",
    "            # middle layer, has both z and z hat\n",
    "            z_hat_hidden = m.addVars(len(UB_hidden_box_list[i]), lb=-np.inf, ub=np.inf, \\\n",
    "                                     vtype=GRB.CONTINUOUS, name=\"hidden_layer_\" + str(i))\n",
    "            z_relu = m.addVars(len(UB_hidden_box_list[i]), lb=0.0, ub = UB_relu,\\\n",
    "                               vtype=GRB.CONTINUOUS, name=\"relu_layer_\" + str(i))\n",
    "            # append to the list\n",
    "            z_hat.append(z_hat_hidden)\n",
    "            z.append(z_relu)\n",
    "        # for last layer, only z_hat exists\n",
    "        else: \n",
    "            z_hat_hidden = m.addVars(len(UB_hidden_box_list[i]), lb=-np.inf, ub=np.inf, \\\n",
    "                                     vtype=GRB.CONTINUOUS, name=\"output_layer\") \n",
    "            # append to the list\n",
    "            z_hat.append(z_hat_hidden)\n",
    "\n",
    "    m.update()\n",
    "    \n",
    "    if verbose:\n",
    "        # Sanity check!\n",
    "        # Size of z should be number of relu activation layers + 1 (for input)\n",
    "        print(\"Number of relu layers: {0}\".format(len(z)))\n",
    "        # Size of z_hat should be number of hidden layers\n",
    "        print(\"Number of hidden layers: {0}\".format(len(z_hat)))\n",
    "        print(\"Size of last hidden layer: {0}\".format(len(z_hat[-1])))\n",
    "    \n",
    "    return m, z, z_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rank(nn, norm=1, skip_first_layer=True, skip_last_layer=True):\n",
    "    numlayer = nn.numlayer \n",
    "    norms = np.zeros((nn.weights[1].shape[0], numlayer-2)) # TODO use list or similar if first and last layer are also used\n",
    "    rank_local_idxs = np.zeros((nn.weights[1].shape[0], numlayer-2))\n",
    "    n_neurons = rank_local_idxs.shape[0] * rank_local_idxs.shape[1]\n",
    "    \n",
    "    for layerno in range(numlayer):\n",
    "        if skip_first_layer and layerno == 0:\n",
    "            #TODO treat first layer\n",
    "            continue\n",
    "        if skip_last_layer and layerno == numlayer-1:\n",
    "            continue\n",
    "        if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "            weights = nn.weights[layerno]\n",
    "            biases = nn.biases[layerno]\n",
    "#             norms[:, layerno-1] = np.linalg.norm(weights, ord=norm, axis=1) + biases\n",
    "            norms[:, layerno-1] = np.linalg.norm(weights, ord=norm, axis=0)\n",
    "\n",
    "        else:\n",
    "            print(' net type not supported')\n",
    "    \n",
    "    # Global rank\n",
    "    temp = np.argsort(-norms, axis=None)\n",
    "    rank_idxs = np.empty_like(temp)\n",
    "    rank_idxs[temp] = np.arange(len(temp))\n",
    "    rank_idxs = rank_idxs.reshape(nn.weights[1].shape[0], int(len(rank_idxs)/ nn.weights[1].shape[0])) /n_neurons\n",
    "    \n",
    "    # Local rank\n",
    "    temp = np.argsort(-norms, axis=0)\n",
    "    rank_local_idxs = np.empty_like(temp)\n",
    "    for layerno in range(numlayer-2):\n",
    "        rank_local_idxs[temp[:,layerno],layerno] = np.arange(norms.shape[0])\n",
    "    rank_local_idxs = rank_local_idxs/rank_local_idxs.shape[0]\n",
    "    \n",
    "    for layerno in range(numlayer):\n",
    "        if skip_first_layer and layerno == 0:\n",
    "            continue\n",
    "        if skip_last_layer and layerno == numlayer-1:\n",
    "            continue\n",
    "        if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "            nn.rank[layerno] = {}\n",
    "            nn.rank[layerno]['global'] = rank_idxs[:, layerno-1] # TODO Change minus 1 to flexibe offset\n",
    "            nn.rank[layerno]['local'] = rank_local_idxs[:, layerno-1] # TODO Change minus 1 to flexibe offset\n",
    "#             nn.use_LP[layerno] = nn.rank[layerno]  < rank_threshold\n",
    "        else:\n",
    "            print(' net type not supported')\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_linear_layerwise(nn, numlayer, LB_N0, UB_N0, lp_list, LB_hidden_box_list, UB_hidden_box_list, \n",
    "                             true_label, influence_threshold=[1.0, 0.0] ,verbose=True):\n",
    "    \"\"\"\n",
    "    Get final bounds using linear programming layerwise. If lp_freq > 1 linear bounds are only calculated every \n",
    "    lp_freq'th layer.\n",
    "    INPUT:\n",
    "        - m: Gurobi model\n",
    "        - z: List of Gurobi variables corresponding to pre-ReLU Layer (hidden)\n",
    "        - z_hat: List of Gurobi variables corresponding to post-ReLU Laye\n",
    "        - nn: Neural Network as defined in initial code (contains layertypes, weights, etc.)\n",
    "        - numlayer: Number of Layers\n",
    "        - LB_N0: Lower Bound of perturbed image input\n",
    "        - UB_N0: Upper Bound of perturbed image input\n",
    "        - lp_list: Layerno to start solvingbounds by LP. \n",
    "        - prob: probability to select a neuron\n",
    "        - LB_hidden_box_list: List of upper Bounds from box approximation\n",
    "        - UB_hidden_box_list: List of upper Bounds from box approximation\n",
    "        - influence_threshold: List of influence threshold where LP is used. First element corresponds \n",
    "                                 to threshold of layers in lp_list, second element to other layers.\n",
    "                                 Therefore, if layer is in lp_list, use LP if rank of Neuron is below \n",
    "                                 influence_threshold[0], default is use LP on ALL neurons of lp_list layer.\n",
    "                                 If layer is not in lp_list, use LP if rank of Neuron is below \n",
    "                                 influence_threshold[1], default do NOT use LP on neurons.\n",
    "                                 \n",
    "    OUTPUT:\n",
    "        - LB_NN: Lower bounds of neural network output\n",
    "        - UB_NN: Upper bounds of neural network output\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sanity check\n",
    "    assert LB_hidden_box_list is not None \n",
    "    assert UB_hidden_box_list is not None\n",
    "    assert all( v <=1.0 or v>=0 for v in influence_threshold)\n",
    "\n",
    "    # create manager for Elina\n",
    "    man = elina_box_manager_alloc()\n",
    "    # create gurobi model\n",
    "    m = get_model()\n",
    "    # create all gurobi variables for the network\n",
    "    m, z, z_hat = add_all_vars(m, numlayer, LB_N0, UB_N0, UB_hidden_box_list)\n",
    "    \n",
    "    # initialize counter\n",
    "    nn.ffn_counter = 0\n",
    "    \n",
    "    # Init statistics\n",
    "    stats = {'time': [],\n",
    "        'LB_hat': [],\n",
    "        'UB_hat': [],\n",
    "        'use_LP': [],\n",
    "        'margin': [],\n",
    "        'margin_per_neuron': [],\n",
    "        'margin_per_time': [],\n",
    "        'tightness_hat': [],\n",
    "        'min_tightness_hat': [],\n",
    "        'max_tightness_hat': [],\n",
    "        'median_tightness_hat': [],\n",
    "        }\n",
    "\n",
    "    # Adding weights constraints for k layers\n",
    "    for layerno in range(numlayer):\n",
    "        if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "            t1 = time.time()\n",
    "                        \n",
    "            # read the layer weights and biases\n",
    "            weights = nn.weights[nn.ffn_counter]\n",
    "            biases = nn.biases[nn.ffn_counter]\n",
    "            np.ascontiguousarray(weights, dtype=np.float)\n",
    "            np.ascontiguousarray(biases, dtype=np.float)\n",
    "\n",
    "            # output shape of the layer\n",
    "            n_in = weights.shape[1]\n",
    "            n_out = weights.shape[0]\n",
    "\n",
    "            # create variables to store bounds of hidden layer\n",
    "            LB_hat = np.zeros(n_out, float)\n",
    "            UB_hat = np.zeros(n_out, float)\n",
    "\n",
    "            # add affine constraint\n",
    "            add_hidden_constraint(m, layerno, z[layerno], z_hat[layerno], weights, biases)\n",
    "            \n",
    "            ##########################################\n",
    "            # First layer: Use original BOX bounds   #\n",
    "            ##########################################\n",
    "            if layerno < lp_list[0] or layerno == 0:\n",
    "                use_LP = np.zeros(n_out, dtype=np.bool)\n",
    "                LB_hat, UB_hat = LB_hidden_box_list[layerno].copy() , UB_hidden_box_list[layerno].copy()\n",
    "            \n",
    "            #########################################\n",
    "            # Last Layer: Use Linear Programming    #\n",
    "            #########################################\n",
    "            elif layerno == numlayer - 1:\n",
    "                use_LP = np.ones(n_out, dtype=np.bool)\n",
    "                \n",
    "                # LB: Get lower bound of correct label\n",
    "                LB_hat[true_label], _ = call_linear_solver(m, z_hat[layerno][true_label], lb_only=True)\n",
    "                \n",
    "                # UB: Get upper bound of all other labels    \n",
    "                for i_out in range(n_out):\n",
    "                    if i_out == true_label:\n",
    "                        continue\n",
    "                        \n",
    "                    _, UB_hat[i_out] = call_linear_solver(m, z_hat[layerno][i_out], ub_only=True)\n",
    "                \n",
    "            ######################################################\n",
    "            # All layers inbetween: Decide if we use LP or BOX   #\n",
    "            ######################################################\n",
    "            else:\n",
    "                \n",
    "                # Calculate box to get tigthness\n",
    "                LB, UB, n_out = get_relu_bounds_using_box(man, LB_hat_prev, UB_hat_prev, n_in)\n",
    "                LB_hat, UB_hat, n_out = get_hidden_bounds_using_box(man, weights, biases, \n",
    "                                                                LB, UB, n_out, verbose)\n",
    "                \n",
    "#                 # Check if Relu Constrain will be non trivial\n",
    "#                 trivial_relu_constrain = LB_hat > 0 or UB_hat < 0\n",
    "#                 nontrivial_relu_constrain = not trivial_relu_constrain\n",
    "                \n",
    "                # Relu activate\n",
    "                relu_inactive = UB_hat < 0\n",
    "                relu_inactive = relu_inactive.squeeze()\n",
    "            \n",
    "                # Get Tighness Rank\n",
    "                tightness_box = UB_hat.squeeze() - LB_hat.squeeze()\n",
    "                tightness_box[relu_inactive] = 0\n",
    "                temp = np.argsort(-tightness_box, axis=0)\n",
    "                tightness_box_rank = np.empty_like(temp)\n",
    "                tightness_box_rank[temp] = np.arange(len(temp))\n",
    "                tightness_box_rank = tightness_box_rank/n_out\n",
    "                \n",
    "                # Get Influence Rank\n",
    "                norm = 1\n",
    "                w = nn.weights[layerno+1]\n",
    "                norms = np.linalg.norm(w, ord=norm, axis=0)\n",
    "                norms[relu_inactive] = 0\n",
    "                influence = norms * tightness_box\n",
    "                temp = np.argsort(-influence, axis=0)\n",
    "                influence_rank = np.empty_like(temp)\n",
    "                influence_rank[temp] = np.arange(len(temp))\n",
    "                influence_rank = influence_rank/n_out\n",
    "                \n",
    "                # LP\n",
    "                # If the layer is in the list of layer use LP on ALL neurons\n",
    "                if (layerno in lp_list):\n",
    "                    # Use LP if the influence_rank is below the specified threshold.\n",
    "                    use_LP = (influence_rank < influence_threshold[0])\n",
    "                    \n",
    "                # LP\n",
    "                # If the layer is NOT in list of layer use LP only on high ranking neurons\n",
    "                else:\n",
    "                    # Use LP if the influence_rank is below the specified threshold.\n",
    "                    use_LP = (influence_rank < influence_threshold[1])\n",
    "                \n",
    "                for i_out in range(n_out):\n",
    "                    if use_LP[i_out]:\n",
    "                        LB_hat[i_out], UB_hat[i_out] = call_linear_solver(m, z_hat[layerno][i_out]) \n",
    "            \n",
    "            # add relu constraint\n",
    "            if layerno < (numlayer - 1) and nn.layertypes[layerno] in [\"ReLU\"]:\n",
    "                add_relu_activation_constraint(m, layerno, z_hat[layerno], z[layerno + 1], LB_hat, UB_hat)\n",
    "            \n",
    "            # preparation for next iteration    \n",
    "            LB_hat_prev, UB_hat_prev = LB_hat.copy(), UB_hat.copy()\n",
    "                \n",
    "            m.update()\n",
    "\n",
    "            # update counter for next iteration\n",
    "            nn.ffn_counter += 1\n",
    "            # Save where we used LP\n",
    "            nn.use_LP[layerno] = use_LP\n",
    "            nn.LB_hat[layerno] = LB_hat\n",
    "            nn.UB_hat[layerno] = UB_hat\n",
    "            \n",
    "            \n",
    "            # Save stats\n",
    "            t2 = time.time()\n",
    "            \n",
    "            stats['time'].append(t2 - t1)\n",
    "            stats['LB_hat'].append(LB_hat.squeeze())\n",
    "            stats['UB_hat'].append(UB_hat.squeeze())\n",
    "            stats['use_LP'].append(use_LP)\n",
    "            tightness = stats['UB_hat'][-1] - stats['LB_hat'][-1]\n",
    "            stats['tightness_hat'].append(tightness)\n",
    "            stats['median_tightness_hat'].append(np.median(tightness))\n",
    "            stats['min_tightness_hat'].append(min(tightness))\n",
    "            stats['max_tightness_hat'].append(max(tightness))\n",
    "\n",
    "            if layerno == (numlayer - 1):\n",
    "                stats['margin'].append(LB_hat[true_label] - max(UB_hat))\n",
    "                n_use_lp = sum([sum(lp) for lp in stats['use_LP']])\n",
    "                tot_time = sum(stats['time'])\n",
    "                stats['margin_per_neuron'].append( stats['margin'][-1]/n_use_lp )\n",
    "                stats['margin_per_time'].append(stats['margin'][-1]/tot_time)\n",
    "\n",
    "\n",
    "            \n",
    "            if verbose:\n",
    "                decimals=2\n",
    "                print(\"--------------------------\")\n",
    "                print(\"Layerno: %d\" %layerno)\n",
    "                print(\"Time %3f\" % (t2 - t1))\n",
    "                if stats['use_LP'][-1].any():\n",
    "                    print(\"Time per LP neuron %3f\" % ((t2 - t1)/ sum(stats['use_LP'][-1])))\n",
    "                    print(\"LP used on %d neurons.\" % sum(stats['use_LP'][-1]))\n",
    "                print(\"Median tigthness of hat bounds: %3f \\n\" % stats['median_tightness_hat'][-1])\n",
    "                print(\"Min tigthness of hat bounds: %3f \\n\" % stats['min_tightness_hat'][-1])\n",
    "                print(\"Max tigthness of hat bounds: %3f \\n\" % stats['max_tightness_hat'][-1])\n",
    "                print(\"[LB_hat | UB_hat | use_LP]\")\n",
    "                pprint(np.stack([LB_hat.squeeze(), UB_hat.squeeze(), stats['use_LP'][-1]], axis = 1).round(decimals=decimals))\n",
    "                print(\"--------------------------\\n\")\n",
    "\n",
    "                if layerno == (numlayer - 1):\n",
    "                    print(\"----------SUMMARY-----------\\n\")\n",
    "                    print(\"Verification Margin (more positive better): %3f \\n\" % stats['margin'][-1])\n",
    "                    print(\"Margin per LP neuron (more positve is better): %6f\\n\" % stats['margin_per_neuron'][-1])\n",
    "                    print(\"Margin per second (more positve is better): %10f\\n\" % stats['margin_per_time'][-1])\n",
    "                    print(\"----------END SUMMARY--------\\n\")\n",
    "\n",
    "        else:\n",
    "            raise(\"Not a valid layer!\")\n",
    "    \n",
    "    # Set bounds of last performed layer to output\n",
    "    LB_NN = LB_hat\n",
    "    UB_NN = UB_hat\n",
    "    # If last Layer is RELU change last lower and upper bounds accordingly.\n",
    "    if nn.layertypes[-1] == \"ReLU\" :\n",
    "        num_out = len(UB_hat)\n",
    "        for i in range(num_out):\n",
    "            if LB_hat[i] < 0 :\n",
    "                LB_NN[i] = 0 \n",
    "            if UB_hat[i] < 0 :\n",
    "                UB_NN[i] = 0 \n",
    "           \n",
    "    return LB_NN, UB_NN, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the problem variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_relu_3_10.txt    mnist_relu_6_100.txt  mnist_relu_9_100.txt\r\n",
      "mnist_relu_3_20.txt    mnist_relu_6_200.txt  mnist_relu_9_200.txt\r\n",
      "mnist_relu_3_50.txt    mnist_relu_6_20.txt\r\n",
      "mnist_relu_4_1024.txt  mnist_relu_6_50.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/riai2018/mnist_nets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get perturbed label and Load NN (provided prediction for unperturbed is true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nn(netname, specname, epsilon):\n",
    "    flag_wrong_label = False\n",
    "    \n",
    "    with open(netname, 'r') as netfile:\n",
    "        netstring = netfile.read()\n",
    "    with open(specname, 'r') as specfile:\n",
    "        specstring = specfile.read()\n",
    "    nn = parse_net(netstring)\n",
    "    x0_low, x0_high = parse_spec(specstring)\n",
    "    LB_N0, UB_N0 = get_perturbed_image(x0_low,0)\n",
    "    \n",
    "    label, _ = analyze(nn,LB_N0,UB_N0,0) # Get label of unperturbed image, i.e. eps=0\n",
    "    \n",
    "    print(\"True label: \" + str(label))\n",
    "    if(label == int(x0_low[0])):\n",
    "        LB_N0, UB_N0 = get_perturbed_image(x0_low, epsilon)\n",
    "    else:\n",
    "        print(\"image not correctly classified by the network. expected label \",int(x0_low[0]), \" classified label: \", label)\n",
    "        flag_wrong_label =  True\n",
    "        \n",
    "    return LB_N0, UB_N0, nn, label, flag_wrong_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 1\n"
     ]
    }
   ],
   "source": [
    "netname = '/home/riai2018/mnist_nets/mnist_relu_6_20.txt'\n",
    "specname = '/home/riai2018/mnist_images/img2.txt'\n",
    "epsilon = 0.001\n",
    "LB_N0, UB_N0, nn, label, flag_wrong_label = load_nn(netname, specname, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU\n",
      "ReLU\n",
      "ReLU\n",
      "ReLU\n",
      "ReLU\n"
     ]
    }
   ],
   "source": [
    "numlayer = nn.numlayer \n",
    "\n",
    "for layerno in range(numlayer):\n",
    "    if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "        print(nn.layertypes[layerno])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Find naive/spectral bounds using box approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "LB_hidden_box_list, UB_hidden_box_list, LB_NN, UB_NN = perform_box_analysis(nn, LB_N0, UB_N0, verbose = False)\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- For Box ----------\n",
      "[OUTPUT] Bounds: \n",
      "array([[ 0.        ,  0.        ],\n",
      "       [ 9.47404515, 10.8678384 ],\n",
      "       [ 2.0732196 ,  2.86511957],\n",
      "       [ 0.60576397,  1.06502746],\n",
      "       [ 0.        ,  0.54891204],\n",
      "       [ 0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ],\n",
      "       [ 2.66937381,  3.50468927],\n",
      "       [ 2.38386408,  3.36602735],\n",
      "       [ 0.        ,  0.        ]])\n",
      "[VERIFY] Verification status: \n",
      "verified\n",
      "----------------------------\n",
      "Calculation time: 0.12157368659973145 s\n"
     ]
    }
   ],
   "source": [
    "# check verifiability with box!\n",
    "print(\"--------- For Box ----------\")\n",
    "print(\"[OUTPUT] Bounds: \")\n",
    "pprint(np.stack([LB_NN, UB_NN], axis = 1))\n",
    "print(\"[VERIFY] Verification status: \")\n",
    "t = time.time()\n",
    "_, flag = verify_network(LB_N0, UB_N0, LB_NN, UB_NN, \\\n",
    "                         label, num_input_pixels = len(LB_N0), num_out_pixels = 10)\n",
    "print(\"----------------------------\")\n",
    "print(\"Calculation time: %s s\"% (t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Find tighter bounds using linear programming over box intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Paper:__ \"Provable defenses against adversarial examples via the convex outer adversarial polytope\"; J. Zico Kolter, Eric Wong [[PDF]](https://machine-learning-and-security.github.io/papers/mlsec17_paper_42.pdf)\n",
    "\n",
    "We follow the following notation: \n",
    "```\n",
    "Consider a k-layer feedforward ReLU-based NN, f_θ : R^|x| → R^|y|. Given equations: \n",
    "        z_hat_{i} = W_i * z_i + b_i, where i = {1, . . . , k}\n",
    "        z_i = max(z_hat_{i-1} , 0),      where i = {2, . . . , k}\n",
    "and, \n",
    "        z_1 = x\n",
    "        f_θ(x) ≡ z_hat_{k}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n",
      "Number of relu layers: 6\n",
      "Number of hidden layers: 6\n",
      "Size of last hidden layer: 10\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "LB_NN, UB_NN = perform_linear_over_box_approximation(nn, LB_N0, UB_N0, LB_hidden_box_list, UB_hidden_box_list, verbose = False)\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- For Linear (over box) ----------\n",
      "[OUTPUT] Bounds: \n",
      "array([[ 0.        ,  0.        ],\n",
      "       [10.0469925 , 10.33118855],\n",
      "       [ 2.42420647,  2.4952212 ],\n",
      "       [ 0.80795125,  0.84694697],\n",
      "       [ 0.06546422,  0.13054258],\n",
      "       [ 0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ],\n",
      "       [ 2.9903704 ,  3.13904587],\n",
      "       [ 2.84708954,  2.92978192],\n",
      "       [ 0.        ,  0.        ]])\n",
      "[VERIFY] Verification status: \n",
      "verified\n",
      "----------------------------\n",
      "Calculation time: 0.540243 s.\n"
     ]
    }
   ],
   "source": [
    "# check verifiability with linear!\n",
    "print(\"--------- For Linear (over box) ----------\")\n",
    "print(\"[OUTPUT] Bounds: \")\n",
    "pprint(np.stack([LB_NN, UB_NN], axis = 1))\n",
    "print(\"[VERIFY] Verification status: \")\n",
    "_, flag = verify_network(LB_N0, UB_N0, LB_NN, UB_NN, \\\n",
    "                         label, num_input_pixels = len(LB_N0), num_out_pixels = 10)\n",
    "print(\"----------------------------\")\n",
    "print(\"Calculation time: %4f s.\" % (t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Optimize through linear only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "lp_freq = 1\n",
    "lp_start = 1\n",
    "verbose = True\n",
    "\n",
    "lp_list = [i for i in range(lp_start, numlayer, lp_freq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relu layers: 6\n",
      "Number of hidden layers: 6\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 0.080661\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.084248 \n",
      "\n",
      "Min tigthness of hat bounds: 0.067921 \n",
      "\n",
      "Max tigthness of hat bounds: 0.109598 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.76, -1.67,   nan,   nan,  0.  ],\n",
      "       [-1.98, -1.87,   nan,   nan,  0.  ],\n",
      "       [-1.46, -1.39,   nan,   nan,  0.  ],\n",
      "       [-0.07,  0.02,   nan,   nan,  0.  ],\n",
      "       [-1.15, -1.05,   nan,   nan,  0.  ],\n",
      "       [ 1.13,  1.22,   nan,   nan,  0.  ],\n",
      "       [-0.73, -0.65,   nan,   nan,  0.  ],\n",
      "       [ 0.51,  0.61,   nan,   nan,  0.  ],\n",
      "       [-1.52, -1.43,   nan,   nan,  0.  ],\n",
      "       [ 1.05,  1.14,   nan,   nan,  0.  ],\n",
      "       [-3.48, -3.39,   nan,   nan,  0.  ],\n",
      "       [-4.13, -4.06,   nan,   nan,  0.  ],\n",
      "       [ 0.97,  1.06,   nan,   nan,  0.  ],\n",
      "       [-0.24, -0.17,   nan,   nan,  0.  ],\n",
      "       [ 1.11,  1.19,   nan,   nan,  0.  ],\n",
      "       [ 0.24,  0.32,   nan,   nan,  0.  ],\n",
      "       [-3.12, -3.03,   nan,   nan,  0.  ],\n",
      "       [ 4.66,  4.75,   nan,   nan,  0.  ],\n",
      "       [-2.72, -2.65,   nan,   nan,  0.  ],\n",
      "       [-0.79, -0.7 ,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 20\n",
      "[Network] Shape of weights: (20, 20)\n",
      "[Network] Shape of biases: (20,)\n",
      "[Network] Out pixels: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riai2018/.local/lib/python3.6/site-packages/numpy/lib/function_base.py:3250: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 0.455225\n",
      "Time per LP neuron 0.022761\n",
      "LP used on 20 neurons.\n",
      "Median global rank: 0.181250\n",
      "Median tigthness of hat bounds: 0.060159 \n",
      "\n",
      "Min tigthness of hat bounds: 0.018668 \n",
      "\n",
      "Max tigthness of hat bounds: 0.134819 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.6 , -0.57,  0.16,  0.36,  1.  ],\n",
      "       [-0.02,  0.04,  0.02,  0.  ,  1.  ],\n",
      "       [-0.49, -0.44,  0.34,  0.71,  1.  ],\n",
      "       [-1.02, -0.96,  0.03,  0.06,  1.  ],\n",
      "       [-0.83, -0.77,  0.17,  0.41,  1.  ],\n",
      "       [ 5.69,  5.83,  0.33,  0.66,  1.  ],\n",
      "       [ 1.65,  1.73,  0.59,  0.86,  1.  ],\n",
      "       [-0.5 , -0.42,  0.07,  0.16,  1.  ],\n",
      "       [-0.6 , -0.56,  0.06,  0.11,  1.  ],\n",
      "       [-0.13, -0.08,  0.09,  0.21,  1.  ],\n",
      "       [-0.03,  0.07,  0.61,  0.91,  1.  ],\n",
      "       [-0.24, -0.2 ,  0.19,  0.5 ,  1.  ],\n",
      "       [-0.66, -0.6 ,  0.18,  0.46,  1.  ],\n",
      "       [ 1.13,  1.22,  0.49,  0.81,  1.  ],\n",
      "       [ 4.91,  5.03,  0.24,  0.56,  1.  ],\n",
      "       [-0.16, -0.08,  0.25,  0.61,  1.  ],\n",
      "       [-1.14, -1.09,  0.11,  0.25,  1.  ],\n",
      "       [ 0.12,  0.14,  0.44,  0.75,  1.  ],\n",
      "       [-0.74, -0.64,  0.82,  0.96,  1.  ],\n",
      "       [ 1.48,  1.52,  0.14,  0.31,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 20\n",
      "[Network] Shape of weights: (20, 20)\n",
      "[Network] Shape of biases: (20,)\n",
      "[Network] Out pixels: 20\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 0.370638\n",
      "Time per LP neuron 0.018532\n",
      "LP used on 20 neurons.\n",
      "Median global rank: 0.600000\n",
      "Median tigthness of hat bounds: 0.040323 \n",
      "\n",
      "Min tigthness of hat bounds: 0.015198 \n",
      "\n",
      "Max tigthness of hat bounds: 0.191052 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.04,  0.06,  0.31,  0.21,  1.  ],\n",
      "       [ 0.03,  0.08,  0.41,  0.36,  1.  ],\n",
      "       [ 3.1 ,  3.19,  0.87,  0.81,  1.  ],\n",
      "       [ 0.77,  0.81,  0.39,  0.31,  1.  ],\n",
      "       [-0.43, -0.4 ,  0.37,  0.25,  1.  ],\n",
      "       [-0.31, -0.29,  0.68,  0.5 ,  1.  ],\n",
      "       [ 0.3 ,  0.33,  0.81,  0.71,  1.  ],\n",
      "       [ 2.46,  2.51,  0.22,  0.16,  1.  ],\n",
      "       [ 7.64,  7.83,  0.21,  0.11,  1.  ],\n",
      "       [-0.44, -0.4 ,  0.89,  0.86,  1.  ],\n",
      "       [-1.1 , -1.06,  0.53,  0.46,  1.  ],\n",
      "       [-2.08, -2.03,  0.86,  0.75,  1.  ],\n",
      "       [ 1.95,  2.02,  0.74,  0.61,  1.  ],\n",
      "       [ 1.25,  1.29,  0.43,  0.41,  1.  ],\n",
      "       [-0.5 , -0.47,  0.69,  0.56,  1.  ],\n",
      "       [ 6.15,  6.31,  0.08,  0.06,  1.  ],\n",
      "       [ 0.19,  0.22,  0.97,  0.91,  1.  ],\n",
      "       [-2.09, -2.04,  0.99,  0.96,  1.  ],\n",
      "       [ 2.56,  2.62,  0.  ,  0.  ,  1.  ],\n",
      "       [ 0.05,  0.09,  0.78,  0.66,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 20\n",
      "[Network] Shape of weights: (20, 20)\n",
      "[Network] Shape of biases: (20,)\n",
      "[Network] Out pixels: 20\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 0.317443\n",
      "Time per LP neuron 0.015872\n",
      "LP used on 20 neurons.\n",
      "Median global rank: 0.587500\n",
      "Median tigthness of hat bounds: 0.077608 \n",
      "\n",
      "Min tigthness of hat bounds: 0.013643 \n",
      "\n",
      "Max tigthness of hat bounds: 0.241237 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-6.550e+00, -6.380e+00,  9.800e-01,  9.600e-01,  1.000e+00],\n",
      "       [-2.500e-01, -2.400e-01,  6.700e-01,  6.100e-01,  1.000e+00],\n",
      "       [-3.570e+00, -3.480e+00,  2.900e-01,  1.100e-01,  1.000e+00],\n",
      "       [-9.000e-02, -6.000e-02,  8.800e-01,  8.100e-01,  1.000e+00],\n",
      "       [ 4.810e+00,  4.910e+00,  4.800e-01,  3.100e-01,  1.000e+00],\n",
      "       [-1.850e+00, -1.780e+00,  8.300e-01,  7.500e-01,  1.000e+00],\n",
      "       [-3.230e+00, -3.130e+00,  6.300e-01,  5.600e-01,  1.000e+00],\n",
      "       [-6.000e-02, -1.000e-02,  7.900e-01,  7.100e-01,  1.000e+00],\n",
      "       [-2.880e+00, -2.800e+00,  2.300e-01,  6.000e-02,  1.000e+00],\n",
      "       [-8.300e-01, -7.600e-01,  4.600e-01,  2.500e-01,  1.000e+00],\n",
      "       [-9.300e-01, -8.800e-01,  3.600e-01,  2.100e-01,  1.000e+00],\n",
      "       [-3.040e+00, -2.940e+00,  7.100e-01,  6.600e-01,  1.000e+00],\n",
      "       [-5.500e-01, -5.300e-01,  6.200e-01,  5.000e-01,  1.000e+00],\n",
      "       [-1.560e+00, -1.520e+00,  9.300e-01,  9.100e-01,  1.000e+00],\n",
      "       [-3.340e+00, -3.250e+00,  9.100e-01,  8.600e-01,  1.000e+00],\n",
      "       [ 3.660e+00,  3.760e+00,  5.700e-01,  4.600e-01,  1.000e+00],\n",
      "       [ 9.880e+00,  1.012e+01,  5.400e-01,  3.600e-01,  1.000e+00],\n",
      "       [-1.540e+00, -1.460e+00,  5.600e-01,  4.100e-01,  1.000e+00],\n",
      "       [ 5.030e+00,  5.140e+00,  3.200e-01,  1.600e-01,  1.000e+00],\n",
      "       [-5.300e-01, -5.100e-01,  4.000e-02,  0.000e+00,  1.000e+00]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 20\n",
      "[Network] Shape of weights: (20, 20)\n",
      "[Network] Shape of biases: (20,)\n",
      "[Network] Out pixels: 20\n",
      "--------------------------\n",
      "Layerno: 4\n",
      "Time 0.339737\n",
      "Time per LP neuron 0.016987\n",
      "LP used on 20 neurons.\n",
      "Median global rank: 0.606250\n",
      "Median tigthness of hat bounds: 0.064361 \n",
      "\n",
      "Min tigthness of hat bounds: 0.013025 \n",
      "\n",
      "Max tigthness of hat bounds: 0.215551 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 2.66,  2.7 ,  0.28,  0.16,  1.  ],\n",
      "       [-1.44, -1.4 ,  0.94,  0.91,  1.  ],\n",
      "       [ 0.1 ,  0.12,  0.92,  0.86,  1.  ],\n",
      "       [-4.82, -4.71,  0.84,  0.81,  1.  ],\n",
      "       [-0.78, -0.76,  0.42,  0.25,  1.  ],\n",
      "       [-4.89, -4.77,  0.38,  0.21,  1.  ],\n",
      "       [-1.06, -1.04,  0.72,  0.61,  1.  ],\n",
      "       [-3.04, -2.94,  0.12,  0.  ,  1.  ],\n",
      "       [-7.82, -7.63,  0.96,  0.96,  1.  ],\n",
      "       [-5.6 , -5.46,  0.75,  0.71,  1.  ],\n",
      "       [-4.51, -4.39,  0.27,  0.11,  1.  ],\n",
      "       [-1.28, -1.25,  0.52,  0.41,  1.  ],\n",
      "       [-2.33, -2.28,  0.73,  0.66,  1.  ],\n",
      "       [-2.5 , -2.43,  0.77,  0.75,  1.  ],\n",
      "       [-3.05, -2.98,  0.64,  0.5 ,  1.  ],\n",
      "       [ 3.9 ,  3.98,  0.5 ,  0.36,  1.  ],\n",
      "       [ 0.13,  0.16,  0.13,  0.06,  1.  ],\n",
      "       [-2.41, -2.35,  0.58,  0.46,  1.  ],\n",
      "       [ 8.82,  9.04,  0.66,  0.56,  1.  ],\n",
      "       [-2.56, -2.5 ,  0.47,  0.31,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 5\n",
      "Time 0.052669\n",
      "Time per LP neuron 0.005267\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: -0.805406 \n",
      "\n",
      "Min tigthness of hat bounds: -10.092971 \n",
      "\n",
      "Max tigthness of hat bounds: 3.088661 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.  , -4.29,   nan,   nan,  1.  ],\n",
      "       [10.1 ,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  2.49,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  0.84,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  0.13,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -2.27,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -4.71,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  3.09,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  2.93,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -1.73,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): 7.004310 \n",
      "\n",
      "Margin per LP neuron (more positve is better): 0.077826\n",
      "\n",
      "Margin per second (more positve is better):   4.333350\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "{'time': [0.08066058158874512, 0.45522499084472656, 0.3706378936767578, 0.3174431324005127, 0.3397374153137207, 0.05266880989074707], 'LB_hat': [array([-1.76385256, -1.98753952, -1.46817394, -0.07222603, -1.15187967,\n",
      "        1.12249094, -0.73749013,  0.50628401, -1.520204  ,  1.04931947,\n",
      "       -3.48031755, -4.1383164 ,  0.96801833, -0.24664968,  1.10875178,\n",
      "        0.23588701, -3.12179195,  4.65153167, -2.72709009, -0.79159644]), array([-0.6098033 , -0.02367247, -0.49726519, -1.02907456, -0.83356255,\n",
      "        5.68995823,  1.64670788, -0.50694538, -0.60802405, -0.13246112,\n",
      "       -0.03219188, -0.24763317, -0.66651502,  1.12758099,  4.90874315,\n",
      "       -0.1625087 , -1.14600878,  0.1171228 , -0.7487879 ,  1.47055233]), array([ 0.03531071,  0.02624121,  3.09712527,  0.76891126, -0.43249294,\n",
      "       -0.31867412,  0.2905095 ,  2.45313689,  7.63473203, -0.44572752,\n",
      "       -1.10985752, -2.08748843,  1.94738587,  1.24120517, -0.50702645,\n",
      "        6.14265306,  0.18595096, -2.09354504,  2.55008573,  0.04508633]), array([-6.55137729, -0.25938453, -3.57131864, -0.09778138,  4.80647989,\n",
      "       -1.85242546, -3.23834304, -0.06958181, -2.88592917, -0.83594417,\n",
      "       -0.93098564, -3.04170352, -0.55271958, -1.56680658, -3.34702281,\n",
      "        3.65273433,  9.87395126, -1.54709841,  5.02390464, -0.53038305]), array([ 2.65045075, -1.44682808,  0.09470069, -4.82338441, -0.78222655,\n",
      "       -4.89843515, -1.06883991, -3.04213539, -7.82989658, -5.60106447,\n",
      "       -4.51762506, -1.28179023, -2.33938845, -2.50469917, -3.05632667,\n",
      "        3.89812884,  0.12964305, -2.41468568,  8.81450803, -2.56320861]), array([ 0.        , 10.09297108,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ])], 'UB_hat': [array([-1.6787971 , -1.87794102, -1.39226741,  0.01510927, -1.0512356 ,\n",
      "        1.21255568, -0.65883889,  0.60238092, -1.43008016,  1.13703233,\n",
      "       -3.39843506, -4.06364544,  1.05145835, -0.1768291 ,  1.18920342,\n",
      "        0.31314121, -3.03268656,  4.74299019, -2.65916901, -0.70835856]), array([-0.57799584,  0.03134706, -0.4454258 , -0.96739661, -0.77239899,\n",
      "        5.82477699,  1.72815857, -0.42375138, -0.56114727, -0.08151063,\n",
      "        0.06477157, -0.20255024, -0.60736089,  1.21215752,  5.02201342,\n",
      "       -0.0872651 , -1.09863358,  0.13579062, -0.6459027 ,  1.5158776 ]), array([ 0.0505089 ,  0.07510812,  3.18629073,  0.80190108, -0.40512236,\n",
      "       -0.29434716,  0.32430092,  2.5032343 ,  7.82578412, -0.40588257,\n",
      "       -1.06905711, -2.03466526,  2.01205578,  1.28009161, -0.47366095,\n",
      "        6.30526012,  0.21094318, -2.04090043,  2.6126968 ,  0.08079992]), array([-6.38987842, -0.24574129, -3.48047353, -0.06987565,  4.90542726,\n",
      "       -1.78484353, -3.13594319, -0.01585314, -2.80827531, -0.76239221,\n",
      "       -0.88696524, -2.94636286, -0.53303364, -1.52165297, -3.2506057 ,\n",
      "        3.75127067, 10.11518781, -1.46953722,  5.1357791 , -0.51032546]), array([ 2.69283907, -1.40796832,  0.11210949, -4.7132369 , -0.76920152,\n",
      "       -4.77387223, -1.04116811, -2.94415953, -7.63704299, -5.46033367,\n",
      "       -4.39428093, -1.25219022, -2.28680949, -2.43662526, -2.98604903,\n",
      "        3.97363613,  0.15351926, -2.3540368 ,  9.03005919, -2.5041566 ]), array([0.        , 0.        , 2.48018364, 0.8327827 , 0.12350749,\n",
      "       0.        , 0.        , 3.08866122, 2.92154509, 0.        ])], 'use_LP': [array([False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False]), array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True]), array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True]), array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True]), array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True]), array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True])], 'local_rank': [array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "       nan, nan, nan, nan, nan, nan, nan]), array([0.35, 0.  , 0.7 , 0.05, 0.4 , 0.65, 0.85, 0.15, 0.1 , 0.2 , 0.9 ,\n",
      "       0.5 , 0.45, 0.8 , 0.55, 0.6 , 0.25, 0.75, 0.95, 0.3 ]), array([0.2 , 0.35, 0.8 , 0.3 , 0.25, 0.5 , 0.7 , 0.15, 0.1 , 0.85, 0.45,\n",
      "       0.75, 0.6 , 0.4 , 0.55, 0.05, 0.9 , 0.95, 0.  , 0.65]), array([0.95, 0.6 , 0.1 , 0.8 , 0.3 , 0.75, 0.55, 0.7 , 0.05, 0.25, 0.2 ,\n",
      "       0.65, 0.5 , 0.9 , 0.85, 0.45, 0.35, 0.4 , 0.15, 0.  ]), array([0.15, 0.9 , 0.85, 0.8 , 0.25, 0.2 , 0.6 , 0.  , 0.95, 0.7 , 0.1 ,\n",
      "       0.4 , 0.65, 0.75, 0.5 , 0.35, 0.05, 0.45, 0.55, 0.3 ]), array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])], 'global_rank': [array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "       nan, nan, nan, nan, nan, nan, nan]), array([0.15  , 0.0125, 0.3375, 0.025 , 0.1625, 0.325 , 0.5875, 0.0625,\n",
      "       0.05  , 0.0875, 0.6   , 0.1875, 0.175 , 0.4875, 0.2375, 0.25  ,\n",
      "       0.1   , 0.4375, 0.8125, 0.1375]), array([0.3   , 0.4   , 0.8625, 0.3875, 0.3625, 0.675 , 0.8   , 0.2125,\n",
      "       0.2   , 0.8875, 0.525 , 0.85  , 0.7375, 0.425 , 0.6875, 0.075 ,\n",
      "       0.9625, 0.9875, 0.    , 0.775 ]), array([0.975 , 0.6625, 0.2875, 0.875 , 0.475 , 0.825 , 0.625 , 0.7875,\n",
      "       0.225 , 0.45  , 0.35  , 0.7   , 0.6125, 0.925 , 0.9   , 0.5625,\n",
      "       0.5375, 0.55  , 0.3125, 0.0375]), array([0.275 , 0.9375, 0.9125, 0.8375, 0.4125, 0.375 , 0.7125, 0.1125,\n",
      "       0.95  , 0.75  , 0.2625, 0.5125, 0.725 , 0.7625, 0.6375, 0.5   ,\n",
      "       0.125 , 0.575 , 0.65  , 0.4625]), array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])], 'margin': [7.0043098589346755], 'margin_per_neuron': [0.07782566509927417], 'margin_per_time': [4.333350422729436], 'tightness_hat': [array([0.08505546, 0.1095985 , 0.07590653, 0.08733529, 0.10064406,\n",
      "       0.09006473, 0.07865124, 0.09609692, 0.09012384, 0.08771286,\n",
      "       0.08188249, 0.07467096, 0.08344001, 0.06982058, 0.08045164,\n",
      "       0.0772542 , 0.08910538, 0.09145852, 0.06792108, 0.08323788]), array([0.03180747, 0.05501954, 0.05183938, 0.06167795, 0.06116357,\n",
      "       0.13481876, 0.08145069, 0.083194  , 0.04687678, 0.05095049,\n",
      "       0.09696345, 0.04508293, 0.05915413, 0.08457652, 0.11327027,\n",
      "       0.07524361, 0.04737519, 0.01866782, 0.1028852 , 0.04532527]), array([0.01519819, 0.04886691, 0.08916545, 0.03298982, 0.02737058,\n",
      "       0.02432696, 0.03379142, 0.05009742, 0.19105209, 0.03984495,\n",
      "       0.04080042, 0.05282317, 0.06466991, 0.03888644, 0.0333655 ,\n",
      "       0.16260706, 0.02499222, 0.05264461, 0.06261107, 0.03571358]), array([0.16149888, 0.01364324, 0.09084511, 0.02790573, 0.09894737,\n",
      "       0.06758192, 0.10239985, 0.05372867, 0.07765386, 0.07355196,\n",
      "       0.04402041, 0.09534066, 0.01968594, 0.04515362, 0.0964171 ,\n",
      "       0.09853634, 0.24123655, 0.07756119, 0.11187447, 0.0200576 ]), array([0.04238832, 0.03885976, 0.0174088 , 0.11014751, 0.01302503,\n",
      "       0.12456292, 0.0276718 , 0.09797586, 0.19285359, 0.1407308 ,\n",
      "       0.12334412, 0.02960001, 0.05257896, 0.06807391, 0.07027763,\n",
      "       0.07550729, 0.02387621, 0.06064889, 0.21555115, 0.05905201]), array([ -4.29693099, -10.09297108,   2.48018364,   0.8327827 ,\n",
      "         0.12350749,  -2.27596269,  -4.71576094,   3.08866122,\n",
      "         2.92154509,  -1.73431876])], 'min_tightness_hat': [0.06792108187027335, 0.018667821878120786, 0.015198190428009059, 0.01364323789929292, 0.01302503377280706, -10.092971078393225], 'max_tightness_hat': [0.10959849628725715, 0.13481876048425256, 0.19105209452972183, 0.24123654668024663, 0.21555115247266698, 3.088661219458549], 'median_tightness_hat': [0.08424773828656917, 0.060158846946151145, 0.04032268132492922, 0.07760752245448321, 0.06436139537288144, -0.805405633252271]}\n"
     ]
    }
   ],
   "source": [
    "t_1 =time.time()\n",
    "LB_NN, UB_NN, stats = perform_linear_layerwise(nn, numlayer, LB_N0, UB_N0, lp_list,\n",
    "                             LB_hidden_box_list, UB_hidden_box_list, label, verbose=verbose)\n",
    "t_2 =time.time()\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------TIME------------\n",
      "Total number of layers = 6\n",
      "lp_list = [1, 2, 3, 4, 5]\n",
      "Time Solving LP: 1.692142 s.\n",
      "----------------------------\n",
      "--------- For Linear ----------\n",
      "[OUTPUT] Bounds: \n",
      "array([[ 0.        ,  0.        ],\n",
      "       [10.09297108,  0.        ],\n",
      "       [ 0.        ,  2.48018364],\n",
      "       [ 0.        ,  0.8327827 ],\n",
      "       [ 0.        ,  0.12350749],\n",
      "       [ 0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ],\n",
      "       [ 0.        ,  3.08866122],\n",
      "       [ 0.        ,  2.92154509],\n",
      "       [ 0.        ,  0.        ]])\n",
      "[VERIFY] Verification status: \n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "print(\"------------TIME------------\")\n",
    "print(\"Total number of layers = %s\"% numlayer)\n",
    "print(\"lp_list = %s\"% lp_list)\n",
    "print(\"Time Solving LP: %4f s.\" % (t_2-t_1))\n",
    "print(\"----------------------------\")\n",
    "\n",
    "# check verifiability with linear!\n",
    "print(\"--------- For Linear ----------\")\n",
    "print(\"[OUTPUT] Bounds: \")\n",
    "pprint(np.stack([LB_NN.squeeze(), UB_NN.squeeze()], axis = 1))\n",
    "print(\"[VERIFY] Verification status: \")\n",
    "_, flag = verify_network(LB_N0, UB_N0, LB_NN, UB_NN, \\\n",
    "                         label, num_input_pixels = len(LB_N0), num_out_pixels = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Speed Linear Solver up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# params\n",
    "lp_freq = 2\n",
    "lp_start = 1\n",
    "verbose = True\n",
    "\n",
    "lp_list = [i for i in range(lp_start, numlayer, lp_freq)]\n",
    "lp_list = [i for i in range(lp_start, numlayer-2)]\n",
    "print(lp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-83b4c32f7a8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m LB_NN, UB_NN, stats = perform_linear_layerwise(nn, numlayer, LB_N0, UB_N0, lp_list,\n\u001b[1;32m      3\u001b[0m                              \u001b[0mLB_hidden_box_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUB_hidden_box_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_rank_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                        local_rank_threshold=0.0)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mt_2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-e82c0f8f0515>\u001b[0m in \u001b[0;36mperform_linear_layerwise\u001b[0;34m(nn, numlayer, LB_N0, UB_N0, lp_list, LB_hidden_box_list, UB_hidden_box_list, true_label, global_rank_threshold, local_rank_threshold, tightness_threshold, influence_threshold, verbose)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mLB_hidden_box_list\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mUB_hidden_box_list\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_rank_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_rank_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m<=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobal_rank_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "t_1 =time.time()\n",
    "LB_NN, UB_NN, stats = perform_linear_layerwise(nn, numlayer, LB_N0, UB_N0, lp_list,\n",
    "                             LB_hidden_box_list, UB_hidden_box_list, label, verbose=verbose, global_rank_threshold=0.0,\n",
    "                                       local_rank_threshold=0.0)\n",
    "t_2 =time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------TIME------------\")\n",
    "print(\"Total number of layers = %s\"% numlayer)\n",
    "print(\"lp_list = %s\"% lp_list)\n",
    "print(\"Time Solving LP: %4f s.\" % (t_2-t_1))\n",
    "print(\"----------------------------\")\n",
    "\n",
    "# check verifiability with linear!\n",
    "print(\"--------- For Linear ----------\")\n",
    "print(\"[OUTPUT] Bounds: \")\n",
    "pprint(np.stack([LB_NN.squeeze(), UB_NN.squeeze()], axis = 1))\n",
    "print(\"[VERIFY] Verification status: \")\n",
    "_, flag = verify_network(LB_N0, UB_N0, LB_NN, UB_NN, \\\n",
    "                         label, num_input_pixels = len(LB_N0), num_out_pixels = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Testing Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_nn_and_write(net_code, img_nrs, epsilon, log_file=None, verbose=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Analyse Neural Network and write the result to a log file. Code heuristic yourself in this function\n",
    "    INPUT:\n",
    "        - net_code: Neural Network code, e.g. mnist_relu_4_1024\n",
    "        - img_nrs: List of image nrs, e.g [0,1,2,3]\n",
    "        - epsilon: Perturbation\n",
    "        - log_file: File to write results\n",
    "    OUTPUT:\n",
    "        - verified_flag: Verification flag. True if network was verified against perturbation.\n",
    "    \"\"\"\n",
    "    nn_root_path = '/home/riai2018/mnist_nets'\n",
    "    img_root_path = '/home/riai2018/mnist_images'\n",
    "    log_root_path = '/home/riai2018/log'\n",
    "    log_base_name = 'log_'\n",
    "    verified_counter, true_label_counter = 0, 0\n",
    "    stamp = '_{:%Y-%m-%d_%H:%M:%S}'.format(datetime.now())\n",
    "    if not os.path.isdir(log_root_path):\n",
    "        os.makedirs(log_root_path)\n",
    "    net_path = os.path.join(nn_root_path, net_code + '.txt')\n",
    "    if log_file is None:\n",
    "        log_file = os.path.join(log_root_path, log_base_name + net_code + '_epsilon_' + str(epsilon))\n",
    "        if kwargs is not None:\n",
    "            log_file = log_file + '_'  + str(kwargs) + \"_\"\n",
    "        log_file = log_file + stamp +'.txt'\n",
    "            \n",
    "    with open(log_file, \"+a\") as f:\n",
    "        f.write(\"Epsilon %s kwargs: %s \\n\\n\" % (epsilon, kwargs))\n",
    "        \n",
    "    assert max(img_nrs) <= 99\n",
    "    assert min(img_nrs) >= 0\n",
    "    t_start = time.time()\n",
    "    \n",
    "    runtimes = []\n",
    "    \n",
    "    for img_nr in img_nrs:\n",
    "        img_path = os.path.join(img_root_path, 'img' + str(img_nr) + '.txt')\n",
    "\n",
    "        # Load NN and perturbe image\n",
    "        LB_N0, UB_N0, nn, label, flag_wrong_label = load_nn(net_path, img_path, epsilon)\n",
    "        true_label_counter += int(not flag_wrong_label)\n",
    "        numlayer = nn.numlayer\n",
    "\n",
    "        # You heuristics come here:\n",
    "#         lp_freq = 2\n",
    "        lp_start = 1\n",
    "        numlayer = nn.numlayer\n",
    "#         lp_list = [i for i in range(lp_start, numlayer, lp_freq)]\n",
    "        lp_list = [i for i in range(lp_start, numlayer-2)]\n",
    "\n",
    "        # Get Bounds\n",
    "        t1 =time.time()\n",
    "        LB_hidden_box_list, UB_hidden_box_list, LB_NN, UB_NN = perform_box_analysis(nn, LB_N0, UB_N0, verbose = False)\n",
    "        LB_NN, UB_NN, stats = perform_linear_layerwise(nn, numlayer, LB_N0, UB_N0, lp_list,\n",
    "                                     LB_hidden_box_list, UB_hidden_box_list, label, verbose=verbose, **kwargs)\n",
    "        # Check if NN was verified\n",
    "        _, verified_flag = verify_network(LB_N0, UB_N0, LB_NN, UB_NN, label, num_input_pixels = len(LB_N0), num_out_pixels = 10)\n",
    "        verified_counter += int(verified_flag)\n",
    "       \n",
    "        t2 = time.time()\n",
    "        \n",
    "        runtimes.append(t2-t1)\n",
    "        \n",
    "        # Write to logfile\n",
    "        with open(log_file, \"+a\") as f:\n",
    "            if not flag_wrong_label and verified_flag:\n",
    "                line = \"{:>10} img_{:>2} verified label {:>2} time {:>5.4f} s\\n\\n\".format(net_code, img_nr, label, t2-t1)\n",
    "            elif not flag_wrong_label and not verified_flag:\n",
    "                line = \"{:>10} img_{:>2} failed label {:>2} time {:>5.4f} s\\n\\n\".format(net_code, img_nr, label, t2-t1)\n",
    "            else:\n",
    "                line = \"{:>10} img_{:>2} not considered\\n\\n\".format(net_code, img_nr)\n",
    "            f.write(line)\n",
    "            f.write(\"Layerwise_time: %s \\n\" % stats['time'])\n",
    "            bounds = np.stack([stats['LB_hat'][-1], stats['UB_hat'][-1]], axis = 1) \n",
    "            f.write(\"Final Bounds: %s \\n\" % (bounds))\n",
    "            f.write(\"Final Verification Margin (negative is not verified): %3f \\n\" % stats['margin'][-1])\n",
    "            f.write(\"Margin per Neuron (more positive is better): %9f \\n\" % stats['margin_per_neuron'][-1])\n",
    "            f.write(\"Margin per Second (more positve is better): %10f\\n\" % stats['margin_per_time'][-1])\n",
    "            f.write(\"\\n-------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "            \n",
    "    with open(log_file, \"+a\") as f:\n",
    "        line = []\n",
    "        line.append(\"\\n--------------------- \\n\")\n",
    "        line.append(\"analysis precision  {:>2} /  {:>2}\\n\".format(verified_counter, true_label_counter))\n",
    "        line.append(\"Average Time: {:>5.4f} \\n\".format((time.time() - t_start)/len(img_nrs)))\n",
    "        line.append(\"Max Time: {:>5.4f} \\n\".format(max(runtimes)))\n",
    "        line.append(\"Min Time: {:>5.4f} \\n\".format(min(runtimes)))\n",
    "        for l in line:\n",
    "            f.write(l)\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Neural Networks: ['mnist_relu_3_10', 'mnist_relu_3_20', 'mnist_relu_3_50', 'mnist_relu_4_1024', 'mnist_relu_6_100', 'mnist_relu_6_20', 'mnist_relu_6_200', 'mnist_relu_6_50', 'mnist_relu_9_100', 'mnist_relu_9_200']\n"
     ]
    }
   ],
   "source": [
    "# Create list of all NN and images\n",
    "\n",
    "directory = '../mnist_nets/'\n",
    "nn_list  = os.listdir(directory)\n",
    "nn_list = [f.replace('.txt','') for f in nn_list]\n",
    "nn_list.sort()\n",
    "print(\"All Neural Networks: %s\" % nn_list)\n",
    "directory = '../mnist_images/'\n",
    "img_nrs  = np.arange(100).tolist()\n",
    "verbose = False\n",
    "# Create list of all groundtruth NN and epsilons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 1\n",
      "Number of relu layers: 6\n",
      "Number of hidden layers: 6\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 0.032199\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.084248 \n",
      "\n",
      "Min tigthness of hat bounds: 0.067921 \n",
      "\n",
      "Max tigthness of hat bounds: 0.109598 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.76, -1.67,   nan,   nan,  0.  ],\n",
      "       [-1.98, -1.87,   nan,   nan,  0.  ],\n",
      "       [-1.46, -1.39,   nan,   nan,  0.  ],\n",
      "       [-0.07,  0.02,   nan,   nan,  0.  ],\n",
      "       [-1.15, -1.05,   nan,   nan,  0.  ],\n",
      "       [ 1.13,  1.22,   nan,   nan,  0.  ],\n",
      "       [-0.73, -0.65,   nan,   nan,  0.  ],\n",
      "       [ 0.51,  0.61,   nan,   nan,  0.  ],\n",
      "       [-1.52, -1.43,   nan,   nan,  0.  ],\n",
      "       [ 1.05,  1.14,   nan,   nan,  0.  ],\n",
      "       [-3.48, -3.39,   nan,   nan,  0.  ],\n",
      "       [-4.13, -4.06,   nan,   nan,  0.  ],\n",
      "       [ 0.97,  1.06,   nan,   nan,  0.  ],\n",
      "       [-0.24, -0.17,   nan,   nan,  0.  ],\n",
      "       [ 1.11,  1.19,   nan,   nan,  0.  ],\n",
      "       [ 0.24,  0.32,   nan,   nan,  0.  ],\n",
      "       [-3.12, -3.03,   nan,   nan,  0.  ],\n",
      "       [ 4.66,  4.75,   nan,   nan,  0.  ],\n",
      "       [-2.72, -2.65,   nan,   nan,  0.  ],\n",
      "       [-0.79, -0.7 ,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 20\n",
      "[Network] Shape of weights: (20, 20)\n",
      "[Network] Shape of biases: (20,)\n",
      "[Network] Out pixels: 20\n",
      "[Network] Input pixels: 20\n",
      "[Network] Shape of weights: (20, 20)\n",
      "[Network] Shape of biases: (20,)\n",
      "[Network] Out pixels: 20\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 0.063729\n",
      "Time per LP neuron 0.010621\n",
      "LP used on 6 neurons.\n",
      "Median global rank: 0.181250\n",
      "Median tigthness of hat bounds: 0.101815 \n",
      "\n",
      "Min tigthness of hat bounds: 0.037151 \n",
      "\n",
      "Max tigthness of hat bounds: 0.173688 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.62, -0.56,  0.16,  0.36,  0.  ],\n",
      "       [-0.02,  0.04,  0.02,  0.  ,  1.  ],\n",
      "       [-0.52, -0.41,  0.34,  0.71,  0.  ],\n",
      "       [-1.07, -0.92,  0.03,  0.06,  0.  ],\n",
      "       [-0.86, -0.74,  0.17,  0.41,  0.  ],\n",
      "       [ 5.69,  5.83,  0.33,  0.66,  1.  ],\n",
      "       [ 1.65,  1.73,  0.59,  0.86,  1.  ],\n",
      "       [-0.55, -0.38,  0.07,  0.16,  0.  ],\n",
      "       [-0.63, -0.53,  0.06,  0.11,  0.  ],\n",
      "       [-0.15, -0.05,  0.09,  0.21,  0.  ],\n",
      "       [-0.03,  0.07,  0.61,  0.91,  1.  ],\n",
      "       [-0.27, -0.17,  0.19,  0.5 ,  0.  ],\n",
      "       [-0.69, -0.58,  0.18,  0.46,  0.  ],\n",
      "       [ 1.13,  1.22,  0.49,  0.81,  1.  ],\n",
      "       [ 4.91,  5.03,  0.24,  0.56,  1.  ],\n",
      "       [-0.19, -0.04,  0.25,  0.61,  0.  ],\n",
      "       [-1.17, -1.07,  0.11,  0.25,  0.  ],\n",
      "       [ 0.11,  0.15,  0.44,  0.75,  0.  ],\n",
      "       [-0.78, -0.61,  0.82,  0.96,  0.  ],\n",
      "       [ 1.44,  1.55,  0.14,  0.31,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 20\n",
      "[Network] Shape of weights: (20, 20)\n",
      "[Network] Shape of biases: (20,)\n",
      "[Network] Out pixels: 20\n",
      "[Network] Input pixels: 20\n",
      "[Network] Shape of weights: (20, 20)\n",
      "[Network] Shape of biases: (20,)\n",
      "[Network] Out pixels: 20\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 0.071544\n",
      "Time per LP neuron 0.011924\n",
      "LP used on 6 neurons.\n",
      "Median global rank: 0.600000\n",
      "Median tigthness of hat bounds: 0.073938 \n",
      "\n",
      "Min tigthness of hat bounds: 0.035714 \n",
      "\n",
      "Max tigthness of hat bounds: 0.191052 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.03,  0.07,  0.31,  0.21,  0.  ],\n",
      "       [ 0.01,  0.1 ,  0.41,  0.36,  0.  ],\n",
      "       [ 3.1 ,  3.19,  0.87,  0.81,  1.  ],\n",
      "       [ 0.76,  0.83,  0.39,  0.31,  0.  ],\n",
      "       [-0.45, -0.38,  0.37,  0.25,  0.  ],\n",
      "       [-0.34, -0.27,  0.68,  0.5 ,  0.  ],\n",
      "       [ 0.28,  0.34,  0.81,  0.71,  0.  ],\n",
      "       [ 2.44,  2.52,  0.22,  0.16,  0.  ],\n",
      "       [ 7.64,  7.83,  0.21,  0.11,  1.  ],\n",
      "       [-0.46, -0.39,  0.89,  0.86,  0.  ],\n",
      "       [-1.14, -1.03,  0.53,  0.46,  0.  ],\n",
      "       [-2.1 , -2.01,  0.86,  0.75,  0.  ],\n",
      "       [ 1.95,  2.02,  0.74,  0.61,  1.  ],\n",
      "       [ 1.23,  1.3 ,  0.43,  0.41,  0.  ],\n",
      "       [-0.52, -0.46,  0.69,  0.56,  0.  ],\n",
      "       [ 6.15,  6.31,  0.08,  0.06,  1.  ],\n",
      "       [ 0.16,  0.24,  0.97,  0.91,  0.  ],\n",
      "       [-2.11, -2.02,  0.99,  0.96,  0.  ],\n",
      "       [ 2.56,  2.62,  0.  ,  0.  ,  1.  ],\n",
      "       [ 0.05,  0.09,  0.78,  0.66,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 20\n",
      "[Network] Shape of weights: (20, 20)\n",
      "[Network] Shape of biases: (20,)\n",
      "[Network] Out pixels: 20\n",
      "[Network] Input pixels: 20\n",
      "[Network] Shape of weights: (20, 20)\n",
      "[Network] Shape of biases: (20,)\n",
      "[Network] Out pixels: 20\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 0.136064\n",
      "Time per LP neuron 0.022677\n",
      "LP used on 6 neurons.\n",
      "Median global rank: 0.587500\n",
      "Median tigthness of hat bounds: 0.149472 \n",
      "\n",
      "Min tigthness of hat bounds: 0.053729 \n",
      "\n",
      "Max tigthness of hat bounds: 0.252701 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-6.550e+00, -6.380e+00,  9.800e-01,  9.600e-01,  1.000e+00],\n",
      "       [-3.000e-01, -2.000e-01,  6.700e-01,  6.100e-01,  0.000e+00],\n",
      "       [-3.600e+00, -3.440e+00,  2.900e-01,  1.100e-01,  0.000e+00],\n",
      "       [-1.300e-01, -3.000e-02,  8.800e-01,  8.100e-01,  0.000e+00],\n",
      "       [ 4.810e+00,  4.910e+00,  4.800e-01,  3.100e-01,  1.000e+00],\n",
      "       [-1.890e+00, -1.730e+00,  8.300e-01,  7.500e-01,  0.000e+00],\n",
      "       [-3.290e+00, -3.090e+00,  6.300e-01,  5.600e-01,  0.000e+00],\n",
      "       [-6.000e-02, -1.000e-02,  7.900e-01,  7.100e-01,  1.000e+00],\n",
      "       [-2.910e+00, -2.770e+00,  2.300e-01,  6.000e-02,  0.000e+00],\n",
      "       [-9.000e-01, -6.800e-01,  4.600e-01,  2.500e-01,  0.000e+00],\n",
      "       [-1.030e+00, -7.800e-01,  3.600e-01,  2.100e-01,  0.000e+00],\n",
      "       [-3.070e+00, -2.910e+00,  7.100e-01,  6.600e-01,  0.000e+00],\n",
      "       [-5.900e-01, -4.800e-01,  6.200e-01,  5.000e-01,  0.000e+00],\n",
      "       [-1.610e+00, -1.470e+00,  9.300e-01,  9.100e-01,  0.000e+00],\n",
      "       [-3.380e+00, -3.210e+00,  9.100e-01,  8.600e-01,  0.000e+00],\n",
      "       [ 3.660e+00,  3.760e+00,  5.700e-01,  4.600e-01,  1.000e+00],\n",
      "       [ 9.880e+00,  1.012e+01,  5.400e-01,  3.600e-01,  1.000e+00],\n",
      "       [-1.600e+00, -1.400e+00,  5.600e-01,  4.100e-01,  0.000e+00],\n",
      "       [ 5.030e+00,  5.140e+00,  3.200e-01,  1.600e-01,  1.000e+00],\n",
      "       [-5.600e-01, -4.700e-01,  4.000e-02,  0.000e+00,  0.000e+00]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 20\n",
      "[Network] Shape of weights: (20, 20)\n",
      "[Network] Shape of biases: (20,)\n",
      "[Network] Out pixels: 20\n",
      "[Network] Input pixels: 20\n",
      "[Network] Shape of weights: (20, 20)\n",
      "[Network] Shape of biases: (20,)\n",
      "[Network] Out pixels: 20\n",
      "--------------------------\n",
      "Layerno: 4\n",
      "Time 0.047060\n",
      "Time per LP neuron 0.023530\n",
      "LP used on 2 neurons.\n",
      "Median global rank: 0.606250\n",
      "Median tigthness of hat bounds: 0.095414 \n",
      "\n",
      "Min tigthness of hat bounds: 0.030780 \n",
      "\n",
      "Max tigthness of hat bounds: 0.215551 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 2.63,  2.72,  0.28,  0.16,  0.  ],\n",
      "       [-1.45, -1.4 ,  0.94,  0.91,  0.  ],\n",
      "       [ 0.06,  0.16,  0.92,  0.86,  0.  ],\n",
      "       [-4.82, -4.71,  0.84,  0.81,  0.  ],\n",
      "       [-0.82, -0.72,  0.42,  0.25,  0.  ],\n",
      "       [-4.9 , -4.77,  0.38,  0.21,  0.  ],\n",
      "       [-1.09, -1.01,  0.72,  0.61,  0.  ],\n",
      "       [-3.04, -2.93,  0.12,  0.  ,  0.  ],\n",
      "       [-7.83, -7.63,  0.96,  0.96,  0.  ],\n",
      "       [-5.61, -5.44,  0.75,  0.71,  0.  ],\n",
      "       [-4.51, -4.39,  0.27,  0.11,  0.  ],\n",
      "       [-1.28, -1.25,  0.52,  0.41,  0.  ],\n",
      "       [-2.34, -2.28,  0.73,  0.66,  0.  ],\n",
      "       [-2.51, -2.42,  0.77,  0.75,  0.  ],\n",
      "       [-3.05, -2.98,  0.64,  0.5 ,  0.  ],\n",
      "       [ 3.9 ,  3.98,  0.5 ,  0.36,  1.  ],\n",
      "       [ 0.1 ,  0.2 ,  0.13,  0.06,  0.  ],\n",
      "       [-2.42, -2.34,  0.58,  0.46,  0.  ],\n",
      "       [ 8.82,  9.04,  0.66,  0.56,  1.  ],\n",
      "       [-2.57, -2.49,  0.47,  0.31,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 5\n",
      "Time 0.080875\n",
      "Time per LP neuron 0.008088\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: -0.805406 \n",
      "\n",
      "Min tigthness of hat bounds: -10.092971 \n",
      "\n",
      "Max tigthness of hat bounds: 3.088661 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.  , -4.29,   nan,   nan,  1.  ],\n",
      "       [10.1 ,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  2.49,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  0.84,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  0.13,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -2.27,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -4.71,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  3.09,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  2.93,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -1.73,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): 7.004310 \n",
      "\n",
      "Margin per LP neuron (more positve is better): 0.233477\n",
      "\n",
      "Margin per second (more positve is better):  16.233528\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "verified\n",
      "True label: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relu layers: 6\n",
      "Number of hidden layers: 6\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 0.042750\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.094487 \n",
      "\n",
      "Min tigthness of hat bounds: 0.075145 \n",
      "\n",
      "Max tigthness of hat bounds: 0.117509 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ -1.26,  -1.17,    nan,    nan,   0.  ],\n",
      "       [  7.8 ,   7.92,    nan,    nan,   0.  ],\n",
      "       [  6.54,   6.62,    nan,    nan,   0.  ],\n",
      "       [ -4.7 ,  -4.6 ,    nan,    nan,   0.  ],\n",
      "       [ -1.84,  -1.73,    nan,    nan,   0.  ],\n",
      "       [ -6.58,  -6.47,    nan,    nan,   0.  ],\n",
      "       [ -7.99,  -7.9 ,    nan,    nan,   0.  ],\n",
      "       [ -2.71,  -2.6 ,    nan,    nan,   0.  ],\n",
      "       [  1.41,   1.51,    nan,    nan,   0.  ],\n",
      "       [  8.43,   8.53,    nan,    nan,   0.  ],\n",
      "       [ -3.16,  -3.07,    nan,    nan,   0.  ],\n",
      "       [  4.95,   5.04,    nan,    nan,   0.  ],\n",
      "       [ -3.13,  -3.04,    nan,    nan,   0.  ],\n",
      "       [ -5.51,  -5.43,    nan,    nan,   0.  ],\n",
      "       [ -3.83,  -3.74,    nan,    nan,   0.  ],\n",
      "       [ -0.88,  -0.79,    nan,    nan,   0.  ],\n",
      "       [  2.08,   2.17,    nan,    nan,   0.  ],\n",
      "       [-12.64, -12.53,    nan,    nan,   0.  ],\n",
      "       [ -0.36,  -0.28,    nan,    nan,   0.  ],\n",
      "       [  0.23,   0.33,    nan,    nan,   0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 20\n",
      "[Network] Shape of weights: (20, 20)\n",
      "[Network] Shape of biases: (20,)\n",
      "[Network] Out pixels: 20\n",
      "[Network] Input pixels: 20\n",
      "[Network] Shape of weights: (20, 20)\n",
      "[Network] Shape of biases: (20,)\n",
      "[Network] Out pixels: 20\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 0.062262\n",
      "Time per LP neuron 0.010377\n",
      "LP used on 6 neurons.\n",
      "Median global rank: 0.181250\n",
      "Median tigthness of hat bounds: 0.126641 \n",
      "\n",
      "Min tigthness of hat bounds: 0.018877 \n",
      "\n",
      "Max tigthness of hat bounds: 0.275764 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.42, -1.34,  0.16,  0.36,  1.  ],\n",
      "       [-5.42, -5.21,  0.02,  0.  ,  0.  ],\n",
      "       [-1.09, -0.99,  0.34,  0.71,  0.  ],\n",
      "       [ 6.29,  6.4 ,  0.03,  0.06,  1.  ],\n",
      "       [ 8.97,  9.12,  0.17,  0.41,  1.  ],\n",
      "       [-3.9 , -3.81,  0.33,  0.66,  0.  ],\n",
      "       [-2.87, -2.77,  0.59,  0.86,  0.  ],\n",
      "       [-1.78, -1.62,  0.07,  0.16,  0.  ],\n",
      "       [ 4.17,  4.24,  0.06,  0.11,  1.  ],\n",
      "       [-3.71, -3.54,  0.09,  0.21,  0.  ],\n",
      "       [-5.28, -5.08,  0.61,  0.91,  0.  ],\n",
      "       [-2.01, -1.94,  0.19,  0.5 ,  0.  ],\n",
      "       [-1.7 , -1.55,  0.18,  0.46,  0.  ],\n",
      "       [-0.4 , -0.21,  0.49,  0.81,  0.  ],\n",
      "       [-4.05, -3.87,  0.24,  0.56,  0.  ],\n",
      "       [-3.83, -3.56,  0.25,  0.61,  0.  ],\n",
      "       [-0.85, -0.82,  0.11,  0.25,  1.  ],\n",
      "       [-0.04, -0.02,  0.44,  0.75,  1.  ],\n",
      "       [-5.16, -4.95,  0.82,  0.96,  0.  ],\n",
      "       [-3.56, -3.47,  0.14,  0.31,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 20\n",
      "[Network] Shape of weights: (20, 20)\n",
      "[Network] Shape of biases: (20,)\n",
      "[Network] Out pixels: 20\n",
      "[Network] Input pixels: 20\n",
      "[Network] Shape of weights: (20, 20)\n",
      "[Network] Shape of biases: (20,)\n",
      "[Network] Out pixels: 20\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 0.063302\n",
      "Time per LP neuron 0.010550\n",
      "LP used on 6 neurons.\n",
      "Median global rank: 0.600000\n",
      "Median tigthness of hat bounds: 0.057867 \n",
      "\n",
      "Min tigthness of hat bounds: 0.014787 \n",
      "\n",
      "Max tigthness of hat bounds: 0.113308 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.73, -0.72,  0.31,  0.21,  0.  ],\n",
      "       [-4.52, -4.43,  0.41,  0.36,  0.  ],\n",
      "       [ 4.37,  4.43,  0.87,  0.81,  1.  ],\n",
      "       [-1.79, -1.72,  0.39,  0.31,  0.  ],\n",
      "       [ 0.1 ,  0.13,  0.37,  0.25,  0.  ],\n",
      "       [-2.42, -2.38,  0.68,  0.5 ,  0.  ],\n",
      "       [ 1.26,  1.28,  0.81,  0.71,  0.  ],\n",
      "       [-2.68, -2.63,  0.22,  0.16,  0.  ],\n",
      "       [-3.21, -3.16,  0.21,  0.11,  0.  ],\n",
      "       [ 5.48,  5.56,  0.89,  0.86,  1.  ],\n",
      "       [-2.42, -2.36,  0.53,  0.46,  0.  ],\n",
      "       [ 0.2 ,  0.22,  0.86,  0.75,  1.  ],\n",
      "       [-3.29, -3.23,  0.74,  0.61,  0.  ],\n",
      "       [ 0.78,  0.81,  0.43,  0.41,  0.  ],\n",
      "       [-0.75, -0.69,  0.69,  0.56,  0.  ],\n",
      "       [-3.23, -3.17,  0.08,  0.06,  0.  ],\n",
      "       [ 3.83,  3.9 ,  0.97,  0.91,  1.  ],\n",
      "       [ 7.62,  7.73,  0.99,  0.96,  1.  ],\n",
      "       [-1.9 , -1.84,  0.  ,  0.  ,  0.  ],\n",
      "       [ 3.61,  3.65,  0.78,  0.66,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 20\n",
      "[Network] Shape of weights: (20, 20)\n",
      "[Network] Shape of biases: (20,)\n",
      "[Network] Out pixels: 20\n",
      "[Network] Input pixels: 20\n",
      "[Network] Shape of weights: (20, 20)\n",
      "[Network] Shape of biases: (20,)\n",
      "[Network] Out pixels: 20\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 0.165181\n",
      "Time per LP neuron 0.027530\n",
      "LP used on 6 neurons.\n",
      "Median global rank: 0.587500\n",
      "Median tigthness of hat bounds: 0.068913 \n",
      "\n",
      "Min tigthness of hat bounds: 0.019582 \n",
      "\n",
      "Max tigthness of hat bounds: 0.114283 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-3.54, -3.46,  0.98,  0.96,  0.  ],\n",
      "       [ 0.85,  0.9 ,  0.67,  0.61,  0.  ],\n",
      "       [-0.82, -0.74,  0.29,  0.11,  0.  ],\n",
      "       [ 3.92,  3.98,  0.88,  0.81,  1.  ],\n",
      "       [-2.15, -2.04,  0.48,  0.31,  0.  ],\n",
      "       [ 1.87,  1.9 ,  0.83,  0.75,  1.  ],\n",
      "       [-0.48, -0.4 ,  0.63,  0.56,  0.  ],\n",
      "       [ 4.26,  4.32,  0.79,  0.71,  1.  ],\n",
      "       [-2.19, -2.13,  0.23,  0.06,  0.  ],\n",
      "       [-2.8 , -2.74,  0.46,  0.25,  0.  ],\n",
      "       [ 0.58,  0.6 ,  0.36,  0.21,  1.  ],\n",
      "       [-5.99, -5.88,  0.71,  0.66,  0.  ],\n",
      "       [-2.1 , -2.03,  0.62,  0.5 ,  0.  ],\n",
      "       [ 1.31,  1.33,  0.93,  0.91,  1.  ],\n",
      "       [-5.84, -5.73,  0.91,  0.86,  0.  ],\n",
      "       [ 6.79,  6.9 ,  0.57,  0.46,  1.  ],\n",
      "       [-0.88, -0.81,  0.54,  0.36,  0.  ],\n",
      "       [-6.39, -6.28,  0.56,  0.41,  0.  ],\n",
      "       [-5.69, -5.6 ,  0.32,  0.16,  0.  ],\n",
      "       [-0.13, -0.07,  0.04,  0.  ,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 20\n",
      "[Network] Shape of weights: (20, 20)\n",
      "[Network] Shape of biases: (20,)\n",
      "[Network] Out pixels: 20\n",
      "[Network] Input pixels: 20\n",
      "[Network] Shape of weights: (20, 20)\n",
      "[Network] Shape of biases: (20,)\n",
      "[Network] Out pixels: 20\n",
      "--------------------------\n",
      "Layerno: 4\n",
      "Time 0.029364\n",
      "Time per LP neuron 0.014682\n",
      "LP used on 2 neurons.\n",
      "Median global rank: 0.606250\n",
      "Median tigthness of hat bounds: 0.050119 \n",
      "\n",
      "Min tigthness of hat bounds: 0.008103 \n",
      "\n",
      "Max tigthness of hat bounds: 0.094678 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-4.47, -4.39,  0.28,  0.16,  0.  ],\n",
      "       [-1.21, -1.18,  0.94,  0.91,  0.  ],\n",
      "       [ 0.45,  0.49,  0.92,  0.86,  0.  ],\n",
      "       [-2.53, -2.48,  0.84,  0.81,  0.  ],\n",
      "       [ 6.18,  6.27,  0.42,  0.25,  1.  ],\n",
      "       [-1.82, -1.75,  0.38,  0.21,  0.  ],\n",
      "       [-1.75, -1.66,  0.72,  0.61,  0.  ],\n",
      "       [-3.54, -3.46,  0.12,  0.  ,  0.  ],\n",
      "       [-2.11, -2.03,  0.96,  0.96,  0.  ],\n",
      "       [ 0.93,  0.94,  0.75,  0.71,  1.  ],\n",
      "       [-2.12, -2.06,  0.27,  0.11,  0.  ],\n",
      "       [-1.05, -1.02,  0.52,  0.41,  0.  ],\n",
      "       [-1.28, -1.25,  0.73,  0.66,  0.  ],\n",
      "       [-2.76, -2.67,  0.77,  0.75,  0.  ],\n",
      "       [-2.17, -2.14,  0.64,  0.5 ,  0.  ],\n",
      "       [-0.18, -0.15,  0.5 ,  0.36,  0.  ],\n",
      "       [ 0.99,  1.04,  0.13,  0.06,  0.  ],\n",
      "       [ 0.55,  0.58,  0.58,  0.46,  0.  ],\n",
      "       [-0.12, -0.07,  0.66,  0.56,  0.  ],\n",
      "       [-0.24, -0.21,  0.47,  0.31,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 5\n",
      "Time 0.054741\n",
      "Time per LP neuron 0.005474\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.097872 \n",
      "\n",
      "Min tigthness of hat bounds: -6.391774 \n",
      "\n",
      "Max tigthness of hat bounds: 1.951687 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 6.4 ,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -4.36,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  0.8 ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -0.01,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -3.52,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  1.96,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  0.62,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  1.08,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -2.84,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  0.22,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): 4.440087 \n",
      "\n",
      "Margin per LP neuron (more positve is better): 0.148003\n",
      "\n",
      "Margin per second (more positve is better):  10.632420\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'time': [0.042749643325805664,\n",
       "  0.06226205825805664,\n",
       "  0.06330156326293945,\n",
       "  0.16518068313598633,\n",
       "  0.029363632202148438,\n",
       "  0.05474138259887695],\n",
       " 'LB_hat': [array([ -1.26549334,   7.79631979,   6.53588223,  -4.70052856,\n",
       "          -1.84236632,  -6.58231054,  -7.99787284,  -2.71496696,\n",
       "           1.40617831,   8.4212984 ,  -3.16152067,   4.94829639,\n",
       "          -3.13571021,  -5.51140898,  -3.83282426,  -0.88180955,\n",
       "           2.07318787, -12.64210322,  -0.36338058,   0.22995437]),\n",
       "  array([-1.42051807, -5.42877403, -1.0961845 ,  6.2877356 ,  8.9673463 ,\n",
       "         -3.9073478 , -2.87461919, -1.78269081,  4.16404499, -3.71106275,\n",
       "         -5.28039444, -2.01104371, -1.70291204, -0.40627105, -4.05005136,\n",
       "         -3.83682073, -0.85056194, -0.04025076, -5.16081344, -3.56168882]),\n",
       "  array([-0.73816649, -4.52844373,  4.36188344, -1.794051  ,  0.0954157 ,\n",
       "         -2.42610735,  1.25077603, -2.68432905, -3.21925747,  5.47647721,\n",
       "         -2.4290538 ,  0.19288418, -3.29416781,  0.77548775, -0.75256349,\n",
       "         -3.23477947,  3.82474315,  7.61604265, -1.90327693,  3.60301575]),\n",
       "  array([-3.54682021,  0.8450139 , -0.82078774,  3.91047957, -2.15247403,\n",
       "          1.86702906, -0.48462219,  4.2567985 , -2.193562  , -2.80966761,\n",
       "          0.57527257, -5.99637276, -2.10319106,  1.3028133 , -5.84725887,\n",
       "          6.78801889, -0.88003003, -6.39671399, -5.69541356, -0.13595128]),\n",
       "  array([-4.47983912, -1.2180316 ,  0.44521687, -2.53727478,  6.17266053,\n",
       "         -1.82252173, -1.75203245, -3.54280474, -2.11054322,  0.92604392,\n",
       "         -2.12215571, -1.05865119, -1.28936554, -2.76482639, -2.17868586,\n",
       "         -0.18317947,  0.98241042,  0.54545641, -0.12275911, -0.24174221]),\n",
       "  array([6.39177426, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ])],\n",
       " 'UB_hat': [array([ -1.17124703,   7.91382858,   6.61990488,  -4.60124735,\n",
       "          -1.73030913,  -6.47899859,  -7.90603671,  -2.60733965,\n",
       "           1.50335569,   8.52330289,  -3.07220904,   5.03112562,\n",
       "          -3.04253861,  -5.43174253,  -3.74517361,  -0.79585329,\n",
       "           2.16939173, -12.5390785 ,  -0.28823524,   0.32468218]),\n",
       "  array([-1.3419137 , -5.21796102, -0.99419164,  6.39540707,  9.11473466,\n",
       "         -3.81243977, -2.77199373, -1.62638875,  4.23443813, -3.54670072,\n",
       "         -5.08113196, -1.94579634, -1.55730158, -0.21164951, -3.87153225,\n",
       "         -3.56105713, -0.82523122, -0.02137346, -4.95835509, -3.47857529]),\n",
       "  array([-0.7233798 , -4.43472093,  4.42707681, -1.7291708 ,  0.12041543,\n",
       "         -2.38563396,  1.27573157, -2.63538963, -3.16507822,  5.55380008,\n",
       "         -2.36326503,  0.2115642 , -3.2330621 ,  0.80193627, -0.69212404,\n",
       "         -3.17724269,  3.89929976,  7.72935114, -1.8450788 ,  3.64844185]),\n",
       "  array([-3.46604444,  0.89050215, -0.7431984 ,  3.9702225 , -2.04877784,\n",
       "          1.89358545, -0.40077277,  4.31515824, -2.131597  , -2.74901955,\n",
       "          0.59485501, -5.88620198, -2.03487386,  1.32594128, -5.73461211,\n",
       "          6.89037521, -0.81052044, -6.28243068, -5.60485077, -0.0711935 ]),\n",
       "  array([-4.39978697, -1.18627529,  0.48179341, -2.48474364,  6.26316004,\n",
       "         -1.75062858, -1.66042966, -3.46462467, -2.03176322,  0.93414686,\n",
       "         -2.06966603, -1.02251338, -1.25077392, -2.67014881, -2.14099426,\n",
       "         -0.15625749,  1.0399142 ,  0.57884334, -0.07501142, -0.21635129]),\n",
       "  array([0.        , 0.        , 0.79552876, 0.        , 0.        ,\n",
       "         1.95168688, 0.61189154, 1.07898203, 0.        , 0.21486805])],\n",
       " 'use_LP': [array([False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False]),\n",
       "  array([ True, False, False,  True,  True, False, False, False,  True,\n",
       "         False, False, False, False, False, False, False,  True,  True,\n",
       "         False, False]),\n",
       "  array([False, False,  True, False, False, False, False, False, False,\n",
       "          True, False,  True, False, False, False, False,  True,  True,\n",
       "         False,  True]),\n",
       "  array([False, False, False,  True, False,  True, False,  True, False,\n",
       "         False,  True, False, False,  True, False,  True, False, False,\n",
       "         False, False]),\n",
       "  array([False, False, False, False,  True, False, False, False, False,\n",
       "          True, False, False, False, False, False, False, False, False,\n",
       "         False, False]),\n",
       "  array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True])],\n",
       " 'local_rank': [array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan]),\n",
       "  array([0.35, 0.  , 0.7 , 0.05, 0.4 , 0.65, 0.85, 0.15, 0.1 , 0.2 , 0.9 ,\n",
       "         0.5 , 0.45, 0.8 , 0.55, 0.6 , 0.25, 0.75, 0.95, 0.3 ]),\n",
       "  array([0.2 , 0.35, 0.8 , 0.3 , 0.25, 0.5 , 0.7 , 0.15, 0.1 , 0.85, 0.45,\n",
       "         0.75, 0.6 , 0.4 , 0.55, 0.05, 0.9 , 0.95, 0.  , 0.65]),\n",
       "  array([0.95, 0.6 , 0.1 , 0.8 , 0.3 , 0.75, 0.55, 0.7 , 0.05, 0.25, 0.2 ,\n",
       "         0.65, 0.5 , 0.9 , 0.85, 0.45, 0.35, 0.4 , 0.15, 0.  ]),\n",
       "  array([0.15, 0.9 , 0.85, 0.8 , 0.25, 0.2 , 0.6 , 0.  , 0.95, 0.7 , 0.1 ,\n",
       "         0.4 , 0.65, 0.75, 0.5 , 0.35, 0.05, 0.45, 0.55, 0.3 ]),\n",
       "  array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])],\n",
       " 'global_rank': [array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan]),\n",
       "  array([0.15  , 0.0125, 0.3375, 0.025 , 0.1625, 0.325 , 0.5875, 0.0625,\n",
       "         0.05  , 0.0875, 0.6   , 0.1875, 0.175 , 0.4875, 0.2375, 0.25  ,\n",
       "         0.1   , 0.4375, 0.8125, 0.1375]),\n",
       "  array([0.3   , 0.4   , 0.8625, 0.3875, 0.3625, 0.675 , 0.8   , 0.2125,\n",
       "         0.2   , 0.8875, 0.525 , 0.85  , 0.7375, 0.425 , 0.6875, 0.075 ,\n",
       "         0.9625, 0.9875, 0.    , 0.775 ]),\n",
       "  array([0.975 , 0.6625, 0.2875, 0.875 , 0.475 , 0.825 , 0.625 , 0.7875,\n",
       "         0.225 , 0.45  , 0.35  , 0.7   , 0.6125, 0.925 , 0.9   , 0.5625,\n",
       "         0.5375, 0.55  , 0.3125, 0.0375]),\n",
       "  array([0.275 , 0.9375, 0.9125, 0.8375, 0.4125, 0.375 , 0.7125, 0.1125,\n",
       "         0.95  , 0.75  , 0.2625, 0.5125, 0.725 , 0.7625, 0.6375, 0.5   ,\n",
       "         0.125 , 0.575 , 0.65  , 0.4625]),\n",
       "  array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])],\n",
       " 'margin': [4.440087375713492],\n",
       " 'margin_per_neuron': [0.1480029125237831],\n",
       " 'margin_per_time': [10.632419549404098],\n",
       " 'tightness_hat': [array([0.09424631, 0.11750879, 0.08402265, 0.09928122, 0.11205719,\n",
       "         0.10331195, 0.09183613, 0.10762731, 0.09717738, 0.1020045 ,\n",
       "         0.08931164, 0.08282923, 0.0931716 , 0.07966645, 0.08765065,\n",
       "         0.08595626, 0.09620386, 0.10302472, 0.07514533, 0.09472781]),\n",
       "  array([0.07860437, 0.21081302, 0.10199287, 0.10767147, 0.14738837,\n",
       "         0.09490802, 0.10262546, 0.15630206, 0.07039313, 0.16436203,\n",
       "         0.19926248, 0.06524737, 0.14561046, 0.19462154, 0.1785191 ,\n",
       "         0.2757636 , 0.02533073, 0.0188773 , 0.20245835, 0.08311354]),\n",
       "  array([0.01478669, 0.0937228 , 0.06519337, 0.0648802 , 0.02499973,\n",
       "         0.04047339, 0.02495553, 0.04893942, 0.05417925, 0.07732287,\n",
       "         0.06578877, 0.01868003, 0.06110571, 0.02644852, 0.06043945,\n",
       "         0.05753678, 0.07455661, 0.1133085 , 0.05819814, 0.0454261 ]),\n",
       "  array([0.08077577, 0.04548825, 0.07758934, 0.05974293, 0.10369619,\n",
       "         0.02655639, 0.08384943, 0.05835974, 0.06196499, 0.06064806,\n",
       "         0.01958244, 0.11017078, 0.0683172 , 0.02312798, 0.11264676,\n",
       "         0.10235632, 0.06950959, 0.11428331, 0.09056279, 0.06475777]),\n",
       "  array([0.08005216, 0.03175631, 0.03657654, 0.05253114, 0.09049952,\n",
       "         0.07189315, 0.09160279, 0.07818007, 0.07878   , 0.00810295,\n",
       "         0.05248968, 0.0361378 , 0.03859162, 0.09467758, 0.0376916 ,\n",
       "         0.02692198, 0.05750378, 0.03338693, 0.04774768, 0.02539091]),\n",
       "  array([-6.39177426, -4.36800585,  0.79552876, -0.01912407, -3.52070023,\n",
       "          1.95168688,  0.61189154,  1.07898203, -2.84009746,  0.21486805])],\n",
       " 'min_tightness_hat': [0.07514533057344241,\n",
       "  0.018877300624378424,\n",
       "  0.014786691971878985,\n",
       "  0.01958243570440832,\n",
       "  0.008102946989802406,\n",
       "  -6.391774260323512],\n",
       " 'max_tightness_hat': [0.1175087878876564,\n",
       "  0.275763596253209,\n",
       "  0.11330849969980505,\n",
       "  0.11428330989540925,\n",
       "  0.0946775779794522,\n",
       "  1.9516868846100195],\n",
       " 'median_tightness_hat': [0.09448706275679808,\n",
       "  0.12664096428313687,\n",
       "  0.05786745712295349,\n",
       "  0.06891339812861358,\n",
       "  0.05011868394501584,\n",
       "  0.09787199070229526]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbose=True\n",
    "analyse_nn_and_write('mnist_relu_6_20', [2, 10] , 0.001, verbose=verbose, global_rank_threshold=[0.0, 0.0],\n",
    "                    local_rank_threshold=[0.0,0.0], tightness_threshold=[0.0, 0.0], influence_threshold=[0.3, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "imgs = [10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Ranking function axis=0 But still wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', imgs , 0.001, global_rank_threshold=[0.0,0.0], local_rank_threshold=[0.3, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Corrected Ranking Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.694447\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 338.267094\n",
      "Time per LP neuron 1.098270\n",
      "LP used on 308 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.436088 \n",
      "\n",
      "Min tigthness of hat bounds: 0.019571 \n",
      "\n",
      "Max tigthness of hat bounds: 0.528724 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.54, -0.51,  0.14,  0.2 ,  1.  ],\n",
      "       [-0.69, -0.25,  0.84,  0.85,  0.  ],\n",
      "       [-1.77, -1.34,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.12, -0.1 ,  0.08,  0.11,  1.  ],\n",
      "       [ 0.26,  0.29,  0.09,  0.13,  1.  ],\n",
      "       [-0.32,  0.14,  0.78,  0.81,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 368.039694\n",
      "Time per LP neuron 3.573201\n",
      "LP used on 103 neurons.\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 3.989023 \n",
      "\n",
      "Min tigthness of hat bounds: 0.237382 \n",
      "\n",
      "Max tigthness of hat bounds: 4.569254 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-2.89,  0.95,  0.35,  0.27,  0.  ],\n",
      "       [-2.71,  1.38,  0.79,  0.76,  0.  ],\n",
      "       [-2.71,  1.27,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-2.17,  1.71,  0.4 ,  0.31,  0.  ],\n",
      "       [-1.82,  2.06,  0.22,  0.15,  0.  ],\n",
      "       [-1.12,  2.83,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 42.659178\n",
      "Time per LP neuron 4.265918\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 18.186769 \n",
      "\n",
      "Min tigthness of hat bounds: -2.034917 \n",
      "\n",
      "Max tigthness of hat bounds: 31.453386 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 2.04,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 16.88,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 31.46,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 18.77,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  9.28,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 17.91,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 18.48,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 23.97,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 16.88,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 31.08,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -29.418469 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.069878\n",
      "\n",
      "Margin per second (more positve is better):  -0.039190\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', imgs , 0.001, global_rank_threshold=[0.0,0.0], \n",
    "                             local_rank_threshold=[0.3, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Corrected Ranking function with TIIIGTHNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.745458\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 405.985557\n",
      "Time per LP neuron 1.318135\n",
      "LP used on 308 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.431785 \n",
      "\n",
      "Min tigthness of hat bounds: 0.021689 \n",
      "\n",
      "Max tigthness of hat bounds: 0.455365 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.54, -0.51,  0.14,  0.2 ,  1.  ],\n",
      "       [-0.69, -0.25,  0.84,  0.85,  0.  ],\n",
      "       [-1.77, -1.34,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.33,  0.11,  0.08,  0.11,  0.  ],\n",
      "       [ 0.05,  0.49,  0.09,  0.13,  0.  ],\n",
      "       [-0.1 , -0.07,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 476.678958\n",
      "Time per LP neuron 4.627951\n",
      "LP used on 103 neurons.\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 3.652740 \n",
      "\n",
      "Min tigthness of hat bounds: 0.263047 \n",
      "\n",
      "Max tigthness of hat bounds: 3.867064 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-2.79,  0.82,  0.35,  0.27,  0.  ],\n",
      "       [-2.42,  1.14,  0.79,  0.76,  0.  ],\n",
      "       [-2.57,  1.07,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-2.02,  1.58,  0.4 ,  0.31,  0.  ],\n",
      "       [-1.67,  1.88,  0.22,  0.15,  0.  ],\n",
      "       [-0.93,  2.63,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 59.710725\n",
      "Time per LP neuron 5.971073\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 14.873692 \n",
      "\n",
      "Min tigthness of hat bounds: -4.949995 \n",
      "\n",
      "Max tigthness of hat bounds: 28.913334 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 4.95,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 14.15,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 28.92,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 16.01,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  6.3 ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 13.94,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 15.61,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 20.21,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 13.71,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 27.36,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -23.963339 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.056920\n",
      "\n",
      "Margin per second (more positve is better):  -0.025382\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', imgs , 0.001, global_rank_threshold=[0.0,0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.3,0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Corrected Ranking function with Influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.767830\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 335.412481\n",
      "Time per LP neuron 1.089002\n",
      "LP used on 308 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.431877 \n",
      "\n",
      "Min tigthness of hat bounds: 0.020786 \n",
      "\n",
      "Max tigthness of hat bounds: 0.490808 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.54, -0.51,  0.14,  0.2 ,  1.  ],\n",
      "       [-0.69, -0.25,  0.84,  0.85,  0.  ],\n",
      "       [-1.77, -1.34,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.12, -0.1 ,  0.08,  0.11,  1.  ],\n",
      "       [ 0.05,  0.49,  0.09,  0.13,  0.  ],\n",
      "       [-0.32,  0.14,  0.78,  0.81,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 377.108374\n",
      "Time per LP neuron 3.661246\n",
      "LP used on 103 neurons.\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 3.678186 \n",
      "\n",
      "Min tigthness of hat bounds: 0.253563 \n",
      "\n",
      "Max tigthness of hat bounds: 4.056960 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-2.79,  0.8 ,  0.35,  0.27,  0.  ],\n",
      "       [-2.5 ,  1.18,  0.79,  0.76,  0.  ],\n",
      "       [-2.59,  1.1 ,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-2.01,  1.57,  0.4 ,  0.31,  0.  ],\n",
      "       [-1.71,  1.94,  0.22,  0.15,  0.  ],\n",
      "       [-1.01,  2.68,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 54.250365\n",
      "Time per LP neuron 5.425037\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 14.784302 \n",
      "\n",
      "Min tigthness of hat bounds: -5.328301 \n",
      "\n",
      "Max tigthness of hat bounds: 28.214818 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 5.33,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 13.77,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 28.2 ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 15.56,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  6.61,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 14.02,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 16.13,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 21.57,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 13.05,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 28.22,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -22.886517 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.054362\n",
      "\n",
      "Margin per second (more positve is better):  -0.029779\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', imgs , 0.001, global_rank_threshold=[0.0,0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.0,0.0],\n",
    "                            influence_threshold=[0.3, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 2.580826\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 122.311486\n",
      "Time per LP neuron 1.187490\n",
      "LP used on 103 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.441551 \n",
      "\n",
      "Min tigthness of hat bounds: 0.022292 \n",
      "\n",
      "Max tigthness of hat bounds: 0.493608 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.54, -0.51,  0.14,  0.2 ,  1.  ],\n",
      "       [-0.69, -0.25,  0.84,  0.85,  0.  ],\n",
      "       [-1.77, -1.34,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.33,  0.11,  0.08,  0.11,  0.  ],\n",
      "       [ 0.05,  0.49,  0.09,  0.13,  0.  ],\n",
      "       [-0.32,  0.14,  0.78,  0.81,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 1131.500196\n",
      "Time per LP neuron 3.673702\n",
      "LP used on 308 neurons.\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 4.796317 \n",
      "\n",
      "Min tigthness of hat bounds: 0.323525 \n",
      "\n",
      "Max tigthness of hat bounds: 5.252499 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-3.39,  1.41,  0.35,  0.27,  0.  ],\n",
      "       [-3.1 ,  1.8 ,  0.79,  0.76,  0.  ],\n",
      "       [-3.17,  1.73,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-2.55,  2.11,  0.4 ,  0.31,  0.  ],\n",
      "       [-2.28,  2.51,  0.22,  0.15,  0.  ],\n",
      "       [-1.55,  3.3 ,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 45.424923\n",
      "Time per LP neuron 4.542492\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 16.929433 \n",
      "\n",
      "Min tigthness of hat bounds: -3.704969 \n",
      "\n",
      "Max tigthness of hat bounds: 30.739605 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 3.71,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 16.48,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 30.25,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 17.39,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  9.65,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 15.15,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 18.41,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 24.52,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 15.51,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 30.74,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -27.034636 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.064215\n",
      "\n",
      "Margin per second (more positve is better):  -0.020767\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', imgs , 0.001, global_rank_threshold=[0.0,0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.0,0.0],\n",
    "                            influence_threshold=[0.1, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.741887\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 424.538470\n",
      "Time per LP neuron 1.035460\n",
      "LP used on 410 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.425926 \n",
      "\n",
      "Min tigthness of hat bounds: 0.020767 \n",
      "\n",
      "Max tigthness of hat bounds: 0.478136 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.54, -0.51,  0.14,  0.2 ,  1.  ],\n",
      "       [-0.69, -0.25,  0.84,  0.85,  0.  ],\n",
      "       [-1.77, -1.34,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.12, -0.1 ,  0.08,  0.11,  1.  ],\n",
      "       [ 0.26,  0.29,  0.09,  0.13,  1.  ],\n",
      "       [-0.32,  0.14,  0.78,  0.81,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 6.934154\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 3.268862 \n",
      "\n",
      "Min tigthness of hat bounds: 2.921551 \n",
      "\n",
      "Max tigthness of hat bounds: 3.698277 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-2.56,  0.59,  0.35,  0.27,  0.  ],\n",
      "       [-2.26,  0.93,  0.79,  0.76,  0.  ],\n",
      "       [-2.39,  0.9 ,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.79,  1.36,  0.4 ,  0.31,  0.  ],\n",
      "       [-1.47,  1.69,  0.22,  0.15,  0.  ],\n",
      "       [-0.81,  2.47,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 40.811424\n",
      "Time per LP neuron 4.081142\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 14.154064 \n",
      "\n",
      "Min tigthness of hat bounds: -6.225681 \n",
      "\n",
      "Max tigthness of hat bounds: 27.277953 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 6.23,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 12.29,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 27.28,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 15.05,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  5.01,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 13.56,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 14.76,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 19.31,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 12.62,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 26.33,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -21.052272 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.050124\n",
      "\n",
      "Margin per second (more positve is better):  -0.044412\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', imgs , 0.001, global_rank_threshold=[0.0,0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.0,0.0],\n",
    "                            influence_threshold=[0.4, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.828523\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 495.623662\n",
      "Time per LP neuron 0.968015\n",
      "LP used on 512 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.220781 \n",
      "\n",
      "Min tigthness of hat bounds: 0.020767 \n",
      "\n",
      "Max tigthness of hat bounds: 0.478136 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.54, -0.51,  0.14,  0.2 ,  1.  ],\n",
      "       [-0.69, -0.25,  0.84,  0.85,  0.  ],\n",
      "       [-1.77, -1.34,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.12, -0.1 ,  0.08,  0.11,  1.  ],\n",
      "       [ 0.26,  0.29,  0.09,  0.13,  1.  ],\n",
      "       [-0.1 , -0.07,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 7.137535\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 2.754658 \n",
      "\n",
      "Min tigthness of hat bounds: 2.443247 \n",
      "\n",
      "Max tigthness of hat bounds: 3.132260 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-2.32,  0.31,  0.35,  0.27,  0.  ],\n",
      "       [-2.  ,  0.7 ,  0.79,  0.76,  0.  ],\n",
      "       [-2.1 ,  0.61,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.59,  1.14,  0.4 ,  0.31,  0.  ],\n",
      "       [-1.2 ,  1.42,  0.22,  0.15,  0.  ],\n",
      "       [-0.51,  2.19,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 40.414592\n",
      "Time per LP neuron 4.041459\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 9.386118 \n",
      "\n",
      "Min tigthness of hat bounds: -11.121960 \n",
      "\n",
      "Max tigthness of hat bounds: 22.874664 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[11.13,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  7.69,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 22.88,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 10.26,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  0.69,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  8.52,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 10.83,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 14.93,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  8.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 21.51,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -11.752704 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.022515\n",
      "\n",
      "Margin per second (more positve is better):  -0.021564\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', imgs , 0.001, global_rank_threshold=[0.0,0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.0,0.0],\n",
    "                            influence_threshold=[0.5, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.761425\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 586.068258\n",
      "Time per LP neuron 0.952957\n",
      "LP used on 615 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.029674 \n",
      "\n",
      "Min tigthness of hat bounds: 0.020495 \n",
      "\n",
      "Max tigthness of hat bounds: 0.464000 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.54, -0.51,  0.14,  0.2 ,  1.  ],\n",
      "       [-0.69, -0.25,  0.84,  0.85,  0.  ],\n",
      "       [-1.77, -1.34,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.12, -0.1 ,  0.08,  0.11,  1.  ],\n",
      "       [ 0.26,  0.29,  0.09,  0.13,  1.  ],\n",
      "       [-0.1 , -0.07,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 7.070687\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 2.195117 \n",
      "\n",
      "Min tigthness of hat bounds: 1.915730 \n",
      "\n",
      "Max tigthness of hat bounds: 2.500451 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-2.02,  0.02,  0.35,  0.27,  0.  ],\n",
      "       [-1.7 ,  0.43,  0.79,  0.76,  0.  ],\n",
      "       [-1.82,  0.34,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.34,  0.91,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.96,  1.19,  0.22,  0.15,  0.  ],\n",
      "       [-0.25,  1.9 ,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 37.433036\n",
      "Time per LP neuron 3.743304\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 4.490270 \n",
      "\n",
      "Min tigthness of hat bounds: -16.249693 \n",
      "\n",
      "Max tigthness of hat bounds: 18.496300 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[16.25,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  3.09,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 18.5 ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  5.38,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -3.61,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  3.61,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  6.96,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 10.5 ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  3.34,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 16.75,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -2.246607 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.003595\n",
      "\n",
      "Margin per second (more positve is better):  -0.003553\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', imgs , 0.001, global_rank_threshold=[0.0,0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.0,0.0],\n",
    "                            influence_threshold=[0.6, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 2.341876\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 930.011757\n",
      "Time per LP neuron 1.297088\n",
      "LP used on 717 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.027883 \n",
      "\n",
      "Min tigthness of hat bounds: 0.019571 \n",
      "\n",
      "Max tigthness of hat bounds: 0.462919 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.54, -0.51,  0.14,  0.2 ,  1.  ],\n",
      "       [-0.69, -0.25,  0.84,  0.85,  0.  ],\n",
      "       [-1.77, -1.34,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.12, -0.1 ,  0.08,  0.11,  1.  ],\n",
      "       [ 0.26,  0.29,  0.09,  0.13,  1.  ],\n",
      "       [-0.1 , -0.07,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 7.352720\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 1.688981 \n",
      "\n",
      "Min tigthness of hat bounds: 1.460180 \n",
      "\n",
      "Max tigthness of hat bounds: 1.998842 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.79, -0.18,  0.35,  0.27,  0.  ],\n",
      "       [-1.47,  0.21,  0.79,  0.76,  0.  ],\n",
      "       [-1.56,  0.07,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.08,  0.68,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.7 ,  0.9 ,  0.22,  0.15,  0.  ],\n",
      "       [-0.  ,  1.64,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "GurobiError",
     "evalue": "Out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGurobiError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-1669cd086496>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m stats = analyse_nn_and_write('mnist_relu_4_1024', [10,2] , 0.001, global_rank_threshold=[0.0,0.0], \n\u001b[1;32m      2\u001b[0m                              \u001b[0mlocal_rank_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtightness_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                             influence_threshold=[0.7, 0.0])\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-826053fd8549>\u001b[0m in \u001b[0;36manalyse_nn_and_write\u001b[0;34m(net_code, img_nrs, epsilon, log_file, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mLB_hidden_box_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUB_hidden_box_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLB_NN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUB_NN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperform_box_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLB_N0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUB_N0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         LB_NN, UB_NN, stats = perform_linear_layerwise(nn, numlayer, LB_N0, UB_N0, lp_list,\n\u001b[0;32m---> 55\u001b[0;31m                                      LB_hidden_box_list, UB_hidden_box_list, label, verbose=verbose, **kwargs)\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Check if NN was verified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverified_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverify_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLB_N0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUB_N0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLB_NN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUB_NN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_input_pixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLB_N0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_out_pixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-c30ef9fd6247>\u001b[0m in \u001b[0;36mperform_linear_layerwise\u001b[0;34m(nn, numlayer, LB_N0, UB_N0, lp_list, LB_hidden_box_list, UB_hidden_box_list, true_label, global_rank_threshold, local_rank_threshold, tightness_threshold, influence_threshold, verbose)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;31m# LB: Get lower bound of correct label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mLB_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_linear_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayerno\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlb_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;31m# UB: Get upper bound of all other labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-56778e1b7fba>\u001b[0m in \u001b[0;36mcall_linear_solver\u001b[0;34m(model, z_hat, lb_only, ub_only)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetObjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGRB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMINIMIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGRB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmodel.pxi\u001b[0m in \u001b[0;36mgurobipy.Model.optimize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mGurobiError\u001b[0m: Out of memory"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', [10,2] , 0.001, global_rank_threshold=[0.0,0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.0,0.0],\n",
    "                            influence_threshold=[0.7, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.721893\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 295.680515\n",
      "Time per LP neuron 0.960002\n",
      "LP used on 308 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.431877 \n",
      "\n",
      "Min tigthness of hat bounds: 0.020786 \n",
      "\n",
      "Max tigthness of hat bounds: 0.490808 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.54, -0.51,  0.14,  0.2 ,  1.  ],\n",
      "       [-0.69, -0.25,  0.84,  0.85,  0.  ],\n",
      "       [-1.77, -1.34,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.12, -0.1 ,  0.08,  0.11,  1.  ],\n",
      "       [ 0.05,  0.49,  0.09,  0.13,  0.  ],\n",
      "       [-0.32,  0.14,  0.78,  0.81,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 347.707394\n",
      "Time per LP neuron 3.219513\n",
      "LP used on 108 neurons.\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 3.678186 \n",
      "\n",
      "Min tigthness of hat bounds: 0.242044 \n",
      "\n",
      "Max tigthness of hat bounds: 4.056960 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-2.79,  0.8 ,  0.35,  0.27,  0.  ],\n",
      "       [-2.5 ,  1.18,  0.79,  0.76,  0.  ],\n",
      "       [-2.59,  1.1 ,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-2.01,  1.57,  0.4 ,  0.31,  0.  ],\n",
      "       [-1.71,  1.94,  0.22,  0.15,  0.  ],\n",
      "       [-1.01,  2.68,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 40.807098\n",
      "Time per LP neuron 4.080710\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 14.700016 \n",
      "\n",
      "Min tigthness of hat bounds: -5.442847 \n",
      "\n",
      "Max tigthness of hat bounds: 28.122246 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 5.45,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 13.59,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 28.13,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 15.48,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  6.59,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 13.93,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 16.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 21.54,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 12.94,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 28.09,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -22.679400 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.053238\n",
      "\n",
      "Margin per second (more positve is better):  -0.033064\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', imgs , 0.001, global_rank_threshold=[0.001,0.01], \n",
    "                             local_rank_threshold=[0.001, 0.01], tightness_threshold=[0.001,0.01],\n",
    "                            influence_threshold=[0.3, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Again Fixed weights and added relu inactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 2.014191\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 430.476153\n",
      "Time per LP neuron 1.024943\n",
      "LP used on 420 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.426491 \n",
      "\n",
      "Min tigthness of hat bounds: 0.020193 \n",
      "\n",
      "Max tigthness of hat bounds: 0.528724 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.54, -0.51,  0.14,  0.2 ,  1.  ],\n",
      "       [-0.48, -0.46,  0.84,  0.85,  1.  ],\n",
      "       [-1.57, -1.54,  1.  ,  1.  ,  1.  ],\n",
      "       ...,\n",
      "       [-0.12, -0.1 ,  0.08,  0.11,  1.  ],\n",
      "       [ 0.26,  0.29,  0.09,  0.13,  1.  ],\n",
      "       [-0.32,  0.14,  0.78,  0.81,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 378.556773\n",
      "Time per LP neuron 3.675308\n",
      "LP used on 103 neurons.\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 4.731693 \n",
      "\n",
      "Min tigthness of hat bounds: 0.277060 \n",
      "\n",
      "Max tigthness of hat bounds: 5.504386 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.14, -0.84,  0.35,  0.27,  1.  ],\n",
      "       [-3.02,  1.69,  0.79,  0.76,  0.  ],\n",
      "       [-3.1 ,  1.66,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-2.49,  2.04,  0.4 ,  0.31,  0.  ],\n",
      "       [-2.2 ,  2.43,  0.22,  0.15,  0.  ],\n",
      "       [-1.47,  3.18,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 45.186026\n",
      "Time per LP neuron 4.518603\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 24.270306 \n",
      "\n",
      "Min tigthness of hat bounds: 4.497138 \n",
      "\n",
      "Max tigthness of hat bounds: 38.648403 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-4.49,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 23.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 38.3 ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 26.1 ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 15.41,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 24.83,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 23.72,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 30.29,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 23.06,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 38.65,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -43.145541 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.080948\n",
      "\n",
      "Margin per second (more positve is better):  -0.050390\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', [10] , 0.001, global_rank_threshold=[0.1, 0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.1, 0.0],\n",
    "                            influence_threshold=[0.3, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.729687\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 530.498190\n",
      "Time per LP neuron 1.048415\n",
      "LP used on 506 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.411058 \n",
      "\n",
      "Min tigthness of hat bounds: 0.020193 \n",
      "\n",
      "Max tigthness of hat bounds: 0.528724 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.54, -0.51,  0.14,  0.2 ,  1.  ],\n",
      "       [-0.48, -0.46,  0.84,  0.85,  1.  ],\n",
      "       [-1.57, -1.54,  1.  ,  1.  ,  1.  ],\n",
      "       ...,\n",
      "       [-0.12, -0.1 ,  0.08,  0.11,  1.  ],\n",
      "       [ 0.26,  0.29,  0.09,  0.13,  1.  ],\n",
      "       [-0.32,  0.14,  0.78,  0.81,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 7.020243\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 4.748591 \n",
      "\n",
      "Min tigthness of hat bounds: 4.147215 \n",
      "\n",
      "Max tigthness of hat bounds: 5.504386 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-3.26,  1.29,  0.35,  0.27,  0.  ],\n",
      "       [-3.02,  1.69,  0.79,  0.76,  0.  ],\n",
      "       [-3.1 ,  1.66,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-2.49,  2.04,  0.4 ,  0.31,  0.  ],\n",
      "       [-2.2 ,  2.43,  0.22,  0.15,  0.  ],\n",
      "       [-1.47,  3.18,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 42.225708\n",
      "Time per LP neuron 4.222571\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 27.817152 \n",
      "\n",
      "Min tigthness of hat bounds: 8.169720 \n",
      "\n",
      "Max tigthness of hat bounds: 41.371048 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-8.16,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 26.48,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 41.06,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 29.79,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 18.41,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 28.66,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 26.98,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 32.94,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 26.5 ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 41.38,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -49.540767 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.096009\n",
      "\n",
      "Margin per second (more positve is better):  -0.085199\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', [10] , 0.001, global_rank_threshold=[0.1, 0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.1, 0.0],\n",
    "                            influence_threshold=[0.4, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.749041\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 575.825227\n",
      "Time per LP neuron 0.972678\n",
      "LP used on 592 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.028887 \n",
      "\n",
      "Min tigthness of hat bounds: 0.019571 \n",
      "\n",
      "Max tigthness of hat bounds: 0.528724 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.54, -0.51,  0.14,  0.2 ,  1.  ],\n",
      "       [-0.48, -0.46,  0.84,  0.85,  1.  ],\n",
      "       [-1.57, -1.54,  1.  ,  1.  ,  1.  ],\n",
      "       ...,\n",
      "       [-0.12, -0.1 ,  0.08,  0.11,  1.  ],\n",
      "       [ 0.26,  0.29,  0.09,  0.13,  1.  ],\n",
      "       [-0.32,  0.14,  0.78,  0.81,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 6.998552\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 4.328299 \n",
      "\n",
      "Min tigthness of hat bounds: 3.737614 \n",
      "\n",
      "Max tigthness of hat bounds: 4.990821 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-3.07,  1.07,  0.35,  0.27,  0.  ],\n",
      "       [-2.78,  1.47,  0.79,  0.76,  0.  ],\n",
      "       [-2.89,  1.45,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-2.23,  1.81,  0.4 ,  0.31,  0.  ],\n",
      "       [-1.98,  2.16,  0.22,  0.15,  0.  ],\n",
      "       [-1.24,  2.98,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 41.998918\n",
      "Time per LP neuron 4.199892\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 23.869348 \n",
      "\n",
      "Min tigthness of hat bounds: 4.097075 \n",
      "\n",
      "Max tigthness of hat bounds: 37.006058 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-4.09,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 22.44,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 37.01,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 25.57,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 14.54,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 24.37,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 23.38,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 28.97,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 22.51,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 36.98,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -41.103133 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.068278\n",
      "\n",
      "Margin per second (more positve is better):  -0.065600\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', [10] , 0.001, global_rank_threshold=[0.1, 0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.1, 0.0],\n",
    "                            influence_threshold=[0.5, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.747272\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 652.014636\n",
      "Time per LP neuron 0.960257\n",
      "LP used on 679 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.027294 \n",
      "\n",
      "Min tigthness of hat bounds: 0.019571 \n",
      "\n",
      "Max tigthness of hat bounds: 0.523947 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.54, -0.51,  0.14,  0.2 ,  1.  ],\n",
      "       [-0.48, -0.46,  0.84,  0.85,  1.  ],\n",
      "       [-1.57, -1.54,  1.  ,  1.  ,  1.  ],\n",
      "       ...,\n",
      "       [-0.12, -0.1 ,  0.08,  0.11,  1.  ],\n",
      "       [ 0.26,  0.29,  0.09,  0.13,  1.  ],\n",
      "       [-0.32,  0.14,  0.78,  0.81,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 7.007844\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 3.533015 \n",
      "\n",
      "Min tigthness of hat bounds: 3.056756 \n",
      "\n",
      "Max tigthness of hat bounds: 4.032804 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-2.71,  0.7 ,  0.35,  0.27,  0.  ],\n",
      "       [-2.37,  1.1 ,  0.79,  0.76,  0.  ],\n",
      "       [-2.5 ,  1.05,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.85,  1.42,  0.4 ,  0.31,  0.  ],\n",
      "       [-1.59,  1.75,  0.22,  0.15,  0.  ],\n",
      "       [-0.89,  2.6 ,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 39.624728\n",
      "Time per LP neuron 3.962473\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 16.581075 \n",
      "\n",
      "Min tigthness of hat bounds: -3.606012 \n",
      "\n",
      "Max tigthness of hat bounds: 29.569726 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 3.61,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 14.76,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 29.57,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 17.56,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  7.26,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 16.33,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 16.85,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 21.61,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 15.06,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 28.89,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -25.963715 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.037683\n",
      "\n",
      "Margin per second (more positve is better):  -0.037070\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', [10] , 0.001, global_rank_threshold=[0.1, 0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.1, 0.0],\n",
    "                            influence_threshold=[0.6, 0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changed weights back to old definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.866492\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 366.662338\n",
      "Time per LP neuron 0.918953\n",
      "LP used on 399 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.428329 \n",
      "\n",
      "Min tigthness of hat bounds: 0.020193 \n",
      "\n",
      "Max tigthness of hat bounds: 0.528724 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.54, -0.51,  0.14,  0.2 ,  1.  ],\n",
      "       [-0.69, -0.25,  0.84,  0.85,  0.  ],\n",
      "       [-1.77, -1.34,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.12, -0.1 ,  0.08,  0.11,  1.  ],\n",
      "       [ 0.26,  0.29,  0.09,  0.13,  1.  ],\n",
      "       [-0.32,  0.14,  0.78,  0.81,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 7.128605\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 4.748591 \n",
      "\n",
      "Min tigthness of hat bounds: 4.147215 \n",
      "\n",
      "Max tigthness of hat bounds: 5.504386 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-3.26,  1.29,  0.35,  0.27,  0.  ],\n",
      "       [-3.02,  1.69,  0.79,  0.76,  0.  ],\n",
      "       [-3.1 ,  1.66,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-2.49,  2.04,  0.4 ,  0.31,  0.  ],\n",
      "       [-2.2 ,  2.43,  0.22,  0.15,  0.  ],\n",
      "       [-1.47,  3.18,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 37.694541\n",
      "Time per LP neuron 3.769454\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 27.817152 \n",
      "\n",
      "Min tigthness of hat bounds: 8.169720 \n",
      "\n",
      "Max tigthness of hat bounds: 41.371048 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-8.16,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 26.48,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 41.06,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 29.79,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 18.41,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 28.66,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 26.98,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 32.94,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 26.5 ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 41.38,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -49.540767 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.121127\n",
      "\n",
      "Margin per second (more positve is better):  -0.119851\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', [10] , 0.001, global_rank_threshold=[0.1, 0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.1, 0.0],\n",
    "                            influence_threshold=[0.3, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changed weights to layerno and fixed relu inactive constrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.906172\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 384.298464\n",
      "Time per LP neuron 0.937313\n",
      "LP used on 410 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.426953 \n",
      "\n",
      "Min tigthness of hat bounds: 0.020193 \n",
      "\n",
      "Max tigthness of hat bounds: 0.520876 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.76, -0.29,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.69, -0.25,  0.84,  0.85,  0.  ],\n",
      "       [-1.77, -1.34,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.12, -0.1 ,  0.08,  0.11,  1.  ],\n",
      "       [ 0.26,  0.29,  0.09,  0.13,  1.  ],\n",
      "       [-0.1 , -0.07,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 7.311157\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 2.154604 \n",
      "\n",
      "Min tigthness of hat bounds: 1.836197 \n",
      "\n",
      "Max tigthness of hat bounds: 2.468414 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-2.06,  0.09,  0.35,  0.27,  0.  ],\n",
      "       [-1.7 ,  0.38,  0.79,  0.76,  0.  ],\n",
      "       [-1.82,  0.32,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.24,  0.86,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.97,  1.17,  0.22,  0.15,  0.  ],\n",
      "       [-0.22,  1.88,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 38.146877\n",
      "Time per LP neuron 3.814688\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 4.143962 \n",
      "\n",
      "Min tigthness of hat bounds: -16.625279 \n",
      "\n",
      "Max tigthness of hat bounds: 18.185820 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[16.63,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  2.75,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 18.19,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  5.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -4.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  3.29,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  6.68,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 10.12,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  2.96,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 16.42,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -1.560541 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.003716\n",
      "\n",
      "Margin per second (more positve is better):  -0.003615\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', [10] , 0.001, global_rank_threshold=[0.1, 0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.1, 0.0],\n",
    "                            influence_threshold=[0.3, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 2.676781\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 300.788319\n",
      "Time per LP neuron 0.976585\n",
      "LP used on 308 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.431853 \n",
      "\n",
      "Min tigthness of hat bounds: 0.022332 \n",
      "\n",
      "Max tigthness of hat bounds: 0.520876 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.76, -0.29,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.69, -0.25,  0.84,  0.85,  0.  ],\n",
      "       [-1.77, -1.34,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.12, -0.1 ,  0.08,  0.11,  1.  ],\n",
      "       [ 0.26,  0.29,  0.09,  0.13,  1.  ],\n",
      "       [-0.1 , -0.07,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 7.100679\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 2.452202 \n",
      "\n",
      "Min tigthness of hat bounds: 2.080734 \n",
      "\n",
      "Max tigthness of hat bounds: 2.768520 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-2.2 ,  0.22,  0.35,  0.27,  0.  ],\n",
      "       [-1.81,  0.52,  0.79,  0.76,  0.  ],\n",
      "       [-1.99,  0.48,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.37,  1.  ,  0.4 ,  0.31,  0.  ],\n",
      "       [-1.12,  1.3 ,  0.22,  0.15,  0.  ],\n",
      "       [-0.36,  2.02,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 37.930262\n",
      "Time per LP neuron 3.793026\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 6.681516 \n",
      "\n",
      "Min tigthness of hat bounds: -13.923144 \n",
      "\n",
      "Max tigthness of hat bounds: 20.426221 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[13.93,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  5.07,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 20.43,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  7.52,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -1.76,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  5.85,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  8.66,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 12.41,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  5.36,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 18.86,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -6.503077 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.020450\n",
      "\n",
      "Margin per second (more positve is better):  -0.018660\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', [10] , 0.001, global_rank_threshold=[0.0, 0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.0, 0.0],\n",
    "                            influence_threshold=[0.3, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.656990\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 289.094816\n",
      "Time per LP neuron 0.938620\n",
      "LP used on 308 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.431853 \n",
      "\n",
      "Min tigthness of hat bounds: 0.022332 \n",
      "\n",
      "Max tigthness of hat bounds: 0.520876 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.76, -0.29,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.69, -0.25,  0.84,  0.85,  0.  ],\n",
      "       [-1.77, -1.34,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.12, -0.1 ,  0.08,  0.11,  1.  ],\n",
      "       [ 0.26,  0.29,  0.09,  0.13,  1.  ],\n",
      "       [-0.1 , -0.07,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 352.964176\n",
      "Time per LP neuron 3.426837\n",
      "LP used on 103 neurons.\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 2.428728 \n",
      "\n",
      "Min tigthness of hat bounds: 0.195598 \n",
      "\n",
      "Max tigthness of hat bounds: 2.730754 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-2.2 ,  0.22,  0.35,  0.27,  0.  ],\n",
      "       [-1.81,  0.52,  0.79,  0.76,  0.  ],\n",
      "       [-1.99,  0.48,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.37,  1.  ,  0.4 ,  0.31,  0.  ],\n",
      "       [-1.12,  1.3 ,  0.22,  0.15,  0.  ],\n",
      "       [-0.36,  2.02,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 35.734900\n",
      "Time per LP neuron 3.573490\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 4.641263 \n",
      "\n",
      "Min tigthness of hat bounds: -17.092680 \n",
      "\n",
      "Max tigthness of hat bounds: 18.283290 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[17.1 ,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  3.04,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 18.29,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  5.45,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -3.48,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  3.3 ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  7.03,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 10.04,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  3.84,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 17.  ,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -1.190610 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.002828\n",
      "\n",
      "Margin per second (more positve is better):  -0.001752\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', [10] , 0.001, global_rank_threshold=[0.0, 0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.0, 0.0],\n",
    "                            influence_threshold=[0.3, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.649722\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 374.888990\n",
      "Time per LP neuron 0.914363\n",
      "LP used on 410 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.425993 \n",
      "\n",
      "Min tigthness of hat bounds: 0.021092 \n",
      "\n",
      "Max tigthness of hat bounds: 0.520876 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.76, -0.29,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.69, -0.25,  0.84,  0.85,  0.  ],\n",
      "       [-1.77, -1.34,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.12, -0.1 ,  0.08,  0.11,  1.  ],\n",
      "       [ 0.26,  0.29,  0.09,  0.13,  1.  ],\n",
      "       [-0.1 , -0.07,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 6.918139\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 1.523202 \n",
      "\n",
      "Min tigthness of hat bounds: 1.312911 \n",
      "\n",
      "Max tigthness of hat bounds: 1.762755 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.73, -0.29,  0.35,  0.27,  0.  ],\n",
      "       [-1.34,  0.07,  0.79,  0.76,  0.  ],\n",
      "       [-1.49,  0.01,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-0.88,  0.54,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.69,  0.83,  0.22,  0.15,  0.  ],\n",
      "       [ 0.15,  1.52,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 35.542764\n",
      "Time per LP neuron 3.554276\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: -0.704665 \n",
      "\n",
      "Min tigthness of hat bounds: -21.948649 \n",
      "\n",
      "Max tigthness of hat bounds: 14.082527 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[21.95,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -1.71,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 14.09,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  0.11,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -8.03,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -1.51,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  2.92,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  5.73,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -1.53,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 11.87,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): 7.866122 \n",
      "\n",
      "Margin per LP neuron (more positve is better): 0.018729\n",
      "\n",
      "Margin per second (more positve is better):   0.018774\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', [10] , 0.001, global_rank_threshold=[0.0, 0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.0, 0.0],\n",
    "                            influence_threshold=[0.4, 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.663882\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 371.824993\n",
      "Time per LP neuron 0.906890\n",
      "LP used on 410 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.425772 \n",
      "\n",
      "Min tigthness of hat bounds: 0.021092 \n",
      "\n",
      "Max tigthness of hat bounds: 0.520876 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.76, -0.29,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.69, -0.25,  0.84,  0.85,  0.  ],\n",
      "       [-1.77, -1.34,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.12, -0.1 ,  0.08,  0.11,  1.  ],\n",
      "       [ 0.26,  0.29,  0.09,  0.13,  1.  ],\n",
      "       [-0.1 , -0.07,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 6.794238\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 1.571152 \n",
      "\n",
      "Min tigthness of hat bounds: 1.363239 \n",
      "\n",
      "Max tigthness of hat bounds: 1.797143 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.75, -0.25,  0.35,  0.27,  0.  ],\n",
      "       [-1.39,  0.11,  0.79,  0.76,  0.  ],\n",
      "       [-1.5 , -0.01,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-0.92,  0.55,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.73,  0.88,  0.22,  0.15,  0.  ],\n",
      "       [ 0.11,  1.57,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 33.186808\n",
      "Time per LP neuron 3.318681\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: -0.375760 \n",
      "\n",
      "Min tigthness of hat bounds: -21.564214 \n",
      "\n",
      "Max tigthness of hat bounds: 14.361338 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[21.57,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -1.46,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 14.37,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  0.49,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -7.73,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -1.23,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  3.12,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  6.05,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -1.27,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 12.15,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): 7.202876 \n",
      "\n",
      "Margin per LP neuron (more positve is better): 0.017150\n",
      "\n",
      "Margin per second (more positve is better):   0.017421\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', [10] , 0.001, global_rank_threshold=[0.0, 0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.4, 0.0],\n",
    "                            influence_threshold=[0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.634518\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 99.113219\n",
      "Time per LP neuron 0.962264\n",
      "LP used on 103 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.441514 \n",
      "\n",
      "Min tigthness of hat bounds: 0.023956 \n",
      "\n",
      "Max tigthness of hat bounds: 0.520876 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.76, -0.29,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.69, -0.25,  0.84,  0.85,  0.  ],\n",
      "       [-1.77, -1.34,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.33,  0.11,  0.08,  0.11,  0.  ],\n",
      "       [ 0.05,  0.49,  0.09,  0.13,  0.  ],\n",
      "       [-0.1 , -0.07,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 945.456269\n",
      "Time per LP neuron 3.069663\n",
      "LP used on 308 neurons.\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 4.276797 \n",
      "\n",
      "Min tigthness of hat bounds: 0.298292 \n",
      "\n",
      "Max tigthness of hat bounds: 4.793890 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-3.14,  1.16,  0.35,  0.27,  0.  ],\n",
      "       [-2.86,  1.57,  0.79,  0.76,  0.  ],\n",
      "       [-0.9 , -0.59,  0.49,  0.41,  1.  ],\n",
      "       ...,\n",
      "       [-2.35,  1.89,  0.4 ,  0.31,  0.  ],\n",
      "       [-2.04,  2.25,  0.22,  0.15,  0.  ],\n",
      "       [-1.29,  3.02,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 36.966294\n",
      "Time per LP neuron 3.696629\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 12.095018 \n",
      "\n",
      "Min tigthness of hat bounds: -10.097073 \n",
      "\n",
      "Max tigthness of hat bounds: 26.568699 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[10.1 ,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 11.01,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 26.57,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 12.99,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  4.44,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 10.83,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 14.76,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 17.51,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 11.21,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 24.85,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -16.471626 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.039125\n",
      "\n",
      "Margin per second (more positve is better):  -0.015207\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', [10] , 0.001, global_rank_threshold=[0.0, 0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.0, 0.0],\n",
    "                            influence_threshold=[0.1, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.668581\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030266 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025867 \n",
      "\n",
      "Max tigthness of hat bounds: 0.040032 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.55, -0.52,   nan,   nan,  0.  ],\n",
      "       [-0.02,  0.01,   nan,   nan,  0.  ],\n",
      "       [-0.51, -0.48,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 1.49,  1.52,   nan,   nan,  0.  ],\n",
      "       [-0.76, -0.73,   nan,   nan,  0.  ],\n",
      "       [ 0.7 ,  0.73,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 388.825625\n",
      "Time per LP neuron 1.083080\n",
      "LP used on 359 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.429208 \n",
      "\n",
      "Min tigthness of hat bounds: 0.021724 \n",
      "\n",
      "Max tigthness of hat bounds: 0.520876 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.76, -0.29,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.69, -0.25,  0.84,  0.85,  0.  ],\n",
      "       [-1.77, -1.34,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.12, -0.1 ,  0.08,  0.11,  1.  ],\n",
      "       [ 0.26,  0.29,  0.09,  0.13,  1.  ],\n",
      "       [-0.1 , -0.07,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 8.182064\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 2.000357 \n",
      "\n",
      "Min tigthness of hat bounds: 1.677569 \n",
      "\n",
      "Max tigthness of hat bounds: 2.280475 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.99, -0.02,  0.35,  0.27,  0.  ],\n",
      "       [-1.59,  0.29,  0.79,  0.76,  0.  ],\n",
      "       [-1.73,  0.23,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.16,  0.8 ,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.91,  1.05,  0.22,  0.15,  0.  ],\n",
      "       [-0.13,  1.79,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 43.457385\n",
      "Time per LP neuron 4.345739\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 2.828087 \n",
      "\n",
      "Min tigthness of hat bounds: -17.983221 \n",
      "\n",
      "Max tigthness of hat bounds: 17.110820 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[17.99,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  1.55,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 17.12,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  3.69,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -5.03,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  1.97,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  5.68,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  8.95,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  1.75,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 15.17,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): 0.872401 \n",
      "\n",
      "Margin per LP neuron (more positve is better): 0.002364\n",
      "\n",
      "Margin per second (more positve is better):   0.001973\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', [10] , 0.001, global_rank_threshold=[0.0, 0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.0, 0.0],\n",
    "                            influence_threshold=[0.35, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 7\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.974612\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.028662 \n",
      "\n",
      "Min tigthness of hat bounds: 0.024511 \n",
      "\n",
      "Max tigthness of hat bounds: 0.037791 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.12,  0.15,   nan,   nan,  0.  ],\n",
      "       [-0.15, -0.13,   nan,   nan,  0.  ],\n",
      "       [-0.72, -0.69,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [-0.79, -0.76,   nan,   nan,  0.  ],\n",
      "       [-0.8 , -0.77,   nan,   nan,  0.  ],\n",
      "       [-0.28, -0.26,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 451.199348\n",
      "Time per LP neuron 1.100486\n",
      "LP used on 410 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.390560 \n",
      "\n",
      "Min tigthness of hat bounds: 0.021139 \n",
      "\n",
      "Max tigthness of hat bounds: 0.478294 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.88, -0.45,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.16, -0.13,  0.84,  0.85,  1.  ],\n",
      "       [-1.25, -0.85,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.65, -0.25,  0.08,  0.11,  0.  ],\n",
      "       [-0.44, -0.04,  0.09,  0.13,  0.  ],\n",
      "       [ 0.92,  0.95,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 8.433702\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 1.352781 \n",
      "\n",
      "Min tigthness of hat bounds: 1.143859 \n",
      "\n",
      "Max tigthness of hat bounds: 1.549728 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.29,  0.97,  0.35,  0.27,  0.  ],\n",
      "       [-2.28, -1.03,  0.79,  0.76,  0.  ],\n",
      "       [ 0.5 ,  1.95,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.42, -0.18,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.48,  0.85,  0.22,  0.15,  0.  ],\n",
      "       [ 0.33,  1.77,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 41.518299\n",
      "Time per LP neuron 4.151830\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.613855 \n",
      "\n",
      "Min tigthness of hat bounds: -22.203407 \n",
      "\n",
      "Max tigthness of hat bounds: 14.505220 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[  0.  ,  -0.97,    nan,    nan,   1.  ],\n",
      "       [  0.  ,   8.67,    nan,    nan,   1.  ],\n",
      "       [  0.  ,   5.8 ,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  14.51,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -2.37,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -2.51,    nan,    nan,   1.  ],\n",
      "       [  0.  , -18.69,    nan,    nan,   1.  ],\n",
      "       [ 22.21,   0.  ,    nan,    nan,   1.  ],\n",
      "       [  0.  ,   2.2 ,    nan,    nan,   1.  ],\n",
      "       [  0.  ,   9.68,    nan,    nan,   1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): 7.698187 \n",
      "\n",
      "Margin per LP neuron (more positve is better): 0.018329\n",
      "\n",
      "Margin per second (more positve is better):   0.015301\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "verified\n",
      "True label: 2\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 2.056749\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030278 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025749 \n",
      "\n",
      "Max tigthness of hat bounds: 0.039281 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.17, -0.14,   nan,   nan,  0.  ],\n",
      "       [ 0.22,  0.25,   nan,   nan,  0.  ],\n",
      "       [ 0.15,  0.18,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 0.38,  0.41,   nan,   nan,  0.  ],\n",
      "       [ 0.64,  0.67,   nan,   nan,  0.  ],\n",
      "       [-0.21, -0.18,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 413.842026\n",
      "Time per LP neuron 1.009371\n",
      "LP used on 410 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.425051 \n",
      "\n",
      "Min tigthness of hat bounds: 0.021679 \n",
      "\n",
      "Max tigthness of hat bounds: 0.523857 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-2.22, -1.75,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.95, -0.49,  0.84,  0.85,  0.  ],\n",
      "       [ 0.32,  0.35,  1.  ,  1.  ,  1.  ],\n",
      "       ...,\n",
      "       [-0.9 , -0.46,  0.08,  0.11,  0.  ],\n",
      "       [ 1.18,  1.21,  0.09,  0.13,  1.  ],\n",
      "       [ 1.  ,  1.03,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 6.957399\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 1.557620 \n",
      "\n",
      "Min tigthness of hat bounds: 1.325259 \n",
      "\n",
      "Max tigthness of hat bounds: 1.773674 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.44,  0.98,  0.35,  0.27,  0.  ],\n",
      "       [-0.23,  1.24,  0.79,  0.76,  0.  ],\n",
      "       [-0.87,  0.62,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-0.6 ,  0.89,  0.4 ,  0.31,  0.  ],\n",
      "       [-1.2 ,  0.4 ,  0.22,  0.15,  0.  ],\n",
      "       [ 0.16,  1.58,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 36.209640\n",
      "Time per LP neuron 3.620964\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.196293 \n",
      "\n",
      "Min tigthness of hat bounds: -21.689132 \n",
      "\n",
      "Max tigthness of hat bounds: 19.625053 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[  0.  ,   6.6 ,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  16.39,    nan,    nan,   1.  ],\n",
      "       [ 21.69,   0.  ,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  19.63,    nan,    nan,   1.  ],\n",
      "       [  0.  , -12.57,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -1.65,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -4.14,    nan,    nan,   1.  ],\n",
      "       [  0.  ,   2.06,    nan,    nan,   1.  ],\n",
      "       [  0.  ,   3.17,    nan,    nan,   1.  ],\n",
      "       [  0.  , -11.6 ,    nan,    nan,   1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): 2.064079 \n",
      "\n",
      "Margin per LP neuron (more positve is better): 0.004914\n",
      "\n",
      "Margin per second (more positve is better):   0.004496\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "verified\n",
      "True label: 1\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 2.556459\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.026938 \n",
      "\n",
      "Min tigthness of hat bounds: 0.023142 \n",
      "\n",
      "Max tigthness of hat bounds: 0.034755 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.88, -0.85,   nan,   nan,  0.  ],\n",
      "       [-0.12, -0.09,   nan,   nan,  0.  ],\n",
      "       [-0.06, -0.03,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 0.57,  0.6 ,   nan,   nan,  0.  ],\n",
      "       [ 0.26,  0.29,   nan,   nan,  0.  ],\n",
      "       [-0.13, -0.11,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 427.371011\n",
      "Time per LP neuron 1.042368\n",
      "LP used on 410 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.355094 \n",
      "\n",
      "Min tigthness of hat bounds: 0.021380 \n",
      "\n",
      "Max tigthness of hat bounds: 0.427107 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.51, -1.12,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.65, -0.27,  0.84,  0.85,  0.  ],\n",
      "       [-0.11,  0.25,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.41, -0.03,  0.08,  0.11,  0.  ],\n",
      "       [ 0.22,  0.24,  0.09,  0.13,  1.  ],\n",
      "       [ 0.27,  0.3 ,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 7.442212\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 1.657892 \n",
      "\n",
      "Min tigthness of hat bounds: 1.437870 \n",
      "\n",
      "Max tigthness of hat bounds: 1.885328 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.6 ,  0.93,  0.35,  0.27,  0.  ],\n",
      "       [-1.  ,  0.6 ,  0.79,  0.76,  0.  ],\n",
      "       [ 0.6 ,  2.2 ,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-0.7 ,  0.85,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.44,  1.19,  0.22,  0.15,  0.  ],\n",
      "       [-0.74,  0.9 ,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 43.445123\n",
      "Time per LP neuron 4.344512\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 3.835737 \n",
      "\n",
      "Min tigthness of hat bounds: -13.132006 \n",
      "\n",
      "Max tigthness of hat bounds: 16.812895 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.  ,  0.05,   nan,   nan,  1.  ],\n",
      "       [13.14,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  9.85,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  5.91,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  8.86,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  1.77,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  1.44,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 16.82,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  7.05,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  0.61,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -3.680889 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.008764\n",
      "\n",
      "Margin per second (more positve is better):  -0.007656\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n",
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.985544\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.031261 \n",
      "\n",
      "Min tigthness of hat bounds: 0.026475 \n",
      "\n",
      "Max tigthness of hat bounds: 0.041886 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.85,  0.88,   nan,   nan,  0.  ],\n",
      "       [ 0.21,  0.24,   nan,   nan,  0.  ],\n",
      "       [-0.04, -0.01,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [-0.47, -0.43,   nan,   nan,  0.  ],\n",
      "       [-0.84, -0.81,   nan,   nan,  0.  ],\n",
      "       [-0.46, -0.43,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 485.917437\n",
      "Time per LP neuron 1.185164\n",
      "LP used on 410 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.418281 \n",
      "\n",
      "Min tigthness of hat bounds: 0.020855 \n",
      "\n",
      "Max tigthness of hat bounds: 0.503625 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.27, -0.8 ,  0.14,  0.2 ,  0.  ],\n",
      "       [ 0.35,  0.37,  0.84,  0.85,  1.  ],\n",
      "       [-0.72, -0.29,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-1.09, -0.66,  0.08,  0.11,  0.  ],\n",
      "       [ 0.39,  0.42,  0.09,  0.13,  1.  ],\n",
      "       [ 1.62,  1.65,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 8.151884\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 1.365929 \n",
      "\n",
      "Min tigthness of hat bounds: 1.174035 \n",
      "\n",
      "Max tigthness of hat bounds: 1.556282 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.01,  1.25,  0.35,  0.27,  0.  ],\n",
      "       [-1.25,  0.02,  0.79,  0.76,  0.  ],\n",
      "       [-0.47,  0.89,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.17,  0.19,  0.4 ,  0.31,  0.  ],\n",
      "       [-1.17,  0.27,  0.22,  0.15,  0.  ],\n",
      "       [-0.33,  0.94,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 39.283166\n",
      "Time per LP neuron 3.928317\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 1.904320 \n",
      "\n",
      "Min tigthness of hat bounds: -17.457846 \n",
      "\n",
      "Max tigthness of hat bounds: 10.365143 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[17.46,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  2.64,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  7.77,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 10.37,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -6.87,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  4.45,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -0.31,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  4.45,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -5.37,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  1.17,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): 7.092703 \n",
      "\n",
      "Margin per LP neuron (more positve is better): 0.016887\n",
      "\n",
      "Margin per second (more positve is better):   0.013249\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "verified\n",
      "True label: 4\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 2.951723\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.028790 \n",
      "\n",
      "Min tigthness of hat bounds: 0.024641 \n",
      "\n",
      "Max tigthness of hat bounds: 0.037223 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.12,  0.15,   nan,   nan,  0.  ],\n",
      "       [ 0.25,  0.28,   nan,   nan,  0.  ],\n",
      "       [-0.48, -0.45,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 0.33,  0.36,   nan,   nan,  0.  ],\n",
      "       [-1.18, -1.16,   nan,   nan,  0.  ],\n",
      "       [-0.36, -0.33,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 424.139941\n",
      "Time per LP neuron 1.034488\n",
      "LP used on 410 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.385320 \n",
      "\n",
      "Min tigthness of hat bounds: 0.020441 \n",
      "\n",
      "Max tigthness of hat bounds: 0.474239 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.59, -1.18,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.19, -0.17,  0.84,  0.85,  1.  ],\n",
      "       [-0.6 , -0.2 ,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.15, -0.13,  0.08,  0.11,  1.  ],\n",
      "       [ 0.54,  0.56,  0.09,  0.13,  1.  ],\n",
      "       [-0.42, -0.  ,  0.78,  0.81,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 8.067580\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 1.633350 \n",
      "\n",
      "Min tigthness of hat bounds: 1.427082 \n",
      "\n",
      "Max tigthness of hat bounds: 1.852822 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.96,  0.63,  0.35,  0.27,  0.  ],\n",
      "       [-0.11,  1.46,  0.79,  0.76,  0.  ],\n",
      "       [-0.61,  1.09,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.58,  0.09,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.04,  1.55,  0.22,  0.15,  0.  ],\n",
      "       [-0.29,  1.3 ,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 43.709466\n",
      "Time per LP neuron 4.370947\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 3.626352 \n",
      "\n",
      "Min tigthness of hat bounds: -7.125844 \n",
      "\n",
      "Max tigthness of hat bounds: 19.021404 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.  ,  6.65,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  3.58,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  3.68,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -0.23,   nan,   nan,  1.  ],\n",
      "       [ 7.13,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -3.4 ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  0.44,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 16.01,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  6.68,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 19.03,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -11.895560 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.028323\n",
      "\n",
      "Margin per second (more positve is better):  -0.024841\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 1\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.763222\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.027634 \n",
      "\n",
      "Min tigthness of hat bounds: 0.023654 \n",
      "\n",
      "Max tigthness of hat bounds: 0.036135 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.96, -0.93,   nan,   nan,  0.  ],\n",
      "       [-0.09, -0.07,   nan,   nan,  0.  ],\n",
      "       [ 0.02,  0.05,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 0.6 ,  0.63,   nan,   nan,  0.  ],\n",
      "       [ 0.34,  0.37,   nan,   nan,  0.  ],\n",
      "       [-0.15, -0.12,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 405.398152\n",
      "Time per LP neuron 0.988776\n",
      "LP used on 410 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.364371 \n",
      "\n",
      "Min tigthness of hat bounds: 0.020421 \n",
      "\n",
      "Max tigthness of hat bounds: 0.437571 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.79, -1.39,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.78, -0.39,  0.84,  0.85,  0.  ],\n",
      "       [ 0.11,  0.13,  1.  ,  1.  ,  1.  ],\n",
      "       ...,\n",
      "       [-0.49, -0.11,  0.08,  0.11,  0.  ],\n",
      "       [ 0.05,  0.07,  0.09,  0.13,  1.  ],\n",
      "       [ 0.38,  0.41,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 7.196353\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 1.370385 \n",
      "\n",
      "Min tigthness of hat bounds: 1.162803 \n",
      "\n",
      "Max tigthness of hat bounds: 1.552155 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.44,  0.85,  0.35,  0.27,  0.  ],\n",
      "       [-1.13,  0.16,  0.79,  0.76,  0.  ],\n",
      "       [ 1.45,  2.78,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-0.53,  0.75,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.06,  1.24,  0.22,  0.15,  0.  ],\n",
      "       [-0.6 ,  0.79,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 34.375601\n",
      "Time per LP neuron 3.437560\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: -0.243852 \n",
      "\n",
      "Min tigthness of hat bounds: -24.844971 \n",
      "\n",
      "Max tigthness of hat bounds: 19.915077 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.  , -4.23,   nan,   nan,  1.  ],\n",
      "       [24.85,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  2.24,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  2.15,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  9.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -6.55,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -7.7 ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 19.92,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  1.48,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -1.96,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): 4.929894 \n",
      "\n",
      "Margin per LP neuron (more positve is better): 0.011738\n",
      "\n",
      "Margin per second (more positve is better):   0.010986\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "verified\n",
      "True label: 4\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.720844\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.029272 \n",
      "\n",
      "Min tigthness of hat bounds: 0.024938 \n",
      "\n",
      "Max tigthness of hat bounds: 0.038183 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.05, -0.02,   nan,   nan,  0.  ],\n",
      "       [ 0.15,  0.17,   nan,   nan,  0.  ],\n",
      "       [-0.62, -0.59,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [-0.28, -0.25,   nan,   nan,  0.  ],\n",
      "       [ 0.22,  0.25,   nan,   nan,  0.  ],\n",
      "       [-0.18, -0.15,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 414.658693\n",
      "Time per LP neuron 1.011363\n",
      "LP used on 410 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.380340 \n",
      "\n",
      "Min tigthness of hat bounds: 0.019745 \n",
      "\n",
      "Max tigthness of hat bounds: 0.468109 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.31,  0.34,  0.14,  0.2 ,  1.  ],\n",
      "       [-0.59, -0.18,  0.84,  0.85,  0.  ],\n",
      "       [-0.62, -0.22,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.45, -0.05,  0.08,  0.11,  0.  ],\n",
      "       [ 0.75,  0.77,  0.09,  0.13,  1.  ],\n",
      "       [ 0.12,  0.15,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 7.312585\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 1.483210 \n",
      "\n",
      "Min tigthness of hat bounds: 1.304478 \n",
      "\n",
      "Max tigthness of hat bounds: 1.735335 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.03,  1.43,  0.35,  0.27,  0.  ],\n",
      "       [ 0.41,  1.83,  0.79,  0.76,  0.  ],\n",
      "       [ 0.55,  2.04,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-0.96,  0.52,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.19,  1.23,  0.22,  0.15,  0.  ],\n",
      "       [-0.33,  1.1 ,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 39.866916\n",
      "Time per LP neuron 3.986692\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 1.251151 \n",
      "\n",
      "Min tigthness of hat bounds: -13.896009 \n",
      "\n",
      "Max tigthness of hat bounds: 14.257305 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.  , -9.36,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 10.8 ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -7.45,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -0.1 ,   nan,   nan,  1.  ],\n",
      "       [13.9 ,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  2.61,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -2.98,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 10.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 14.26,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 13.23,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -0.361296 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.000860\n",
      "\n",
      "Margin per second (more positve is better):  -0.000779\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n",
      "True label: 9\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 2.059216\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.029117 \n",
      "\n",
      "Min tigthness of hat bounds: 0.024871 \n",
      "\n",
      "Max tigthness of hat bounds: 0.039547 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.57, -0.54,   nan,   nan,  0.  ],\n",
      "       [-0.29, -0.26,   nan,   nan,  0.  ],\n",
      "       [ 0.19,  0.22,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [-0.46, -0.43,   nan,   nan,  0.  ],\n",
      "       [-0.17, -0.14,   nan,   nan,  0.  ],\n",
      "       [-0.96, -0.93,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 459.443403\n",
      "Time per LP neuron 1.120594\n",
      "LP used on 410 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.378190 \n",
      "\n",
      "Min tigthness of hat bounds: 0.020719 \n",
      "\n",
      "Max tigthness of hat bounds: 0.468799 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.02,  0.01,  0.14,  0.2 ,  1.  ],\n",
      "       [ 0.18,  0.21,  0.84,  0.85,  1.  ],\n",
      "       [-0.11, -0.09,  1.  ,  1.  ,  1.  ],\n",
      "       ...,\n",
      "       [-0.58, -0.19,  0.08,  0.11,  0.  ],\n",
      "       [-0.42, -0.02,  0.09,  0.13,  0.  ],\n",
      "       [ 0.62,  0.64,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 7.073435\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 1.639541 \n",
      "\n",
      "Min tigthness of hat bounds: 1.416202 \n",
      "\n",
      "Max tigthness of hat bounds: 1.875456 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.99,  0.63,  0.35,  0.27,  0.  ],\n",
      "       [-1.53,  0.11,  0.79,  0.76,  0.  ],\n",
      "       [-0.49,  1.21,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.07,  0.56,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.96,  0.73,  0.22,  0.15,  0.  ],\n",
      "       [-0.13,  1.47,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "GurobiError",
     "evalue": "Out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGurobiError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-5d938ad98b5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m stats = analyse_nn_and_write('mnist_relu_4_1024', img_nrs , 0.001, global_rank_threshold=[0.0, 0.0], \n\u001b[1;32m      2\u001b[0m                              \u001b[0mlocal_rank_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtightness_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                             influence_threshold=[0.4, 0.0])\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-826053fd8549>\u001b[0m in \u001b[0;36manalyse_nn_and_write\u001b[0;34m(net_code, img_nrs, epsilon, log_file, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mLB_hidden_box_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUB_hidden_box_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLB_NN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUB_NN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperform_box_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLB_N0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUB_N0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         LB_NN, UB_NN, stats = perform_linear_layerwise(nn, numlayer, LB_N0, UB_N0, lp_list,\n\u001b[0;32m---> 55\u001b[0;31m                                      LB_hidden_box_list, UB_hidden_box_list, label, verbose=verbose, **kwargs)\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Check if NN was verified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverified_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverify_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLB_N0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUB_N0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLB_NN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUB_NN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_input_pixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLB_N0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_out_pixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-e82c0f8f0515>\u001b[0m in \u001b[0;36mperform_linear_layerwise\u001b[0;34m(nn, numlayer, LB_N0, UB_N0, lp_list, LB_hidden_box_list, UB_hidden_box_list, true_label, global_rank_threshold, local_rank_threshold, tightness_threshold, influence_threshold, verbose)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;31m# LB: Get lower bound of correct label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mLB_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_linear_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayerno\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlb_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;31m# UB: Get upper bound of all other labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-56778e1b7fba>\u001b[0m in \u001b[0;36mcall_linear_solver\u001b[0;34m(model, z_hat, lb_only, ub_only)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetObjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGRB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMINIMIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGRB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmodel.pxi\u001b[0m in \u001b[0;36mgurobipy.Model.optimize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mGurobiError\u001b[0m: Out of memory"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', img_nrs , 0.001, global_rank_threshold=[0.0, 0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.0, 0.0],\n",
    "                            influence_threshold=[0.4, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 7\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.685140\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.028662 \n",
      "\n",
      "Min tigthness of hat bounds: 0.024511 \n",
      "\n",
      "Max tigthness of hat bounds: 0.037791 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.12,  0.15,   nan,   nan,  0.  ],\n",
      "       [-0.15, -0.13,   nan,   nan,  0.  ],\n",
      "       [-0.72, -0.69,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [-0.79, -0.76,   nan,   nan,  0.  ],\n",
      "       [-0.8 , -0.77,   nan,   nan,  0.  ],\n",
      "       [-0.28, -0.26,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 309.426209\n",
      "Time per LP neuron 1.004631\n",
      "LP used on 308 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.395205 \n",
      "\n",
      "Min tigthness of hat bounds: 0.021179 \n",
      "\n",
      "Max tigthness of hat bounds: 0.478294 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.88, -0.45,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.35,  0.06,  0.84,  0.85,  0.  ],\n",
      "       [-1.25, -0.85,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.65, -0.25,  0.08,  0.11,  0.  ],\n",
      "       [-0.44, -0.04,  0.09,  0.13,  0.  ],\n",
      "       [ 0.92,  0.95,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 7.150257\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 2.159182 \n",
      "\n",
      "Min tigthness of hat bounds: 1.877202 \n",
      "\n",
      "Max tigthness of hat bounds: 2.491058 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.7 ,  1.38,  0.35,  0.27,  0.  ],\n",
      "       [-2.67, -0.63,  0.79,  0.76,  0.  ],\n",
      "       [ 0.14,  2.32,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.81,  0.22,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.85,  1.22,  0.22,  0.15,  0.  ],\n",
      "       [-0.06,  2.17,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 41.644011\n",
      "Time per LP neuron 4.164401\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 5.764169 \n",
      "\n",
      "Min tigthness of hat bounds: -15.933595 \n",
      "\n",
      "Max tigthness of hat bounds: 19.698301 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[  0.  ,   3.73,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  13.8 ,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  11.23,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  19.7 ,    nan,    nan,   1.  ],\n",
      "       [  0.  ,   2.54,    nan,    nan,   1.  ],\n",
      "       [  0.  ,   3.45,    nan,    nan,   1.  ],\n",
      "       [  0.  , -13.85,    nan,    nan,   1.  ],\n",
      "       [ 15.94,   0.  ,    nan,    nan,   1.  ],\n",
      "       [  0.  ,   7.81,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  15.51,    nan,    nan,   1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -3.764706 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.011839\n",
      "\n",
      "Margin per second (more positve is better):  -0.010460\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n",
      "True label: 2\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.635878\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030278 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025749 \n",
      "\n",
      "Max tigthness of hat bounds: 0.039281 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.17, -0.14,   nan,   nan,  0.  ],\n",
      "       [ 0.22,  0.25,   nan,   nan,  0.  ],\n",
      "       [ 0.15,  0.18,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 0.38,  0.41,   nan,   nan,  0.  ],\n",
      "       [ 0.64,  0.67,   nan,   nan,  0.  ],\n",
      "       [-0.21, -0.18,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 318.017984\n",
      "Time per LP neuron 1.032526\n",
      "LP used on 308 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.430921 \n",
      "\n",
      "Min tigthness of hat bounds: 0.022868 \n",
      "\n",
      "Max tigthness of hat bounds: 0.523857 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-2.22, -1.75,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.95, -0.49,  0.84,  0.85,  0.  ],\n",
      "       [ 0.12,  0.55,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.9 , -0.46,  0.08,  0.11,  0.  ],\n",
      "       [ 1.18,  1.21,  0.09,  0.13,  1.  ],\n",
      "       [ 1.  ,  1.03,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 6.951546\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 2.549889 \n",
      "\n",
      "Min tigthness of hat bounds: 2.255644 \n",
      "\n",
      "Max tigthness of hat bounds: 2.864336 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.94,  1.45,  0.35,  0.27,  0.  ],\n",
      "       [-0.78,  1.77,  0.79,  0.76,  0.  ],\n",
      "       [-1.41,  1.1 ,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.11,  1.38,  0.4 ,  0.31,  0.  ],\n",
      "       [-1.68,  0.88,  0.22,  0.15,  0.  ],\n",
      "       [-0.31,  2.05,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 39.816443\n",
      "Time per LP neuron 3.981644\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 6.928524 \n",
      "\n",
      "Min tigthness of hat bounds: -14.003075 \n",
      "\n",
      "Max tigthness of hat bounds: 25.699754 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.  , 11.81,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 22.5 ,   nan,   nan,  1.  ],\n",
      "       [14.01,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 25.7 ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -6.06,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  5.56,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  2.37,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  8.31,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  9.94,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -4.07,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -11.696678 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.036782\n",
      "\n",
      "Margin per second (more positve is better):  -0.031921\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n",
      "True label: 1\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.650117\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.026938 \n",
      "\n",
      "Min tigthness of hat bounds: 0.023142 \n",
      "\n",
      "Max tigthness of hat bounds: 0.034755 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.88, -0.85,   nan,   nan,  0.  ],\n",
      "       [-0.12, -0.09,   nan,   nan,  0.  ],\n",
      "       [-0.06, -0.03,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 0.57,  0.6 ,   nan,   nan,  0.  ],\n",
      "       [ 0.26,  0.29,   nan,   nan,  0.  ],\n",
      "       [-0.13, -0.11,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 299.423280\n",
      "Time per LP neuron 0.972154\n",
      "LP used on 308 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.360518 \n",
      "\n",
      "Min tigthness of hat bounds: 0.021656 \n",
      "\n",
      "Max tigthness of hat bounds: 0.427107 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.51, -1.12,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.65, -0.27,  0.84,  0.85,  0.  ],\n",
      "       [-0.11,  0.25,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.41, -0.03,  0.08,  0.11,  0.  ],\n",
      "       [ 0.22,  0.24,  0.09,  0.13,  1.  ],\n",
      "       [ 0.27,  0.3 ,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 6.961875\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 2.378926 \n",
      "\n",
      "Min tigthness of hat bounds: 2.104668 \n",
      "\n",
      "Max tigthness of hat bounds: 2.680132 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.99,  1.31,  0.35,  0.27,  0.  ],\n",
      "       [-1.31,  0.98,  0.79,  0.76,  0.  ],\n",
      "       [ 0.29,  2.57,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.02,  1.21,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.77,  1.53,  0.22,  0.15,  0.  ],\n",
      "       [-1.14,  1.25,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 41.267953\n",
      "Time per LP neuron 4.126795\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 10.511221 \n",
      "\n",
      "Min tigthness of hat bounds: -7.104121 \n",
      "\n",
      "Max tigthness of hat bounds: 22.572551 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.  ,  5.56,   nan,   nan,  1.  ],\n",
      "       [ 7.11,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 16.31,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 12.52,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 14.73,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  8.51,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  7.27,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 22.58,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 13.39,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  7.71,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -15.468429 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.048643\n",
      "\n",
      "Margin per second (more positve is better):  -0.044284\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n",
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.666828\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.031261 \n",
      "\n",
      "Min tigthness of hat bounds: 0.026475 \n",
      "\n",
      "Max tigthness of hat bounds: 0.041886 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.85,  0.88,   nan,   nan,  0.  ],\n",
      "       [ 0.21,  0.24,   nan,   nan,  0.  ],\n",
      "       [-0.04, -0.01,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [-0.47, -0.43,   nan,   nan,  0.  ],\n",
      "       [-0.84, -0.81,   nan,   nan,  0.  ],\n",
      "       [-0.46, -0.43,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 290.577598\n",
      "Time per LP neuron 0.943434\n",
      "LP used on 308 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.423987 \n",
      "\n",
      "Min tigthness of hat bounds: 0.021895 \n",
      "\n",
      "Max tigthness of hat bounds: 0.503625 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.27, -0.8 ,  0.14,  0.2 ,  0.  ],\n",
      "       [ 0.14,  0.58,  0.84,  0.85,  0.  ],\n",
      "       [-0.72, -0.29,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-1.09, -0.66,  0.08,  0.11,  0.  ],\n",
      "       [ 0.39,  0.42,  0.09,  0.13,  1.  ],\n",
      "       [ 1.62,  1.65,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 6.935134\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 2.329012 \n",
      "\n",
      "Min tigthness of hat bounds: 2.028969 \n",
      "\n",
      "Max tigthness of hat bounds: 2.655154 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.47,  1.7 ,  0.35,  0.27,  0.  ],\n",
      "       [-1.71,  0.51,  0.79,  0.76,  0.  ],\n",
      "       [-0.96,  1.4 ,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.69,  0.67,  0.4 ,  0.31,  0.  ],\n",
      "       [-1.67,  0.75,  0.22,  0.15,  0.  ],\n",
      "       [-0.77,  1.42,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 37.379476\n",
      "Time per LP neuron 3.737948\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 8.783441 \n",
      "\n",
      "Min tigthness of hat bounds: -10.069411 \n",
      "\n",
      "Max tigthness of hat bounds: 16.541079 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[10.07,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  9.42,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 13.99,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 16.55,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -0.51,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 10.72,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  5.52,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 10.8 ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  1.38,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  8.16,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -6.471667 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.020351\n",
      "\n",
      "Margin per second (more positve is better):  -0.019229\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n",
      "True label: 4\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.859769\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.028790 \n",
      "\n",
      "Min tigthness of hat bounds: 0.024641 \n",
      "\n",
      "Max tigthness of hat bounds: 0.037223 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.12,  0.15,   nan,   nan,  0.  ],\n",
      "       [ 0.25,  0.28,   nan,   nan,  0.  ],\n",
      "       [-0.48, -0.45,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 0.33,  0.36,   nan,   nan,  0.  ],\n",
      "       [-1.18, -1.16,   nan,   nan,  0.  ],\n",
      "       [-0.36, -0.33,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 295.159842\n",
      "Time per LP neuron 0.958311\n",
      "LP used on 308 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.391103 \n",
      "\n",
      "Min tigthness of hat bounds: 0.020755 \n",
      "\n",
      "Max tigthness of hat bounds: 0.474239 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.59, -1.18,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.38,  0.02,  0.84,  0.85,  0.  ],\n",
      "       [-0.6 , -0.2 ,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.15, -0.13,  0.08,  0.11,  1.  ],\n",
      "       [ 0.54,  0.56,  0.09,  0.13,  1.  ],\n",
      "       [-0.42, -0.  ,  0.78,  0.81,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 7.017199\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 2.350748 \n",
      "\n",
      "Min tigthness of hat bounds: 2.045368 \n",
      "\n",
      "Max tigthness of hat bounds: 2.607235 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.27,  0.97,  0.35,  0.27,  0.  ],\n",
      "       [-0.49,  1.82,  0.79,  0.76,  0.  ],\n",
      "       [-0.98,  1.44,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.96,  0.45,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.4 ,  1.89,  0.22,  0.15,  0.  ],\n",
      "       [-0.68,  1.67,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 40.304359\n",
      "Time per LP neuron 4.030436\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 10.068746 \n",
      "\n",
      "Min tigthness of hat bounds: -0.424139 \n",
      "\n",
      "Max tigthness of hat bounds: 25.028128 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.  , 11.73,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  9.81,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 10.34,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  6.54,   nan,   nan,  1.  ],\n",
      "       [ 0.43,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  3.39,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  5.94,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 21.57,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 12.91,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 25.03,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -24.603989 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.077371\n",
      "\n",
      "Margin per second (more positve is better):  -0.071452\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 1\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.632065\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.027634 \n",
      "\n",
      "Min tigthness of hat bounds: 0.023654 \n",
      "\n",
      "Max tigthness of hat bounds: 0.036135 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.96, -0.93,   nan,   nan,  0.  ],\n",
      "       [-0.09, -0.07,   nan,   nan,  0.  ],\n",
      "       [ 0.02,  0.05,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 0.6 ,  0.63,   nan,   nan,  0.  ],\n",
      "       [ 0.34,  0.37,   nan,   nan,  0.  ],\n",
      "       [-0.15, -0.12,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 294.578977\n",
      "Time per LP neuron 0.956425\n",
      "LP used on 308 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.369921 \n",
      "\n",
      "Min tigthness of hat bounds: 0.021478 \n",
      "\n",
      "Max tigthness of hat bounds: 0.437571 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.79, -1.39,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.78, -0.39,  0.84,  0.85,  0.  ],\n",
      "       [-0.06,  0.31,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.49, -0.11,  0.08,  0.11,  0.  ],\n",
      "       [ 0.05,  0.07,  0.09,  0.13,  1.  ],\n",
      "       [ 0.38,  0.41,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 7.036745\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 2.116538 \n",
      "\n",
      "Min tigthness of hat bounds: 1.889952 \n",
      "\n",
      "Max tigthness of hat bounds: 2.391281 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.81,  1.22,  0.35,  0.27,  0.  ],\n",
      "       [-1.49,  0.54,  0.79,  0.76,  0.  ],\n",
      "       [ 1.08,  3.16,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-0.84,  1.09,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.42,  1.61,  0.22,  0.15,  0.  ],\n",
      "       [-1.01,  1.16,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 37.118520\n",
      "Time per LP neuron 3.711852\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 5.253790 \n",
      "\n",
      "Min tigthness of hat bounds: -19.238933 \n",
      "\n",
      "Max tigthness of hat bounds: 24.178556 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.  ,  0.18,   nan,   nan,  1.  ],\n",
      "       [19.24,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  7.7 ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  7.84,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 13.65,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -0.94,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -2.68,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 24.18,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  6.74,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  3.78,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -4.939623 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.015533\n",
      "\n",
      "Margin per second (more positve is better):  -0.014513\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n",
      "True label: 4\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.627619\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.029272 \n",
      "\n",
      "Min tigthness of hat bounds: 0.024938 \n",
      "\n",
      "Max tigthness of hat bounds: 0.038183 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.05, -0.02,   nan,   nan,  0.  ],\n",
      "       [ 0.15,  0.17,   nan,   nan,  0.  ],\n",
      "       [-0.62, -0.59,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [-0.28, -0.25,   nan,   nan,  0.  ],\n",
      "       [ 0.22,  0.25,   nan,   nan,  0.  ],\n",
      "       [-0.18, -0.15,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 295.740573\n",
      "Time per LP neuron 0.960197\n",
      "LP used on 308 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.386086 \n",
      "\n",
      "Min tigthness of hat bounds: 0.021034 \n",
      "\n",
      "Max tigthness of hat bounds: 0.468109 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.31,  0.34,  0.14,  0.2 ,  1.  ],\n",
      "       [-0.59, -0.18,  0.84,  0.85,  0.  ],\n",
      "       [-0.62, -0.22,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.45, -0.05,  0.08,  0.11,  0.  ],\n",
      "       [ 0.57,  0.95,  0.09,  0.13,  0.  ],\n",
      "       [ 0.12,  0.15,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 6.902371\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 2.265998 \n",
      "\n",
      "Min tigthness of hat bounds: 1.906513 \n",
      "\n",
      "Max tigthness of hat bounds: 2.551450 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.45,  1.85,  0.35,  0.27,  0.  ],\n",
      "       [ 0.08,  2.2 ,  0.79,  0.76,  0.  ],\n",
      "       [ 0.21,  2.41,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.4 ,  0.95,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.59,  1.64,  0.22,  0.15,  0.  ],\n",
      "       [-0.66,  1.45,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 42.330177\n",
      "Time per LP neuron 4.233018\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 8.045066 \n",
      "\n",
      "Min tigthness of hat bounds: -6.698373 \n",
      "\n",
      "Max tigthness of hat bounds: 19.888622 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.  , -3.67,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 16.71,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -0.18,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  6.87,   nan,   nan,  1.  ],\n",
      "       [ 6.7 ,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  9.23,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  2.59,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 16.04,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 19.89,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 19.4 ,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -13.190249 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.041479\n",
      "\n",
      "Margin per second (more positve is better):  -0.038056\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n",
      "True label: 9\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.685862\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.029117 \n",
      "\n",
      "Min tigthness of hat bounds: 0.024871 \n",
      "\n",
      "Max tigthness of hat bounds: 0.039547 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.57, -0.54,   nan,   nan,  0.  ],\n",
      "       [-0.29, -0.26,   nan,   nan,  0.  ],\n",
      "       [ 0.19,  0.22,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [-0.46, -0.43,   nan,   nan,  0.  ],\n",
      "       [-0.17, -0.14,   nan,   nan,  0.  ],\n",
      "       [-0.96, -0.93,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', img_nrs , 0.001, global_rank_threshold=[0.0, 0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.0, 0.0],\n",
    "                            influence_threshold=[0.3, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 7\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 2.040956\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.028662 \n",
      "\n",
      "Min tigthness of hat bounds: 0.024511 \n",
      "\n",
      "Max tigthness of hat bounds: 0.037791 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.12,  0.15,   nan,   nan,  0.  ],\n",
      "       [-0.15, -0.13,   nan,   nan,  0.  ],\n",
      "       [-0.72, -0.69,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [-0.79, -0.76,   nan,   nan,  0.  ],\n",
      "       [-0.8 , -0.77,   nan,   nan,  0.  ],\n",
      "       [-0.28, -0.26,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 526.511029\n",
      "Time per LP neuron 1.028342\n",
      "LP used on 512 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.200384 \n",
      "\n",
      "Min tigthness of hat bounds: 0.020706 \n",
      "\n",
      "Max tigthness of hat bounds: 0.478294 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.88, -0.45,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.16, -0.13,  0.84,  0.85,  1.  ],\n",
      "       [-1.25, -0.85,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.65, -0.25,  0.08,  0.11,  0.  ],\n",
      "       [-0.44, -0.04,  0.09,  0.13,  0.  ],\n",
      "       [ 0.92,  0.95,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 6.922009\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 0.662099 \n",
      "\n",
      "Min tigthness of hat bounds: 0.541931 \n",
      "\n",
      "Max tigthness of hat bounds: 0.768888 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.05,  0.63,  0.35,  0.27,  0.  ],\n",
      "       [-1.97, -1.35,  0.79,  0.76,  0.  ],\n",
      "       [ 0.89,  1.53,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.08, -0.46,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.15,  0.53,  0.22,  0.15,  0.  ],\n",
      "       [ 0.76,  1.43,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 31.118115\n",
      "Time per LP neuron 3.111812\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: -2.397912 \n",
      "\n",
      "Min tigthness of hat bounds: -25.874909 \n",
      "\n",
      "Max tigthness of hat bounds: 11.528180 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[  0.  ,  -3.72,    nan,    nan,   1.  ],\n",
      "       [  0.  ,   5.83,    nan,    nan,   1.  ],\n",
      "       [  0.  ,   2.73,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  11.53,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -5.14,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -6.02,    nan,    nan,   1.  ],\n",
      "       [  0.  , -21.26,    nan,    nan,   1.  ],\n",
      "       [ 25.88,   0.  ,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -1.06,    nan,    nan,   1.  ],\n",
      "       [  0.  ,   6.3 ,    nan,    nan,   1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): 14.346729 \n",
      "\n",
      "Margin per LP neuron (more positve is better): 0.027484\n",
      "\n",
      "Margin per second (more positve is better):   0.025321\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "verified\n",
      "True label: 2\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.631934\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.030278 \n",
      "\n",
      "Min tigthness of hat bounds: 0.025749 \n",
      "\n",
      "Max tigthness of hat bounds: 0.039281 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.17, -0.14,   nan,   nan,  0.  ],\n",
      "       [ 0.22,  0.25,   nan,   nan,  0.  ],\n",
      "       [ 0.15,  0.18,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 0.38,  0.41,   nan,   nan,  0.  ],\n",
      "       [ 0.64,  0.67,   nan,   nan,  0.  ],\n",
      "       [-0.21, -0.18,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 483.800396\n",
      "Time per LP neuron 0.944923\n",
      "LP used on 512 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.216066 \n",
      "\n",
      "Min tigthness of hat bounds: 0.020920 \n",
      "\n",
      "Max tigthness of hat bounds: 0.523857 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-2.22, -1.75,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.95, -0.49,  0.84,  0.85,  0.  ],\n",
      "       [ 0.32,  0.35,  1.  ,  1.  ,  1.  ],\n",
      "       ...,\n",
      "       [-0.9 , -0.46,  0.08,  0.11,  0.  ],\n",
      "       [ 1.18,  1.21,  0.09,  0.13,  1.  ],\n",
      "       [ 1.  ,  1.03,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 6.634392\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 0.703710 \n",
      "\n",
      "Min tigthness of hat bounds: 0.584406 \n",
      "\n",
      "Max tigthness of hat bounds: 0.825185 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.06,  0.58,  0.35,  0.27,  0.  ],\n",
      "       [ 0.17,  0.84,  0.79,  0.76,  0.  ],\n",
      "       [-0.48,  0.17,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-0.17,  0.52,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.78, -0.02,  0.22,  0.15,  0.  ],\n",
      "       [ 0.54,  1.25,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 30.411917\n",
      "Time per LP neuron 3.041192\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: -3.528023 \n",
      "\n",
      "Min tigthness of hat bounds: -26.294801 \n",
      "\n",
      "Max tigthness of hat bounds: 16.434464 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[  0.  ,   3.8 ,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  13.18,    nan,    nan,   1.  ],\n",
      "       [ 26.3 ,   0.  ,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  16.44,    nan,    nan,   1.  ],\n",
      "       [  0.  , -16.07,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -5.69,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -7.95,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -1.36,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -0.7 ,    nan,    nan,   1.  ],\n",
      "       [  0.  , -15.42,    nan,    nan,   1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): 9.860337 \n",
      "\n",
      "Margin per LP neuron (more positve is better): 0.018890\n",
      "\n",
      "Margin per second (more positve is better):   0.018872\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "verified\n",
      "True label: 1\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.689342\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.026938 \n",
      "\n",
      "Min tigthness of hat bounds: 0.023142 \n",
      "\n",
      "Max tigthness of hat bounds: 0.034755 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.88, -0.85,   nan,   nan,  0.  ],\n",
      "       [-0.12, -0.09,   nan,   nan,  0.  ],\n",
      "       [-0.06, -0.03,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 0.57,  0.6 ,   nan,   nan,  0.  ],\n",
      "       [ 0.26,  0.29,   nan,   nan,  0.  ],\n",
      "       [-0.13, -0.11,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 467.019925\n",
      "Time per LP neuron 0.912148\n",
      "LP used on 512 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.188426 \n",
      "\n",
      "Min tigthness of hat bounds: 0.020420 \n",
      "\n",
      "Max tigthness of hat bounds: 0.427107 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.51, -1.12,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.65, -0.27,  0.84,  0.85,  0.  ],\n",
      "       [ 0.06,  0.08,  1.  ,  1.  ,  1.  ],\n",
      "       ...,\n",
      "       [-0.41, -0.03,  0.08,  0.11,  0.  ],\n",
      "       [ 0.22,  0.24,  0.09,  0.13,  1.  ],\n",
      "       [ 0.27,  0.3 ,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 6.605385\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 0.959651 \n",
      "\n",
      "Min tigthness of hat bounds: 0.808833 \n",
      "\n",
      "Max tigthness of hat bounds: 1.098603 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.29,  0.62,  0.35,  0.27,  0.  ],\n",
      "       [-0.66,  0.28,  0.79,  0.76,  0.  ],\n",
      "       [ 0.93,  1.89,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-0.39,  0.54,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.1 ,  0.85,  0.22,  0.15,  0.  ],\n",
      "       [-0.41,  0.54,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 38.973662\n",
      "Time per LP neuron 3.897366\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: -1.365687 \n",
      "\n",
      "Min tigthness of hat bounds: -18.329975 \n",
      "\n",
      "Max tigthness of hat bounds: 12.602799 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.  , -4.2 ,   nan,   nan,  1.  ],\n",
      "       [18.33,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  4.93,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  0.48,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  4.45,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -3.51,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -3.2 ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 12.61,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  2.12,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -4.95,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): 5.727175 \n",
      "\n",
      "Margin per LP neuron (more positve is better): 0.010972\n",
      "\n",
      "Margin per second (more positve is better):   0.011136\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "verified\n",
      "True label: 0\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.639693\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.031261 \n",
      "\n",
      "Min tigthness of hat bounds: 0.026475 \n",
      "\n",
      "Max tigthness of hat bounds: 0.041886 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.85,  0.88,   nan,   nan,  0.  ],\n",
      "       [ 0.21,  0.24,   nan,   nan,  0.  ],\n",
      "       [-0.04, -0.01,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [-0.47, -0.43,   nan,   nan,  0.  ],\n",
      "       [-0.84, -0.81,   nan,   nan,  0.  ],\n",
      "       [-0.46, -0.43,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 475.259058\n",
      "Time per LP neuron 0.928240\n",
      "LP used on 512 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.214157 \n",
      "\n",
      "Min tigthness of hat bounds: 0.020670 \n",
      "\n",
      "Max tigthness of hat bounds: 0.503625 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.27, -0.8 ,  0.14,  0.2 ,  0.  ],\n",
      "       [ 0.35,  0.37,  0.84,  0.85,  1.  ],\n",
      "       [-0.72, -0.29,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-1.09, -0.66,  0.08,  0.11,  0.  ],\n",
      "       [ 0.39,  0.42,  0.09,  0.13,  1.  ],\n",
      "       [ 1.62,  1.65,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 6.681669\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 0.565768 \n",
      "\n",
      "Min tigthness of hat bounds: 0.468030 \n",
      "\n",
      "Max tigthness of hat bounds: 0.676324 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.38,  0.86,  0.35,  0.27,  0.  ],\n",
      "       [-0.89, -0.36,  0.79,  0.76,  0.  ],\n",
      "       [-0.06,  0.49,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-0.75, -0.23,  0.4 ,  0.31,  0.  ],\n",
      "       [-0.77, -0.17,  0.22,  0.15,  0.  ],\n",
      "       [ 0.04,  0.59,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 28.185370\n",
      "Time per LP neuron 2.818537\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: -1.551347 \n",
      "\n",
      "Min tigthness of hat bounds: -21.344981 \n",
      "\n",
      "Max tigthness of hat bounds: 7.161094 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 21.35,   0.  ,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -0.71,    nan,    nan,   1.  ],\n",
      "       [  0.  ,   4.79,    nan,    nan,   1.  ],\n",
      "       [  0.  ,   7.17,    nan,    nan,   1.  ],\n",
      "       [  0.  , -10.08,    nan,    nan,   1.  ],\n",
      "       [  0.  ,   1.43,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -3.38,    nan,    nan,   1.  ],\n",
      "       [  0.  ,   1.13,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -8.85,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -2.38,    nan,    nan,   1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): 14.183887 \n",
      "\n",
      "Margin per LP neuron (more positve is better): 0.027172\n",
      "\n",
      "Margin per second (more positve is better):   0.027716\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "verified\n",
      "True label: 4\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.630524\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.028790 \n",
      "\n",
      "Min tigthness of hat bounds: 0.024641 \n",
      "\n",
      "Max tigthness of hat bounds: 0.037223 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.12,  0.15,   nan,   nan,  0.  ],\n",
      "       [ 0.25,  0.28,   nan,   nan,  0.  ],\n",
      "       [-0.48, -0.45,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 0.33,  0.36,   nan,   nan,  0.  ],\n",
      "       [-1.18, -1.16,   nan,   nan,  0.  ],\n",
      "       [-0.36, -0.33,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 505.603894\n",
      "Time per LP neuron 0.987508\n",
      "LP used on 512 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.198654 \n",
      "\n",
      "Min tigthness of hat bounds: 0.019666 \n",
      "\n",
      "Max tigthness of hat bounds: 0.474239 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.59, -1.18,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.19, -0.17,  0.84,  0.85,  1.  ],\n",
      "       [-0.6 , -0.2 ,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.15, -0.13,  0.08,  0.11,  1.  ],\n",
      "       [ 0.54,  0.56,  0.09,  0.13,  1.  ],\n",
      "       [-0.42, -0.  ,  0.78,  0.81,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 7.118275\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 0.881014 \n",
      "\n",
      "Min tigthness of hat bounds: 0.751278 \n",
      "\n",
      "Max tigthness of hat bounds: 1.031253 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.54,  0.27,  0.35,  0.27,  0.  ],\n",
      "       [ 0.27,  1.08,  0.79,  0.76,  0.  ],\n",
      "       [-0.26,  0.68,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-1.17, -0.36,  0.4 ,  0.31,  0.  ],\n",
      "       [ 0.33,  1.21,  0.22,  0.15,  0.  ],\n",
      "       [ 0.07,  0.98,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 36.792618\n",
      "Time per LP neuron 3.679262\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: -1.717146 \n",
      "\n",
      "Min tigthness of hat bounds: -13.005101 \n",
      "\n",
      "Max tigthness of hat bounds: 14.324595 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.  ,  2.44,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -1.42,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -2.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -5.72,   nan,   nan,  1.  ],\n",
      "       [13.01,  0.  ,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -9.05,   nan,   nan,  1.  ],\n",
      "       [ 0.  , -4.32,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 11.39,   nan,   nan,  1.  ],\n",
      "       [ 0.  ,  1.43,   nan,   nan,  1.  ],\n",
      "       [ 0.  , 14.33,   nan,   nan,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -1.319494 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -0.002528\n",
      "\n",
      "Margin per second (more positve is better):  -0.002394\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 1\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.655506\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.027634 \n",
      "\n",
      "Min tigthness of hat bounds: 0.023654 \n",
      "\n",
      "Max tigthness of hat bounds: 0.036135 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.96, -0.93,   nan,   nan,  0.  ],\n",
      "       [-0.09, -0.07,   nan,   nan,  0.  ],\n",
      "       [ 0.02,  0.05,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [ 0.6 ,  0.63,   nan,   nan,  0.  ],\n",
      "       [ 0.34,  0.37,   nan,   nan,  0.  ],\n",
      "       [-0.15, -0.12,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 476.250762\n",
      "Time per LP neuron 0.930177\n",
      "LP used on 512 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.190836 \n",
      "\n",
      "Min tigthness of hat bounds: 0.018890 \n",
      "\n",
      "Max tigthness of hat bounds: 0.437571 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.79, -1.39,  0.14,  0.2 ,  0.  ],\n",
      "       [-0.78, -0.39,  0.84,  0.85,  0.  ],\n",
      "       [ 0.11,  0.13,  1.  ,  1.  ,  1.  ],\n",
      "       ...,\n",
      "       [-0.49, -0.11,  0.08,  0.11,  0.  ],\n",
      "       [ 0.05,  0.07,  0.09,  0.13,  1.  ],\n",
      "       [ 0.38,  0.41,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 6.747624\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 0.678560 \n",
      "\n",
      "Min tigthness of hat bounds: 0.576067 \n",
      "\n",
      "Max tigthness of hat bounds: 0.803094 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.09,  0.53,  0.35,  0.27,  0.  ],\n",
      "       [-0.8 , -0.15,  0.79,  0.76,  0.  ],\n",
      "       [ 1.77,  2.48,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-0.19,  0.42,  0.4 ,  0.31,  0.  ],\n",
      "       [ 0.26,  0.93,  0.22,  0.15,  0.  ],\n",
      "       [-0.3 ,  0.44,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 29.595206\n",
      "Time per LP neuron 2.959521\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: -3.779171 \n",
      "\n",
      "Min tigthness of hat bounds: -28.500639 \n",
      "\n",
      "Max tigthness of hat bounds: 17.405531 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[  0.  ,  -6.91,    nan,    nan,   1.  ],\n",
      "       [ 28.51,   0.  ,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -1.22,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -1.76,    nan,    nan,   1.  ],\n",
      "       [  0.  ,   6.12,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -9.96,    nan,    nan,   1.  ],\n",
      "       [  0.  , -10.82,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  17.41,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -1.97,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -5.58,    nan,    nan,   1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): 11.095108 \n",
      "\n",
      "Margin per LP neuron (more positve is better): 0.021255\n",
      "\n",
      "Margin per second (more positve is better):   0.021575\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "verified\n",
      "True label: 4\n",
      "Number of relu layers: 4\n",
      "Number of hidden layers: 4\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 1.697352\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 0.029272 \n",
      "\n",
      "Min tigthness of hat bounds: 0.024938 \n",
      "\n",
      "Max tigthness of hat bounds: 0.038183 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-0.05, -0.02,   nan,   nan,  0.  ],\n",
      "       [ 0.15,  0.17,   nan,   nan,  0.  ],\n",
      "       [-0.62, -0.59,   nan,   nan,  0.  ],\n",
      "       ...,\n",
      "       [-0.28, -0.25,   nan,   nan,  0.  ],\n",
      "       [ 0.22,  0.25,   nan,   nan,  0.  ],\n",
      "       [-0.18, -0.15,   nan,   nan,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 534.100935\n",
      "Time per LP neuron 1.043166\n",
      "LP used on 512 neurons.\n",
      "Median global rank: 0.424316\n",
      "Median tigthness of hat bounds: 0.196513 \n",
      "\n",
      "Min tigthness of hat bounds: 0.019745 \n",
      "\n",
      "Max tigthness of hat bounds: 0.468109 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.31,  0.34,  0.14,  0.2 ,  1.  ],\n",
      "       [-0.59, -0.18,  0.84,  0.85,  0.  ],\n",
      "       [-0.62, -0.22,  1.  ,  1.  ,  0.  ],\n",
      "       ...,\n",
      "       [-0.45, -0.05,  0.08,  0.11,  0.  ],\n",
      "       [ 0.75,  0.77,  0.09,  0.13,  1.  ],\n",
      "       [ 0.12,  0.15,  0.78,  0.81,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "[Network] Input pixels: 1024\n",
      "[Network] Shape of weights: (1024, 1024)\n",
      "[Network] Shape of biases: (1024,)\n",
      "[Network] Out pixels: 1024\n",
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 6.820449\n",
      "Median global rank: 0.556641\n",
      "Median tigthness of hat bounds: 0.775169 \n",
      "\n",
      "Min tigthness of hat bounds: 0.653914 \n",
      "\n",
      "Max tigthness of hat bounds: 0.911096 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ 0.33,  1.05,  0.35,  0.27,  0.  ],\n",
      "       [ 0.74,  1.48,  0.79,  0.76,  0.  ],\n",
      "       [ 0.91,  1.68,  0.49,  0.41,  0.  ],\n",
      "       ...,\n",
      "       [-0.59,  0.18,  0.4 ,  0.31,  0.  ],\n",
      "       [ 0.14,  0.9 ,  0.22,  0.15,  0.  ],\n",
      "       [-0.  ,  0.76,  0.25,  0.16,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 36.952194\n",
      "Time per LP neuron 3.695219\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: -3.379479 \n",
      "\n",
      "Min tigthness of hat bounds: -19.075385 \n",
      "\n",
      "Max tigthness of hat bounds: 10.780550 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[  0.  , -13.09,    nan,    nan,   1.  ],\n",
      "       [  0.  ,   6.97,    nan,    nan,   1.  ],\n",
      "       [  0.  , -12.18,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -4.96,    nan,    nan,   1.  ],\n",
      "       [ 19.08,   0.  ,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -1.79,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  -6.67,    nan,    nan,   1.  ],\n",
      "       [  0.  ,   6.03,    nan,    nan,   1.  ],\n",
      "       [  0.  ,  10.79,    nan,    nan,   1.  ],\n",
      "       [  0.  ,   9.51,    nan,    nan,   1.  ]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): 8.294835 \n",
      "\n",
      "Margin per LP neuron (more positve is better): 0.015890\n",
      "\n",
      "Margin per second (more positve is better):   0.014312\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_4_1024', img_nrs , 0.001, global_rank_threshold=[0.0, 0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.0, 0.0],\n",
    "                            influence_threshold=[0.5, 0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mnist_relu_3_10',\n",
       " 'mnist_relu_3_20',\n",
       " 'mnist_relu_3_50',\n",
       " 'mnist_relu_4_1024',\n",
       " 'mnist_relu_6_100',\n",
       " 'mnist_relu_6_20',\n",
       " 'mnist_relu_6_200',\n",
       " 'mnist_relu_6_50',\n",
       " 'mnist_relu_9_100',\n",
       " 'mnist_relu_9_200']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0\n",
      "Number of relu layers: 9\n",
      "Number of hidden layers: 9\n",
      "Size of last hidden layer: 10\n",
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 0.405502\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 6.661518 \n",
      "\n",
      "Min tigthness of hat bounds: 6.119983 \n",
      "\n",
      "Max tigthness of hat bounds: 8.992730 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[ -6.4 ,   0.78,    nan,    nan,   0.  ],\n",
      "       [ -4.22,   2.34,    nan,    nan,   0.  ],\n",
      "       [ -7.77,  -0.83,    nan,    nan,   0.  ],\n",
      "       [ -8.35,  -1.03,    nan,    nan,   0.  ],\n",
      "       [ -4.69,   2.25,    nan,    nan,   0.  ],\n",
      "       [ -4.64,   1.58,    nan,    nan,   0.  ],\n",
      "       [ -4.72,   1.96,    nan,    nan,   0.  ],\n",
      "       [ -1.81,   6.02,    nan,    nan,   0.  ],\n",
      "       [ -5.03,   1.42,    nan,    nan,   0.  ],\n",
      "       [ -3.36,   3.04,    nan,    nan,   0.  ],\n",
      "       [-10.01,  -2.53,    nan,    nan,   0.  ],\n",
      "       [ -4.59,   2.03,    nan,    nan,   0.  ],\n",
      "       [ -2.45,   5.26,    nan,    nan,   0.  ],\n",
      "       [-12.09,  -4.4 ,    nan,    nan,   0.  ],\n",
      "       [ -7.43,  -0.54,    nan,    nan,   0.  ],\n",
      "       [ -5.66,   0.69,    nan,    nan,   0.  ],\n",
      "       [  1.21,   8.48,    nan,    nan,   0.  ],\n",
      "       [ -4.39,   2.13,    nan,    nan,   0.  ],\n",
      "       [ -5.89,   0.99,    nan,    nan,   0.  ],\n",
      "       [ -6.03,   0.49,    nan,    nan,   0.  ],\n",
      "       [ -4.66,   1.64,    nan,    nan,   0.  ],\n",
      "       [ -4.59,   1.96,    nan,    nan,   0.  ],\n",
      "       [ -4.11,   3.29,    nan,    nan,   0.  ],\n",
      "       [ -2.78,   4.3 ,    nan,    nan,   0.  ],\n",
      "       [ -4.5 ,   1.92,    nan,    nan,   0.  ],\n",
      "       [ -7.71,  -1.17,    nan,    nan,   0.  ],\n",
      "       [ -3.63,   2.5 ,    nan,    nan,   0.  ],\n",
      "       [ -6.82,  -0.3 ,    nan,    nan,   0.  ],\n",
      "       [ -5.72,   0.85,    nan,    nan,   0.  ],\n",
      "       [ -5.21,   1.27,    nan,    nan,   0.  ],\n",
      "       [ -4.32,   2.23,    nan,    nan,   0.  ],\n",
      "       [ -7.23,  -0.29,    nan,    nan,   0.  ],\n",
      "       [ -4.13,   2.41,    nan,    nan,   0.  ],\n",
      "       [ -6.72,   0.36,    nan,    nan,   0.  ],\n",
      "       [ -4.24,   1.88,    nan,    nan,   0.  ],\n",
      "       [ -9.77,  -1.78,    nan,    nan,   0.  ],\n",
      "       [ -3.62,   2.83,    nan,    nan,   0.  ],\n",
      "       [ -4.2 ,   2.6 ,    nan,    nan,   0.  ],\n",
      "       [ -1.77,   5.03,    nan,    nan,   0.  ],\n",
      "       [ -2.35,   4.13,    nan,    nan,   0.  ],\n",
      "       [ -3.78,   2.83,    nan,    nan,   0.  ],\n",
      "       [ -7.12,   0.33,    nan,    nan,   0.  ],\n",
      "       [ -6.62,   0.33,    nan,    nan,   0.  ],\n",
      "       [ -5.4 ,   1.33,    nan,    nan,   0.  ],\n",
      "       [ -4.69,   1.71,    nan,    nan,   0.  ],\n",
      "       [ -4.25,   2.09,    nan,    nan,   0.  ],\n",
      "       [ -2.37,   4.26,    nan,    nan,   0.  ],\n",
      "       [ -4.1 ,   2.28,    nan,    nan,   0.  ],\n",
      "       [ -5.73,   0.61,    nan,    nan,   0.  ],\n",
      "       [ -3.71,   3.67,    nan,    nan,   0.  ],\n",
      "       [ -6.28,   0.83,    nan,    nan,   0.  ],\n",
      "       [ -5.16,   1.14,    nan,    nan,   0.  ],\n",
      "       [ -5.14,   1.16,    nan,    nan,   0.  ],\n",
      "       [ -5.18,   1.3 ,    nan,    nan,   0.  ],\n",
      "       [ -5.38,   1.2 ,    nan,    nan,   0.  ],\n",
      "       [ -4.77,   1.61,    nan,    nan,   0.  ],\n",
      "       [ -5.26,   1.03,    nan,    nan,   0.  ],\n",
      "       [ -7.28,   0.05,    nan,    nan,   0.  ],\n",
      "       [ -4.74,   1.76,    nan,    nan,   0.  ],\n",
      "       [ -3.75,   3.81,    nan,    nan,   0.  ],\n",
      "       [ -4.78,   1.53,    nan,    nan,   0.  ],\n",
      "       [ -6.5 ,   0.33,    nan,    nan,   0.  ],\n",
      "       [ -3.87,   2.84,    nan,    nan,   0.  ],\n",
      "       [ -4.71,   2.  ,    nan,    nan,   0.  ],\n",
      "       [ -5.83,   1.3 ,    nan,    nan,   0.  ],\n",
      "       [ -3.66,   2.59,    nan,    nan,   0.  ],\n",
      "       [ -5.75,   0.96,    nan,    nan,   0.  ],\n",
      "       [ -4.38,   1.8 ,    nan,    nan,   0.  ],\n",
      "       [ -5.65,   0.98,    nan,    nan,   0.  ],\n",
      "       [ -3.72,   3.11,    nan,    nan,   0.  ],\n",
      "       [ -2.91,   3.64,    nan,    nan,   0.  ],\n",
      "       [ -5.2 ,   1.29,    nan,    nan,   0.  ],\n",
      "       [ -3.78,   2.79,    nan,    nan,   0.  ],\n",
      "       [ -4.33,   2.03,    nan,    nan,   0.  ],\n",
      "       [ -4.26,   2.09,    nan,    nan,   0.  ],\n",
      "       [ -4.27,   3.33,    nan,    nan,   0.  ],\n",
      "       [ -3.69,   3.02,    nan,    nan,   0.  ],\n",
      "       [ -7.16,   0.25,    nan,    nan,   0.  ],\n",
      "       [ -2.91,   5.36,    nan,    nan,   0.  ],\n",
      "       [ -4.71,   1.74,    nan,    nan,   0.  ],\n",
      "       [ -4.11,   3.15,    nan,    nan,   0.  ],\n",
      "       [ -9.5 ,  -1.86,    nan,    nan,   0.  ],\n",
      "       [ -7.81,  -0.36,    nan,    nan,   0.  ],\n",
      "       [ -6.51,   0.27,    nan,    nan,   0.  ],\n",
      "       [ -4.3 ,   2.06,    nan,    nan,   0.  ],\n",
      "       [ -3.64,   2.55,    nan,    nan,   0.  ],\n",
      "       [ -5.72,   0.69,    nan,    nan,   0.  ],\n",
      "       [ -8.11,  -0.37,    nan,    nan,   0.  ],\n",
      "       [ -5.44,   1.19,    nan,    nan,   0.  ],\n",
      "       [-10.67,  -2.1 ,    nan,    nan,   0.  ],\n",
      "       [ -5.59,   0.55,    nan,    nan,   0.  ],\n",
      "       [ -3.68,   2.78,    nan,    nan,   0.  ],\n",
      "       [ -4.02,   3.09,    nan,    nan,   0.  ],\n",
      "       [ -5.64,   1.88,    nan,    nan,   0.  ],\n",
      "       [ -4.5 ,   2.12,    nan,    nan,   0.  ],\n",
      "       [ -6.86,  -0.16,    nan,    nan,   0.  ],\n",
      "       [ -2.13,   4.53,    nan,    nan,   0.  ],\n",
      "       [ -6.29,   1.88,    nan,    nan,   0.  ],\n",
      "       [ -3.73,   2.95,    nan,    nan,   0.  ],\n",
      "       [ -7.32,  -0.78,    nan,    nan,   0.  ],\n",
      "       [ -6.09,   0.51,    nan,    nan,   0.  ],\n",
      "       [ -5.22,   1.16,    nan,    nan,   0.  ],\n",
      "       [ -4.41,   2.19,    nan,    nan,   0.  ],\n",
      "       [ -4.58,   1.94,    nan,    nan,   0.  ],\n",
      "       [ -4.44,   2.1 ,    nan,    nan,   0.  ],\n",
      "       [ -6.09,   0.39,    nan,    nan,   0.  ],\n",
      "       [ -4.45,   2.21,    nan,    nan,   0.  ],\n",
      "       [ -5.51,   0.94,    nan,    nan,   0.  ],\n",
      "       [ -3.28,   3.41,    nan,    nan,   0.  ],\n",
      "       [ -3.95,   2.62,    nan,    nan,   0.  ],\n",
      "       [-11.28,  -3.63,    nan,    nan,   0.  ],\n",
      "       [ -4.32,   2.5 ,    nan,    nan,   0.  ],\n",
      "       [ -5.86,   0.45,    nan,    nan,   0.  ],\n",
      "       [ -3.21,   3.15,    nan,    nan,   0.  ],\n",
      "       [ -7.06,   0.57,    nan,    nan,   0.  ],\n",
      "       [ -3.8 ,   2.95,    nan,    nan,   0.  ],\n",
      "       [ -4.36,   2.81,    nan,    nan,   0.  ],\n",
      "       [ -5.06,   1.1 ,    nan,    nan,   0.  ],\n",
      "       [ -4.38,   2.11,    nan,    nan,   0.  ],\n",
      "       [ -4.5 ,   2.38,    nan,    nan,   0.  ],\n",
      "       [ -4.88,   2.02,    nan,    nan,   0.  ],\n",
      "       [ -7.96,   0.36,    nan,    nan,   0.  ],\n",
      "       [ -4.59,   1.92,    nan,    nan,   0.  ],\n",
      "       [ -6.08,   0.4 ,    nan,    nan,   0.  ],\n",
      "       [ -5.83,   1.27,    nan,    nan,   0.  ],\n",
      "       [ -3.47,   3.01,    nan,    nan,   0.  ],\n",
      "       [ -5.35,   2.63,    nan,    nan,   0.  ],\n",
      "       [ -4.11,   2.81,    nan,    nan,   0.  ],\n",
      "       [ -1.76,   5.76,    nan,    nan,   0.  ],\n",
      "       [ -5.19,   1.06,    nan,    nan,   0.  ],\n",
      "       [ -5.82,   1.09,    nan,    nan,   0.  ],\n",
      "       [ -3.99,   2.36,    nan,    nan,   0.  ],\n",
      "       [ -4.24,   2.74,    nan,    nan,   0.  ],\n",
      "       [ -5.07,   1.63,    nan,    nan,   0.  ],\n",
      "       [ -8.25,  -0.74,    nan,    nan,   0.  ],\n",
      "       [ -3.92,   2.43,    nan,    nan,   0.  ],\n",
      "       [ -4.64,   2.12,    nan,    nan,   0.  ],\n",
      "       [ -7.37,  -0.14,    nan,    nan,   0.  ],\n",
      "       [ -5.91,   0.96,    nan,    nan,   0.  ],\n",
      "       [ -7.99,  -0.78,    nan,    nan,   0.  ],\n",
      "       [ -3.94,   2.59,    nan,    nan,   0.  ],\n",
      "       [ -4.21,   2.38,    nan,    nan,   0.  ],\n",
      "       [ -3.67,   3.  ,    nan,    nan,   0.  ],\n",
      "       [ -3.19,   3.46,    nan,    nan,   0.  ],\n",
      "       [ -6.35,   0.42,    nan,    nan,   0.  ],\n",
      "       [ -5.11,   1.78,    nan,    nan,   0.  ],\n",
      "       [ -3.75,   2.69,    nan,    nan,   0.  ],\n",
      "       [ -5.24,   1.76,    nan,    nan,   0.  ],\n",
      "       [ -4.94,   1.86,    nan,    nan,   0.  ],\n",
      "       [ -5.7 ,   0.43,    nan,    nan,   0.  ],\n",
      "       [ -3.14,   3.11,    nan,    nan,   0.  ],\n",
      "       [ -4.04,   3.37,    nan,    nan,   0.  ],\n",
      "       [ -4.39,   2.7 ,    nan,    nan,   0.  ],\n",
      "       [ -4.02,   2.41,    nan,    nan,   0.  ],\n",
      "       [ -3.54,   2.77,    nan,    nan,   0.  ],\n",
      "       [ -7.5 ,   0.11,    nan,    nan,   0.  ],\n",
      "       [ -6.22,   0.76,    nan,    nan,   0.  ],\n",
      "       [ -5.61,   0.59,    nan,    nan,   0.  ],\n",
      "       [ -3.31,   2.95,    nan,    nan,   0.  ],\n",
      "       [ -4.16,   3.72,    nan,    nan,   0.  ],\n",
      "       [ -6.61,   0.26,    nan,    nan,   0.  ],\n",
      "       [ -4.74,   1.54,    nan,    nan,   0.  ],\n",
      "       [ -5.07,   1.48,    nan,    nan,   0.  ],\n",
      "       [ -7.79,  -0.54,    nan,    nan,   0.  ],\n",
      "       [  0.15,   8.18,    nan,    nan,   0.  ],\n",
      "       [ -6.76,   0.15,    nan,    nan,   0.  ],\n",
      "       [ -1.74,   5.42,    nan,    nan,   0.  ],\n",
      "       [ -4.68,   1.56,    nan,    nan,   0.  ],\n",
      "       [ -4.14,   2.39,    nan,    nan,   0.  ],\n",
      "       [ -5.13,   1.69,    nan,    nan,   0.  ],\n",
      "       [ -3.11,   3.42,    nan,    nan,   0.  ],\n",
      "       [ -4.63,   1.93,    nan,    nan,   0.  ],\n",
      "       [ -5.32,   1.34,    nan,    nan,   0.  ],\n",
      "       [ -6.14,   2.85,    nan,    nan,   0.  ],\n",
      "       [ -1.57,   5.16,    nan,    nan,   0.  ],\n",
      "       [ -4.68,   2.07,    nan,    nan,   0.  ],\n",
      "       [ -4.94,   2.69,    nan,    nan,   0.  ],\n",
      "       [ -3.65,   2.95,    nan,    nan,   0.  ],\n",
      "       [ -5.01,   1.73,    nan,    nan,   0.  ],\n",
      "       [ -7.77,  -1.04,    nan,    nan,   0.  ],\n",
      "       [ -6.7 ,  -0.07,    nan,    nan,   0.  ],\n",
      "       [ -4.29,   2.15,    nan,    nan,   0.  ],\n",
      "       [ -3.56,   3.19,    nan,    nan,   0.  ],\n",
      "       [ -4.37,   2.04,    nan,    nan,   0.  ],\n",
      "       [ -6.73,  -0.14,    nan,    nan,   0.  ],\n",
      "       [ -4.8 ,   2.  ,    nan,    nan,   0.  ],\n",
      "       [ -5.3 ,   1.01,    nan,    nan,   0.  ],\n",
      "       [ -6.47,   0.32,    nan,    nan,   0.  ],\n",
      "       [ -2.42,   4.89,    nan,    nan,   0.  ],\n",
      "       [ -4.49,   2.11,    nan,    nan,   0.  ],\n",
      "       [ -4.49,   2.02,    nan,    nan,   0.  ],\n",
      "       [ -3.71,   2.63,    nan,    nan,   0.  ],\n",
      "       [ -5.37,   1.25,    nan,    nan,   0.  ],\n",
      "       [ -3.17,   3.56,    nan,    nan,   0.  ],\n",
      "       [  0.63,   8.05,    nan,    nan,   0.  ],\n",
      "       [ -5.2 ,   1.81,    nan,    nan,   0.  ],\n",
      "       [ -5.34,   1.03,    nan,    nan,   0.  ],\n",
      "       [ -3.66,   3.61,    nan,    nan,   0.  ],\n",
      "       [ -5.24,   1.09,    nan,    nan,   0.  ],\n",
      "       [  0.13,   8.24,    nan,    nan,   0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n",
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 20.396812\n",
      "Time per LP neuron 0.203968\n",
      "LP used on 100 neurons.\n",
      "Median global rank: 0.497857\n",
      "Median tigthness of hat bounds: 22.556801 \n",
      "\n",
      "Min tigthness of hat bounds: 14.557036 \n",
      "\n",
      "Max tigthness of hat bounds: 33.312678 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.073e+01,  6.270e+00,  1.000e-01,  1.600e-01,  1.000e+00],\n",
      "       [-1.039e+01,  6.080e+00,  4.900e-01,  4.800e-01,  1.000e+00],\n",
      "       [-1.645e+01,  1.179e+01,  2.700e-01,  3.000e-01,  0.000e+00],\n",
      "       [-2.056e+01,  1.146e+01,  1.200e-01,  1.900e-01,  0.000e+00],\n",
      "       [-9.210e+00,  6.510e+00,  7.300e-01,  7.500e-01,  1.000e+00],\n",
      "       [-1.927e+01,  9.150e+00,  5.700e-01,  5.600e-01,  0.000e+00],\n",
      "       [-1.606e+01,  1.440e+01,  3.600e-01,  3.800e-01,  0.000e+00],\n",
      "       [-1.787e+01,  1.087e+01,  1.000e-01,  1.600e-01,  0.000e+00],\n",
      "       [-1.217e+01,  4.430e+00,  6.300e-01,  6.000e-01,  1.000e+00],\n",
      "       [-8.390e+00,  7.070e+00,  5.300e-01,  5.200e-01,  1.000e+00],\n",
      "       [-2.158e+01,  1.171e+01,  1.000e-02,  0.000e+00,  0.000e+00],\n",
      "       [-8.640e+00,  6.970e+00,  6.800e-01,  6.800e-01,  1.000e+00],\n",
      "       [-7.550e+00,  1.108e+01,  5.000e-02,  6.000e-02,  1.000e+00],\n",
      "       [-2.001e+01,  1.227e+01,  6.500e-01,  6.200e-01,  0.000e+00],\n",
      "       [-1.491e+01,  1.453e+01,  5.600e-01,  5.400e-01,  0.000e+00],\n",
      "       [-1.539e+01,  1.317e+01,  9.200e-01,  9.000e-01,  0.000e+00],\n",
      "       [-1.060e+01,  5.760e+00,  3.000e-02,  3.000e-02,  1.000e+00],\n",
      "       [-1.714e+01,  1.148e+01,  6.200e-01,  5.900e-01,  0.000e+00],\n",
      "       [-1.881e+01,  1.003e+01,  6.400e-01,  6.000e-01,  0.000e+00],\n",
      "       [-1.795e+01,  1.019e+01,  6.800e-01,  6.600e-01,  0.000e+00],\n",
      "       [-1.595e+01,  1.262e+01,  9.800e-01,  9.600e-01,  0.000e+00],\n",
      "       [-1.026e+01,  6.420e+00,  4.600e-01,  4.600e-01,  1.000e+00],\n",
      "       [-1.849e+01,  8.720e+00,  4.000e-02,  4.000e-02,  0.000e+00],\n",
      "       [-8.370e+00,  9.600e+00,  1.500e-01,  2.100e-01,  1.000e+00],\n",
      "       [-1.642e+01,  1.307e+01,  5.300e-01,  5.300e-01,  0.000e+00],\n",
      "       [-9.880e+00,  7.670e+00,  5.600e-01,  5.500e-01,  1.000e+00],\n",
      "       [-1.675e+01,  1.425e+01,  8.100e-01,  8.200e-01,  0.000e+00],\n",
      "       [-1.243e+01,  4.850e+00,  4.500e-01,  4.500e-01,  1.000e+00],\n",
      "       [-1.746e+01,  1.385e+01,  1.000e+00,  1.000e+00,  0.000e+00],\n",
      "       [-1.736e+01,  1.261e+01,  7.900e-01,  8.100e-01,  0.000e+00],\n",
      "       [-1.319e+01,  5.450e+00,  7.300e-01,  7.700e-01,  1.000e+00],\n",
      "       [-1.709e+01,  1.399e+01,  1.400e-01,  2.000e-01,  0.000e+00],\n",
      "       [-1.842e+01,  1.000e+01,  6.600e-01,  6.400e-01,  0.000e+00],\n",
      "       [-1.015e+01,  9.190e+00,  2.100e-01,  2.500e-01,  1.000e+00],\n",
      "       [-2.129e+01,  1.005e+01,  7.300e-01,  7.600e-01,  0.000e+00],\n",
      "       [-1.995e+01,  1.060e+01,  6.000e-02,  8.000e-02,  0.000e+00],\n",
      "       [-1.670e+01,  1.322e+01,  9.100e-01,  8.900e-01,  0.000e+00],\n",
      "       [-1.199e+01,  5.880e+00,  3.300e-01,  3.400e-01,  1.000e+00],\n",
      "       [-9.640e+00,  5.910e+00,  2.100e-01,  2.600e-01,  1.000e+00],\n",
      "       [-1.048e+01,  6.430e+00,  7.100e-01,  7.200e-01,  1.000e+00],\n",
      "       [-8.910e+00,  6.480e+00,  7.300e-01,  7.700e-01,  1.000e+00],\n",
      "       [-1.869e+01,  1.110e+01,  5.000e-02,  6.000e-02,  0.000e+00],\n",
      "       [-1.126e+01,  7.710e+00,  7.000e-02,  1.000e-01,  1.000e+00],\n",
      "       [-1.594e+01,  1.420e+01,  6.400e-01,  6.100e-01,  0.000e+00],\n",
      "       [-8.830e+00,  7.800e+00,  7.400e-01,  7.800e-01,  1.000e+00],\n",
      "       [-9.300e+00,  9.290e+00,  6.000e-01,  5.700e-01,  1.000e+00],\n",
      "       [-1.614e+01,  1.118e+01,  1.600e-01,  2.200e-01,  0.000e+00],\n",
      "       [-1.047e+01,  8.330e+00,  5.400e-01,  5.300e-01,  1.000e+00],\n",
      "       [-1.645e+01,  1.337e+01,  3.800e-01,  3.900e-01,  0.000e+00],\n",
      "       [-8.490e+00,  1.041e+01,  8.000e-02,  1.200e-01,  1.000e+00],\n",
      "       [-1.764e+01,  1.314e+01,  1.200e-01,  1.800e-01,  0.000e+00],\n",
      "       [-8.230e+00,  8.710e+00,  9.600e-01,  9.400e-01,  1.000e+00],\n",
      "       [-1.527e+01,  1.156e+01,  6.700e-01,  6.600e-01,  0.000e+00],\n",
      "       [-1.015e+01,  8.040e+00,  7.900e-01,  7.900e-01,  1.000e+00],\n",
      "       [-1.671e+01,  1.307e+01,  4.900e-01,  4.900e-01,  0.000e+00],\n",
      "       [-8.100e+00,  8.800e+00,  6.200e-01,  5.900e-01,  1.000e+00],\n",
      "       [-8.970e+00,  7.670e+00,  6.900e-01,  6.900e-01,  1.000e+00],\n",
      "       [-1.889e+01,  8.620e+00,  8.000e-02,  1.300e-01,  0.000e+00],\n",
      "       [-1.479e+01,  1.437e+01,  6.000e-01,  5.800e-01,  0.000e+00],\n",
      "       [-8.670e+00,  7.950e+00,  2.000e-02,  2.000e-02,  1.000e+00],\n",
      "       [-1.904e+01,  9.690e+00,  8.000e-01,  8.100e-01,  0.000e+00],\n",
      "       [-1.123e+01,  6.510e+00,  6.800e-01,  6.700e-01,  1.000e+00],\n",
      "       [-2.172e+01,  9.930e+00,  3.500e-01,  3.600e-01,  0.000e+00],\n",
      "       [-9.840e+00,  7.030e+00,  9.500e-01,  9.200e-01,  1.000e+00],\n",
      "       [-1.725e+01,  1.228e+01,  4.500e-01,  4.500e-01,  0.000e+00],\n",
      "       [-8.630e+00,  8.130e+00,  9.900e-01,  9.900e-01,  1.000e+00],\n",
      "       [-1.644e+01,  1.012e+01,  8.800e-01,  8.700e-01,  0.000e+00],\n",
      "       [-9.150e+00,  6.700e+00,  9.900e-01,  9.900e-01,  1.000e+00],\n",
      "       [-1.659e+01,  1.210e+01,  6.600e-01,  6.500e-01,  0.000e+00],\n",
      "       [-1.415e+01,  1.316e+01,  4.800e-01,  4.700e-01,  0.000e+00],\n",
      "       [-1.212e+01,  7.110e+00,  5.500e-01,  5.400e-01,  1.000e+00],\n",
      "       [-9.670e+00,  6.520e+00,  3.400e-01,  3.500e-01,  1.000e+00],\n",
      "       [-1.848e+01,  1.168e+01,  4.200e-01,  4.300e-01,  0.000e+00],\n",
      "       [-1.255e+01,  4.020e+00,  4.100e-01,  4.200e-01,  1.000e+00],\n",
      "       [-1.568e+01,  1.634e+01,  7.900e-01,  8.000e-01,  0.000e+00],\n",
      "       [-1.387e+01,  1.509e+01,  6.000e-02,  9.000e-02,  0.000e+00],\n",
      "       [-1.059e+01,  6.750e+00,  3.900e-01,  4.100e-01,  1.000e+00],\n",
      "       [-1.708e+01,  1.222e+01,  2.600e-01,  2.900e-01,  0.000e+00],\n",
      "       [-2.085e+01,  1.020e+01,  2.000e-02,  1.000e-02,  0.000e+00],\n",
      "       [-9.210e+00,  7.260e+00,  6.600e-01,  6.500e-01,  1.000e+00],\n",
      "       [-1.071e+01,  8.050e+00,  1.000e-01,  1.500e-01,  1.000e+00],\n",
      "       [-1.781e+01,  1.078e+01,  1.700e-01,  2.300e-01,  0.000e+00],\n",
      "       [-9.290e+00,  1.158e+01,  1.100e-01,  1.700e-01,  1.000e+00],\n",
      "       [-1.881e+01,  1.062e+01,  3.600e-01,  3.700e-01,  0.000e+00],\n",
      "       [-8.550e+00,  7.200e+00,  3.900e-01,  4.000e-01,  1.000e+00],\n",
      "       [-9.840e+00,  6.080e+00,  4.300e-01,  4.300e-01,  1.000e+00],\n",
      "       [-1.380e+01,  1.448e+01,  7.200e-01,  7.300e-01,  0.000e+00],\n",
      "       [-1.149e+01,  5.200e+00,  3.400e-01,  3.400e-01,  1.000e+00],\n",
      "       [-1.116e+01,  5.390e+00,  3.700e-01,  3.800e-01,  1.000e+00],\n",
      "       [-1.169e+01,  6.890e+00,  5.000e-02,  7.000e-02,  1.000e+00],\n",
      "       [-1.150e+01,  5.360e+00,  6.600e-01,  6.400e-01,  1.000e+00],\n",
      "       [-1.934e+01,  1.166e+01,  7.900e-01,  7.900e-01,  0.000e+00],\n",
      "       [-9.690e+00,  7.230e+00,  5.100e-01,  5.100e-01,  1.000e+00],\n",
      "       [-9.960e+00,  5.620e+00,  1.000e-01,  1.500e-01,  1.000e+00],\n",
      "       [-1.068e+01,  9.080e+00,  4.200e-01,  4.200e-01,  1.000e+00],\n",
      "       [-9.220e+00,  6.460e+00,  2.900e-01,  3.100e-01,  1.000e+00],\n",
      "       [-9.510e+00,  6.230e+00,  7.200e-01,  7.400e-01,  1.000e+00],\n",
      "       [-1.278e+01,  5.840e+00,  3.000e-02,  3.000e-02,  1.000e+00],\n",
      "       [-1.991e+01,  1.264e+01,  2.700e-01,  3.100e-01,  0.000e+00],\n",
      "       [-7.340e+00,  7.600e+00,  1.800e-01,  2.400e-01,  1.000e+00],\n",
      "       [-1.065e+01,  5.760e+00,  4.400e-01,  4.400e-01,  1.000e+00],\n",
      "       [-1.935e+01,  1.122e+01,  9.800e-01,  9.700e-01,  0.000e+00],\n",
      "       [-1.089e+01,  6.280e+00,  7.900e-01,  8.000e-01,  1.000e+00],\n",
      "       [-1.564e+01,  1.210e+01,  8.700e-01,  8.700e-01,  0.000e+00],\n",
      "       [-1.977e+01,  9.960e+00,  9.500e-01,  9.300e-01,  0.000e+00],\n",
      "       [-1.819e+01,  9.820e+00,  5.600e-01,  5.500e-01,  0.000e+00],\n",
      "       [-1.686e+01,  1.054e+01,  9.300e-01,  9.100e-01,  0.000e+00],\n",
      "       [-1.174e+01,  5.260e+00,  9.900e-01,  9.800e-01,  1.000e+00],\n",
      "       [-9.570e+00,  6.630e+00,  9.700e-01,  9.500e-01,  1.000e+00],\n",
      "       [-1.217e+01,  4.540e+00,  7.500e-01,  7.800e-01,  1.000e+00],\n",
      "       [-1.031e+01,  5.260e+00,  6.000e-02,  7.000e-02,  1.000e+00],\n",
      "       [-8.060e+00,  1.080e+01,  2.500e-01,  2.800e-01,  1.000e+00],\n",
      "       [-1.393e+01,  1.239e+01,  6.100e-01,  5.800e-01,  0.000e+00],\n",
      "       [-1.614e+01,  1.124e+01,  9.600e-01,  9.400e-01,  0.000e+00],\n",
      "       [-1.558e+01,  1.441e+01,  1.100e-01,  1.700e-01,  0.000e+00],\n",
      "       [-1.223e+01,  1.666e+01,  7.200e-01,  7.400e-01,  0.000e+00],\n",
      "       [-1.476e+01,  1.509e+01,  2.000e-01,  2.500e-01,  0.000e+00],\n",
      "       [-1.806e+01,  1.250e+01,  8.600e-01,  8.500e-01,  0.000e+00],\n",
      "       [-1.578e+01,  8.460e+00,  3.900e-01,  4.000e-01,  0.000e+00],\n",
      "       [-2.032e+01,  7.460e+00,  1.600e-01,  2.200e-01,  0.000e+00],\n",
      "       [-1.513e+01,  1.450e+01,  3.300e-01,  3.300e-01,  0.000e+00],\n",
      "       [-1.247e+01,  5.880e+00,  4.000e-02,  4.000e-02,  1.000e+00],\n",
      "       [-9.580e+00,  6.690e+00,  9.600e-01,  9.300e-01,  1.000e+00],\n",
      "       [-1.669e+01,  1.050e+01,  9.800e-01,  9.700e-01,  0.000e+00],\n",
      "       [-1.264e+01,  5.830e+00,  2.200e-01,  2.700e-01,  1.000e+00],\n",
      "       [-1.094e+01,  6.520e+00,  7.000e-01,  7.100e-01,  1.000e+00],\n",
      "       [-1.005e+01,  8.450e+00,  5.000e-02,  5.000e-02,  1.000e+00],\n",
      "       [-1.893e+01,  1.112e+01,  8.000e-02,  1.200e-01,  0.000e+00],\n",
      "       [-5.730e+00,  1.351e+01,  9.000e-02,  1.400e-01,  1.000e+00],\n",
      "       [-1.614e+01,  1.302e+01,  9.300e-01,  9.000e-01,  0.000e+00],\n",
      "       [-1.997e+01,  8.340e+00,  6.500e-01,  6.300e-01,  0.000e+00],\n",
      "       [-1.799e+01,  1.043e+01,  6.800e-01,  6.700e-01,  0.000e+00],\n",
      "       [-1.883e+01,  1.151e+01,  2.500e-01,  2.900e-01,  0.000e+00],\n",
      "       [-1.624e+01,  8.620e+00,  5.000e-01,  5.000e-01,  0.000e+00],\n",
      "       [-1.864e+01,  1.153e+01,  6.000e-02,  9.000e-02,  0.000e+00],\n",
      "       [-1.597e+01,  1.266e+01,  5.800e-01,  5.700e-01,  0.000e+00],\n",
      "       [-8.680e+00,  7.370e+00,  7.000e-01,  7.000e-01,  1.000e+00],\n",
      "       [-1.793e+01,  1.068e+01,  4.600e-01,  4.600e-01,  0.000e+00],\n",
      "       [-2.178e+01,  9.270e+00,  7.000e-01,  7.000e-01,  0.000e+00],\n",
      "       [-1.743e+01,  1.140e+01,  5.200e-01,  5.200e-01,  0.000e+00],\n",
      "       [-8.430e+00,  8.190e+00,  8.500e-01,  8.400e-01,  1.000e+00],\n",
      "       [-1.976e+01,  1.063e+01,  2.600e-01,  3.000e-01,  0.000e+00],\n",
      "       [-8.290e+00,  6.770e+00,  6.900e-01,  6.900e-01,  1.000e+00],\n",
      "       [-7.620e+00,  8.310e+00,  9.900e-01,  9.800e-01,  1.000e+00],\n",
      "       [-1.712e+01,  1.349e+01,  5.000e-01,  4.900e-01,  0.000e+00],\n",
      "       [-1.820e+01,  1.191e+01,  3.400e-01,  3.500e-01,  0.000e+00],\n",
      "       [-8.650e+00,  7.940e+00,  9.800e-01,  9.600e-01,  1.000e+00],\n",
      "       [-8.780e+00,  8.260e+00,  3.300e-01,  3.300e-01,  1.000e+00],\n",
      "       [-9.920e+00,  6.420e+00,  5.000e-01,  5.000e-01,  1.000e+00],\n",
      "       [-1.333e+01,  6.040e+00,  7.000e-01,  7.100e-01,  1.000e+00],\n",
      "       [-9.260e+00,  5.290e+00,  6.400e-01,  6.100e-01,  1.000e+00],\n",
      "       [-8.190e+00,  8.810e+00,  7.000e-02,  1.100e-01,  1.000e+00],\n",
      "       [-1.118e+01,  5.610e+00,  7.300e-01,  7.500e-01,  1.000e+00],\n",
      "       [-1.005e+01,  7.370e+00,  8.300e-01,  8.200e-01,  1.000e+00],\n",
      "       [-1.948e+01,  1.022e+01,  9.700e-01,  9.500e-01,  0.000e+00],\n",
      "       [-1.144e+01,  5.190e+00,  8.000e-02,  1.100e-01,  1.000e+00],\n",
      "       [-1.761e+01,  9.320e+00,  4.900e-01,  4.800e-01,  0.000e+00],\n",
      "       [-7.260e+00,  1.011e+01,  7.100e-01,  7.200e-01,  1.000e+00],\n",
      "       [-1.032e+01,  6.480e+00,  9.400e-01,  9.100e-01,  1.000e+00],\n",
      "       [-1.900e+01,  1.084e+01,  2.000e-02,  2.000e-02,  0.000e+00],\n",
      "       [-9.970e+00,  6.550e+00,  8.700e-01,  8.600e-01,  1.000e+00],\n",
      "       [-9.180e+00,  7.430e+00,  7.300e-01,  7.500e-01,  1.000e+00],\n",
      "       [-7.020e+00,  9.840e+00,  8.700e-01,  8.500e-01,  1.000e+00],\n",
      "       [-1.855e+01,  9.440e+00,  9.000e-02,  1.400e-01,  0.000e+00],\n",
      "       [-8.740e+00,  7.280e+00,  7.000e-02,  1.000e-01,  1.000e+00],\n",
      "       [-1.817e+01,  9.080e+00,  3.000e-01,  3.200e-01,  0.000e+00],\n",
      "       [-1.811e+01,  1.084e+01,  1.700e-01,  2.300e-01,  0.000e+00],\n",
      "       [-1.028e+01,  7.250e+00,  8.000e-02,  1.300e-01,  1.000e+00],\n",
      "       [-1.708e+01,  1.183e+01,  9.000e-01,  8.900e-01,  0.000e+00],\n",
      "       [-1.885e+01,  9.620e+00,  1.300e-01,  1.900e-01,  0.000e+00],\n",
      "       [-8.950e+00,  7.630e+00,  3.000e-01,  3.200e-01,  1.000e+00],\n",
      "       [-1.039e+01,  6.550e+00,  6.500e-01,  6.200e-01,  1.000e+00],\n",
      "       [-1.548e+01,  1.420e+01,  8.600e-01,  8.400e-01,  0.000e+00],\n",
      "       [-1.433e+01,  1.439e+01,  1.900e-01,  2.400e-01,  0.000e+00],\n",
      "       [-1.723e+01,  1.553e+01,  6.800e-01,  6.800e-01,  0.000e+00],\n",
      "       [-9.340e+00,  9.060e+00,  1.400e-01,  2.000e-01,  1.000e+00],\n",
      "       [-1.404e+01,  1.439e+01,  1.500e-01,  2.100e-01,  0.000e+00],\n",
      "       [-1.294e+01,  3.800e+00,  8.700e-01,  8.600e-01,  1.000e+00],\n",
      "       [-1.029e+01,  8.150e+00,  4.100e-01,  4.100e-01,  1.000e+00],\n",
      "       [-1.070e+01,  7.390e+00,  8.500e-01,  8.300e-01,  1.000e+00],\n",
      "       [-1.951e+01,  1.033e+01,  9.900e-01,  1.000e+00,  0.000e+00],\n",
      "       [-1.894e+01,  9.590e+00,  3.600e-01,  3.700e-01,  0.000e+00],\n",
      "       [-1.115e+01,  6.100e+00,  5.700e-01,  5.600e-01,  1.000e+00],\n",
      "       [-1.069e+01,  6.290e+00,  8.400e-01,  8.300e-01,  1.000e+00],\n",
      "       [-1.531e+01,  3.750e+00,  1.200e-01,  1.800e-01,  1.000e+00],\n",
      "       [-1.268e+01,  4.550e+00,  3.600e-01,  3.600e-01,  1.000e+00],\n",
      "       [-1.753e+01,  1.578e+01,  7.200e-01,  7.300e-01,  0.000e+00],\n",
      "       [-6.730e+00,  9.790e+00,  9.500e-01,  9.200e-01,  1.000e+00],\n",
      "       [-1.453e+01,  1.400e+01,  4.700e-01,  4.700e-01,  0.000e+00],\n",
      "       [-1.833e+01,  1.267e+01,  2.400e-01,  2.800e-01,  0.000e+00],\n",
      "       [-1.558e+01,  1.490e+01,  8.900e-01,  8.800e-01,  0.000e+00],\n",
      "       [-1.819e+01,  1.230e+01,  3.900e-01,  3.900e-01,  0.000e+00],\n",
      "       [-1.798e+01,  1.195e+01,  2.100e-01,  2.500e-01,  0.000e+00],\n",
      "       [-2.115e+01,  8.960e+00,  5.100e-01,  5.000e-01,  0.000e+00],\n",
      "       [-1.285e+01,  7.150e+00,  5.000e-02,  5.000e-02,  1.000e+00],\n",
      "       [-1.957e+01,  1.108e+01,  4.300e-01,  4.400e-01,  0.000e+00],\n",
      "       [-1.885e+01,  1.119e+01,  8.900e-01,  8.800e-01,  0.000e+00],\n",
      "       [-1.224e+01,  3.440e+00,  2.300e-01,  2.700e-01,  1.000e+00],\n",
      "       [-1.085e+01,  8.560e+00,  6.500e-01,  6.300e-01,  1.000e+00],\n",
      "       [-1.380e+01,  5.640e+00,  6.000e-02,  8.000e-02,  1.000e+00]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n",
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 28.308021\n",
      "Time per LP neuron 0.283080\n",
      "LP used on 100 neurons.\n",
      "Median global rank: 0.476071\n",
      "Median tigthness of hat bounds: 110.117277 \n",
      "\n",
      "Min tigthness of hat bounds: 78.079737 \n",
      "\n",
      "Max tigthness of hat bounds: 155.293516 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-4.4240e+01,  4.0630e+01,  2.6000e-01,  2.1000e-01,  1.0000e+00],\n",
      "       [-4.9420e+01,  3.5840e+01,  4.7000e-01,  4.9000e-01,  1.0000e+00],\n",
      "       [-4.9080e+01,  2.9240e+01,  4.2000e-01,  4.0000e-01,  1.0000e+00],\n",
      "       [-4.1780e+01,  5.1960e+01,  7.8000e-01,  8.0000e-01,  1.0000e+00],\n",
      "       [-4.9760e+01,  4.3210e+01,  2.4000e-01,  1.8000e-01,  1.0000e+00],\n",
      "       [-7.9400e+01,  5.1900e+01,  8.2000e-01,  8.3000e-01,  0.0000e+00],\n",
      "       [-8.9460e+01,  4.3410e+01,  7.6000e-01,  7.7000e-01,  0.0000e+00],\n",
      "       [-8.3210e+01,  5.6890e+01,  9.5000e-01,  9.7000e-01,  0.0000e+00],\n",
      "       [-4.7260e+01,  4.2830e+01,  6.0000e-02,  4.0000e-02,  1.0000e+00],\n",
      "       [-7.5770e+01,  6.4180e+01,  3.5000e-01,  3.2000e-01,  0.0000e+00],\n",
      "       [-4.5160e+01,  4.8890e+01,  9.6000e-01,  9.8000e-01,  1.0000e+00],\n",
      "       [-8.3220e+01,  6.2310e+01,  1.0000e-02,  0.0000e+00,  0.0000e+00],\n",
      "       [-7.2310e+01,  5.8270e+01,  2.9000e-01,  2.5000e-01,  0.0000e+00],\n",
      "       [-5.1810e+01,  3.5150e+01,  8.2000e-01,  8.2000e-01,  1.0000e+00],\n",
      "       [-5.3370e+01,  2.7890e+01,  5.3000e-01,  5.8000e-01,  1.0000e+00],\n",
      "       [-5.4950e+01,  3.0550e+01,  5.3000e-01,  5.7000e-01,  1.0000e+00],\n",
      "       [-7.1610e+01,  6.3590e+01,  5.0000e-01,  5.3000e-01,  0.0000e+00],\n",
      "       [-4.4290e+01,  4.1500e+01,  6.1000e-01,  6.3000e-01,  1.0000e+00],\n",
      "       [-3.8640e+01,  5.0360e+01,  7.6000e-01,  7.8000e-01,  1.0000e+00],\n",
      "       [-4.4700e+01,  3.7780e+01,  4.7000e-01,  4.8000e-01,  1.0000e+00],\n",
      "       [-7.7780e+01,  5.5210e+01,  7.8000e-01,  7.9000e-01,  0.0000e+00],\n",
      "       [-7.1860e+01,  5.6290e+01,  4.4000e-01,  4.3000e-01,  0.0000e+00],\n",
      "       [-4.5430e+01,  4.2770e+01,  7.0000e-01,  7.0000e-01,  1.0000e+00],\n",
      "       [-5.5470e+01,  3.9380e+01,  2.7000e-01,  2.2000e-01,  1.0000e+00],\n",
      "       [-5.4450e+01,  3.8140e+01,  7.2000e-01,  7.2000e-01,  1.0000e+00],\n",
      "       [-7.8930e+01,  3.9110e+01,  4.0000e-02,  2.0000e-02,  0.0000e+00],\n",
      "       [-5.1790e+01,  3.4700e+01,  8.0000e-01,  8.1000e-01,  1.0000e+00],\n",
      "       [-4.3130e+01,  4.6280e+01,  7.4000e-01,  7.4000e-01,  1.0000e+00],\n",
      "       [-6.9510e+01,  6.8880e+01,  8.3000e-01,  8.5000e-01,  0.0000e+00],\n",
      "       [-5.5750e+01,  3.1460e+01,  4.4000e-01,  4.3000e-01,  1.0000e+00],\n",
      "       [-4.9050e+01,  4.0860e+01,  2.0000e-02,  1.0000e-02,  1.0000e+00],\n",
      "       [-8.5380e+01,  6.4490e+01,  7.4000e-01,  7.4000e-01,  0.0000e+00],\n",
      "       [-7.6170e+01,  6.0810e+01,  6.9000e-01,  6.9000e-01,  0.0000e+00],\n",
      "       [-4.7600e+01,  3.8720e+01,  2.2000e-01,  1.6000e-01,  1.0000e+00],\n",
      "       [-4.6690e+01,  4.9370e+01,  9.4000e-01,  9.6000e-01,  1.0000e+00],\n",
      "       [-5.8830e+01,  3.5600e+01,  7.6000e-01,  7.9000e-01,  1.0000e+00],\n",
      "       [-4.9130e+01,  3.7970e+01,  6.7000e-01,  6.7000e-01,  1.0000e+00],\n",
      "       [-1.1136e+02,  3.5810e+01,  6.6000e-01,  6.6000e-01,  0.0000e+00],\n",
      "       [-4.2110e+01,  3.5970e+01,  7.0000e-02,  4.0000e-02,  1.0000e+00],\n",
      "       [-5.0410e+01,  3.8190e+01,  5.4000e-01,  5.8000e-01,  1.0000e+00],\n",
      "       [-5.8170e+01,  3.5410e+01,  3.9000e-01,  3.7000e-01,  1.0000e+00],\n",
      "       [-8.7380e+01,  5.1190e+01,  6.3000e-01,  6.5000e-01,  0.0000e+00],\n",
      "       [-7.5990e+01,  5.9090e+01,  1.7000e-01,  1.2000e-01,  0.0000e+00],\n",
      "       [-8.4020e+01,  5.7770e+01,  4.8000e-01,  5.0000e-01,  0.0000e+00],\n",
      "       [-1.0673e+02,  4.4380e+01,  6.2000e-01,  6.4000e-01,  0.0000e+00],\n",
      "       [-4.4930e+01,  4.4460e+01,  1.0000e-01,  7.0000e-02,  1.0000e+00],\n",
      "       [-5.2550e+01,  3.5250e+01,  7.9000e-01,  8.1000e-01,  1.0000e+00],\n",
      "       [-8.3020e+01,  5.8070e+01,  1.9000e-01,  1.4000e-01,  0.0000e+00],\n",
      "       [-4.3790e+01,  4.0900e+01,  4.3000e-01,  4.2000e-01,  1.0000e+00],\n",
      "       [-7.6130e+01,  5.9220e+01,  3.0000e-01,  2.7000e-01,  0.0000e+00],\n",
      "       [-8.3220e+01,  6.4350e+01,  6.4000e-01,  6.6000e-01,  0.0000e+00],\n",
      "       [-9.7100e+01,  5.8190e+01,  4.0000e-02,  3.0000e-02,  0.0000e+00],\n",
      "       [-9.5620e+01,  4.7440e+01,  2.8000e-01,  2.3000e-01,  0.0000e+00],\n",
      "       [-9.2780e+01,  5.4160e+01,  5.2000e-01,  5.7000e-01,  0.0000e+00],\n",
      "       [-1.0348e+02,  3.4280e+01,  4.6000e-01,  4.7000e-01,  0.0000e+00],\n",
      "       [-8.2660e+01,  5.0010e+01,  3.1000e-01,  2.8000e-01,  0.0000e+00],\n",
      "       [-9.6730e+01,  4.4670e+01,  4.7000e-01,  4.9000e-01,  0.0000e+00],\n",
      "       [-8.3270e+01,  5.0460e+01,  5.8000e-01,  6.0000e-01,  0.0000e+00],\n",
      "       [-4.4510e+01,  3.9600e+01,  7.3000e-01,  7.3000e-01,  1.0000e+00],\n",
      "       [-8.4020e+01,  5.7830e+01,  2.8000e-01,  2.4000e-01,  0.0000e+00],\n",
      "       [-4.3440e+01,  4.7790e+01,  9.4000e-01,  9.4000e-01,  1.0000e+00],\n",
      "       [-7.3450e+01,  7.1530e+01,  2.8000e-01,  2.4000e-01,  0.0000e+00],\n",
      "       [-4.6420e+01,  4.3380e+01,  7.4000e-01,  7.3000e-01,  1.0000e+00],\n",
      "       [-9.2590e+01,  5.1850e+01,  5.7000e-01,  5.9000e-01,  0.0000e+00],\n",
      "       [-4.8080e+01,  4.2560e+01,  5.1000e-01,  5.4000e-01,  1.0000e+00],\n",
      "       [-6.8360e+01,  5.2190e+01,  7.6000e-01,  7.8000e-01,  0.0000e+00],\n",
      "       [-8.7640e+01,  3.9970e+01,  8.4000e-01,  8.7000e-01,  0.0000e+00],\n",
      "       [-4.5720e+01,  4.0360e+01,  5.4000e-01,  5.9000e-01,  1.0000e+00],\n",
      "       [-8.6930e+01,  5.1580e+01,  9.3000e-01,  9.3000e-01,  0.0000e+00],\n",
      "       [-8.2240e+01,  6.2160e+01,  4.9000e-01,  5.2000e-01,  0.0000e+00],\n",
      "       [-8.0010e+01,  7.5040e+01,  1.6000e-01,  1.1000e-01,  0.0000e+00],\n",
      "       [-4.1760e+01,  3.8550e+01,  4.2000e-01,  4.1000e-01,  1.0000e+00],\n",
      "       [-8.7570e+01,  5.8470e+01,  9.2000e-01,  9.3000e-01,  0.0000e+00],\n",
      "       [-4.4830e+01,  3.7330e+01,  4.0000e-02,  2.0000e-02,  1.0000e+00],\n",
      "       [-8.7150e+01,  5.6990e+01,  9.8000e-01,  1.0000e+00,  0.0000e+00],\n",
      "       [-4.6380e+01,  4.2510e+01,  6.1000e-01,  6.2000e-01,  1.0000e+00],\n",
      "       [-4.7390e+01,  3.3750e+01,  2.6000e-01,  2.0000e-01,  1.0000e+00],\n",
      "       [-5.0720e+01,  3.5200e+01,  8.2000e-01,  8.2000e-01,  1.0000e+00],\n",
      "       [-4.6570e+01,  3.7370e+01,  9.0000e-01,  9.2000e-01,  1.0000e+00],\n",
      "       [-5.2480e+01,  3.2980e+01,  5.1000e-01,  5.5000e-01,  1.0000e+00],\n",
      "       [-8.5550e+01,  4.7550e+01,  4.6000e-01,  4.7000e-01,  0.0000e+00],\n",
      "       [-7.3660e+01,  5.7260e+01,  4.0000e-01,  3.9000e-01,  0.0000e+00],\n",
      "       [-6.8020e+01,  2.3780e+01,  2.5000e-01,  1.9000e-01,  1.0000e+00],\n",
      "       [-8.5430e+01,  5.9780e+01,  9.3000e-01,  9.4000e-01,  0.0000e+00],\n",
      "       [-5.8210e+01,  3.4630e+01,  1.7000e-01,  1.3000e-01,  1.0000e+00],\n",
      "       [-8.1150e+01,  5.6020e+01,  2.7000e-01,  2.3000e-01,  0.0000e+00],\n",
      "       [-9.3150e+01,  4.1940e+01,  3.8000e-01,  3.5000e-01,  0.0000e+00],\n",
      "       [-5.6770e+01,  3.1050e+01,  1.7000e-01,  1.3000e-01,  1.0000e+00],\n",
      "       [-5.4830e+01,  3.6300e+01,  3.3000e-01,  3.0000e-01,  1.0000e+00],\n",
      "       [-4.5010e+01,  3.8030e+01,  2.2000e-01,  1.6000e-01,  1.0000e+00],\n",
      "       [-3.9480e+01,  4.3370e+01,  3.9000e-01,  3.6000e-01,  1.0000e+00],\n",
      "       [-4.7640e+01,  3.1760e+01,  9.4000e-01,  9.5000e-01,  1.0000e+00],\n",
      "       [-5.5780e+01,  3.5090e+01,  5.1000e-01,  5.5000e-01,  1.0000e+00],\n",
      "       [-8.3140e+01,  5.8580e+01,  2.2000e-01,  1.7000e-01,  0.0000e+00],\n",
      "       [-7.4530e+01,  6.6150e+01,  2.9000e-01,  2.5000e-01,  0.0000e+00],\n",
      "       [-7.4470e+01,  6.4790e+01,  3.2000e-01,  2.9000e-01,  0.0000e+00],\n",
      "       [-8.2000e+01,  5.7830e+01,  1.2000e-01,  8.0000e-02,  0.0000e+00],\n",
      "       [-4.3820e+01,  3.7590e+01,  2.7000e-01,  2.2000e-01,  1.0000e+00],\n",
      "       [-8.2900e+01,  4.9650e+01,  8.3000e-01,  8.6000e-01,  0.0000e+00],\n",
      "       [-9.1850e+01,  4.3940e+01,  2.5000e-01,  2.0000e-01,  0.0000e+00],\n",
      "       [-3.9940e+01,  4.3680e+01,  8.2000e-01,  8.4000e-01,  1.0000e+00],\n",
      "       [-7.3660e+01,  5.9210e+01,  6.0000e-01,  6.2000e-01,  0.0000e+00],\n",
      "       [-6.9390e+01,  6.0310e+01,  1.4000e-01,  9.0000e-02,  0.0000e+00],\n",
      "       [-5.6160e+01,  2.8680e+01,  7.5000e-01,  7.5000e-01,  1.0000e+00],\n",
      "       [-8.2810e+01,  5.2620e+01,  8.3000e-01,  8.5000e-01,  0.0000e+00],\n",
      "       [-4.3280e+01,  4.5300e+01,  6.8000e-01,  6.8000e-01,  1.0000e+00],\n",
      "       [-7.1010e+01,  6.8760e+01,  8.2000e-01,  8.3000e-01,  0.0000e+00],\n",
      "       [-8.5350e+01,  4.6100e+01,  1.7000e-01,  1.2000e-01,  0.0000e+00],\n",
      "       [-7.9180e+01,  6.6080e+01,  3.3000e-01,  3.0000e-01,  0.0000e+00],\n",
      "       [-4.8930e+01,  3.4180e+01,  4.6000e-01,  4.6000e-01,  1.0000e+00],\n",
      "       [-8.2230e+01,  5.7940e+01,  3.1000e-01,  2.8000e-01,  0.0000e+00],\n",
      "       [-4.2870e+01,  4.2010e+01,  4.5000e-01,  4.5000e-01,  1.0000e+00],\n",
      "       [-4.2950e+01,  4.3140e+01,  4.4000e-01,  4.2000e-01,  1.0000e+00],\n",
      "       [-7.5090e+01,  5.6870e+01,  3.6000e-01,  3.3000e-01,  0.0000e+00],\n",
      "       [-8.5480e+01,  5.4400e+01,  8.6000e-01,  8.8000e-01,  0.0000e+00],\n",
      "       [-7.8420e+01,  4.8850e+01,  6.4000e-01,  6.5000e-01,  0.0000e+00],\n",
      "       [-4.4850e+01,  3.9260e+01,  4.0000e-01,  4.0000e-01,  1.0000e+00],\n",
      "       [-7.2630e+01,  5.5470e+01,  7.2000e-01,  7.2000e-01,  0.0000e+00],\n",
      "       [-7.0370e+01,  6.2510e+01,  3.7000e-01,  3.4000e-01,  0.0000e+00],\n",
      "       [-8.7830e+01,  5.6770e+01,  6.8000e-01,  6.9000e-01,  0.0000e+00],\n",
      "       [-4.9870e+01,  3.4250e+01,  4.4000e-01,  4.4000e-01,  1.0000e+00],\n",
      "       [-6.4550e+01,  6.3550e+01,  3.3000e-01,  3.1000e-01,  0.0000e+00],\n",
      "       [-8.3240e+01,  6.2020e+01,  2.9000e-01,  2.5000e-01,  0.0000e+00],\n",
      "       [-4.4890e+01,  4.2940e+01,  3.1000e-01,  2.9000e-01,  1.0000e+00],\n",
      "       [-3.8390e+01,  4.0430e+01,  9.0000e-02,  6.0000e-02,  1.0000e+00],\n",
      "       [-4.6490e+01,  3.6090e+01,  9.0000e-02,  6.0000e-02,  1.0000e+00],\n",
      "       [-7.8460e+01,  5.2150e+01,  3.8000e-01,  3.6000e-01,  0.0000e+00],\n",
      "       [-4.8200e+01,  3.7290e+01,  8.3000e-01,  8.6000e-01,  1.0000e+00],\n",
      "       [-7.5790e+01,  4.8010e+01,  3.1000e-01,  2.7000e-01,  0.0000e+00],\n",
      "       [-5.2360e+01,  3.4070e+01,  8.8000e-01,  8.9000e-01,  1.0000e+00],\n",
      "       [-8.3350e+01,  5.6490e+01,  8.8000e-01,  9.0000e-01,  0.0000e+00],\n",
      "       [-4.4150e+01,  4.3570e+01,  8.5000e-01,  8.7000e-01,  1.0000e+00],\n",
      "       [-7.9970e+01,  6.1030e+01,  9.7000e-01,  9.9000e-01,  0.0000e+00],\n",
      "       [-4.9090e+01,  3.6180e+01,  9.4000e-01,  9.5000e-01,  1.0000e+00],\n",
      "       [-7.7930e+01,  5.4620e+01,  9.7000e-01,  9.8000e-01,  0.0000e+00],\n",
      "       [-8.4500e+01,  5.8920e+01,  9.5000e-01,  9.7000e-01,  0.0000e+00],\n",
      "       [-9.5190e+01,  5.2360e+01,  2.5000e-01,  1.9000e-01,  0.0000e+00],\n",
      "       [-9.2260e+01,  5.2240e+01,  8.2000e-01,  8.4000e-01,  0.0000e+00],\n",
      "       [-7.6390e+01,  5.2070e+01,  9.7000e-01,  9.9000e-01,  0.0000e+00],\n",
      "       [-5.8410e+01,  4.3770e+01,  8.7000e-01,  8.9000e-01,  1.0000e+00],\n",
      "       [-7.0280e+01,  6.5890e+01,  4.7000e-01,  4.8000e-01,  0.0000e+00],\n",
      "       [-5.2480e+01,  3.6390e+01,  9.5000e-01,  9.6000e-01,  1.0000e+00],\n",
      "       [-4.7790e+01,  4.4170e+01,  9.0000e-02,  5.0000e-02,  1.0000e+00],\n",
      "       [-4.3290e+01,  5.0470e+01,  2.0000e-01,  1.5000e-01,  1.0000e+00],\n",
      "       [-7.7780e+01,  6.3090e+01,  7.5000e-01,  7.5000e-01,  0.0000e+00],\n",
      "       [-4.3630e+01,  3.9790e+01,  4.8000e-01,  5.1000e-01,  1.0000e+00],\n",
      "       [-6.9600e+01,  6.4130e+01,  6.7000e-01,  6.7000e-01,  0.0000e+00],\n",
      "       [-8.3750e+01,  5.1230e+01,  5.2000e-01,  5.6000e-01,  0.0000e+00],\n",
      "       [-9.5970e+01,  4.4200e+01,  6.1000e-01,  6.3000e-01,  0.0000e+00],\n",
      "       [-4.5690e+01,  3.8800e+01,  2.4000e-01,  1.8000e-01,  1.0000e+00],\n",
      "       [-4.4520e+01,  4.0000e+01,  1.6000e-01,  1.1000e-01,  1.0000e+00],\n",
      "       [-6.3490e+01,  2.6940e+01,  1.5000e-01,  1.0000e-01,  1.0000e+00],\n",
      "       [-4.8330e+01,  4.0700e+01,  3.7000e-01,  3.4000e-01,  1.0000e+00],\n",
      "       [-5.9870e+01,  3.0440e+01,  2.1000e-01,  1.5000e-01,  1.0000e+00],\n",
      "       [-9.0660e+01,  5.8290e+01,  6.8000e-01,  6.8000e-01,  0.0000e+00],\n",
      "       [-5.2170e+01,  3.4600e+01,  4.9000e-01,  5.2000e-01,  1.0000e+00],\n",
      "       [-5.4390e+01,  3.0040e+01,  7.6000e-01,  7.7000e-01,  1.0000e+00],\n",
      "       [-9.6680e+01,  4.5420e+01,  3.6000e-01,  3.3000e-01,  0.0000e+00],\n",
      "       [-8.0670e+01,  5.9660e+01,  1.3000e-01,  9.0000e-02,  0.0000e+00],\n",
      "       [-5.5210e+01,  4.4170e+01,  7.1000e-01,  7.1000e-01,  1.0000e+00],\n",
      "       [-4.1740e+01,  3.9490e+01,  3.5000e-01,  3.2000e-01,  1.0000e+00],\n",
      "       [-4.7150e+01,  3.6380e+01,  1.0000e-01,  7.0000e-02,  1.0000e+00],\n",
      "       [-4.8340e+01,  3.9820e+01,  4.4000e-01,  4.4000e-01,  1.0000e+00],\n",
      "       [-7.5020e+01,  7.0010e+01,  8.6000e-01,  8.8000e-01,  0.0000e+00],\n",
      "       [-7.0380e+01,  6.0760e+01,  4.2000e-01,  4.1000e-01,  0.0000e+00],\n",
      "       [-5.0740e+01,  2.7460e+01,  9.9000e-01,  1.0000e+00,  1.0000e+00],\n",
      "       [-7.8830e+01,  6.3710e+01,  8.8000e-01,  9.0000e-01,  0.0000e+00],\n",
      "       [-4.5920e+01,  3.8970e+01,  4.0000e-01,  3.9000e-01,  1.0000e+00],\n",
      "       [-5.8220e+01,  2.6630e+01,  4.5000e-01,  4.6000e-01,  1.0000e+00],\n",
      "       [-8.3280e+01,  5.2570e+01,  4.8000e-01,  5.0000e-01,  0.0000e+00],\n",
      "       [-7.8220e+01,  5.3710e+01,  5.1000e-01,  5.4000e-01,  0.0000e+00],\n",
      "       [-6.6820e+01,  6.7270e+01,  1.8000e-01,  1.4000e-01,  0.0000e+00],\n",
      "       [-4.7300e+01,  3.5860e+01,  8.8000e-01,  9.1000e-01,  1.0000e+00],\n",
      "       [-4.4100e+01,  3.8950e+01,  7.9000e-01,  8.0000e-01,  1.0000e+00],\n",
      "       [-8.3650e+01,  5.6440e+01,  8.9000e-01,  9.1000e-01,  0.0000e+00],\n",
      "       [-1.0421e+02,  4.0880e+01,  9.0000e-02,  5.0000e-02,  0.0000e+00],\n",
      "       [-8.0160e+01,  4.7670e+01,  3.9000e-01,  3.7000e-01,  0.0000e+00],\n",
      "       [-8.4780e+01,  5.1150e+01,  4.9000e-01,  5.3000e-01,  0.0000e+00],\n",
      "       [-4.4810e+01,  3.8380e+01,  5.9000e-01,  6.1000e-01,  1.0000e+00],\n",
      "       [-8.2610e+01,  6.5760e+01,  1.6000e-01,  1.0000e-01,  0.0000e+00],\n",
      "       [-6.0490e+01,  2.6180e+01,  4.8000e-01,  5.0000e-01,  1.0000e+00],\n",
      "       [-8.2640e+01,  5.7450e+01,  3.9000e-01,  3.8000e-01,  0.0000e+00],\n",
      "       [-8.8740e+01,  5.4240e+01,  7.5000e-01,  7.6000e-01,  0.0000e+00],\n",
      "       [-4.3530e+01,  4.2000e+01,  3.9000e-01,  3.8000e-01,  1.0000e+00],\n",
      "       [-5.2310e+01,  2.9740e+01,  5.2000e-01,  5.6000e-01,  1.0000e+00],\n",
      "       [-5.0040e+01,  4.1630e+01,  2.6000e-01,  2.1000e-01,  1.0000e+00],\n",
      "       [-8.5690e+01,  5.3400e+01,  9.1000e-01,  9.2000e-01,  0.0000e+00],\n",
      "       [-7.8250e+01,  5.8390e+01,  2.9000e-01,  2.6000e-01,  0.0000e+00],\n",
      "       [-8.2730e+01,  5.8840e+01,  3.8000e-01,  3.5000e-01,  0.0000e+00],\n",
      "       [-5.0470e+01,  2.9100e+01,  5.9000e-01,  6.0000e-01,  1.0000e+00],\n",
      "       [-4.4960e+01,  4.5230e+01,  5.9000e-01,  6.1000e-01,  1.0000e+00],\n",
      "       [-5.6610e+01,  2.8380e+01,  7.0000e-01,  7.1000e-01,  1.0000e+00],\n",
      "       [-4.5320e+01,  4.2010e+01,  4.5000e-01,  4.5000e-01,  1.0000e+00],\n",
      "       [-5.8290e+01,  3.3890e+01,  6.2000e-01,  6.4000e-01,  1.0000e+00],\n",
      "       [-5.4370e+01,  2.9670e+01,  5.0000e-02,  3.0000e-02,  1.0000e+00],\n",
      "       [-4.7450e+01,  3.6460e+01,  7.5000e-01,  7.5000e-01,  1.0000e+00],\n",
      "       [-6.0720e+01,  2.8970e+01,  7.0000e-01,  7.0000e-01,  1.0000e+00],\n",
      "       [-6.4650e+01,  6.3860e+01,  2.3000e-01,  1.7000e-01,  0.0000e+00],\n",
      "       [-8.5700e+01,  5.4520e+01,  1.1000e-01,  8.0000e-02,  0.0000e+00],\n",
      "       [-7.9200e+01,  6.4110e+01,  3.5000e-01,  3.1000e-01,  0.0000e+00]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n",
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 67.903631\n",
      "Time per LP neuron 0.679036\n",
      "LP used on 100 neurons.\n",
      "Median global rank: 0.539286\n",
      "Median tigthness of hat bounds: 565.371626 \n",
      "\n",
      "Min tigthness of hat bounds: 385.266800 \n",
      "\n",
      "Max tigthness of hat bounds: 781.524809 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-2.5688e+02,  1.2838e+02,  4.2000e-01,  4.0000e-01,  1.0000e+00],\n",
      "       [-3.4398e+02,  3.2237e+02,  4.4000e-01,  4.3000e-01,  0.0000e+00],\n",
      "       [-3.6984e+02,  2.9524e+02,  2.5000e-01,  2.2000e-01,  0.0000e+00],\n",
      "       [-2.3491e+02,  1.6360e+02,  2.4000e-01,  2.1000e-01,  1.0000e+00],\n",
      "       [-3.5262e+02,  3.2339e+02,  5.0000e-02,  3.0000e-02,  0.0000e+00],\n",
      "       [-2.8880e+02,  1.7002e+02,  5.4000e-01,  5.0000e-01,  1.0000e+00],\n",
      "       [-4.1381e+02,  2.9034e+02,  7.1000e-01,  7.1000e-01,  0.0000e+00],\n",
      "       [-3.7571e+02,  3.2791e+02,  5.5000e-01,  5.0000e-01,  0.0000e+00],\n",
      "       [-3.6396e+02,  3.0040e+02,  1.5000e-01,  1.2000e-01,  0.0000e+00],\n",
      "       [-3.4661e+02,  1.4638e+02,  4.7000e-01,  4.5000e-01,  1.0000e+00],\n",
      "       [-3.9427e+02,  3.0279e+02,  1.5000e-01,  1.3000e-01,  0.0000e+00],\n",
      "       [-2.9354e+02,  1.3823e+02,  7.6000e-01,  7.6000e-01,  1.0000e+00],\n",
      "       [-2.4171e+02,  1.8736e+02,  4.2000e-01,  4.0000e-01,  1.0000e+00],\n",
      "       [-4.0769e+02,  3.1435e+02,  7.6000e-01,  7.5000e-01,  0.0000e+00],\n",
      "       [-2.3884e+02,  1.8437e+02,  3.1000e-01,  3.0000e-01,  1.0000e+00],\n",
      "       [-2.2615e+02,  1.9607e+02,  5.6000e-01,  5.3000e-01,  1.0000e+00],\n",
      "       [-2.9672e+02,  1.8104e+02,  8.7000e-01,  8.4000e-01,  1.0000e+00],\n",
      "       [-2.9737e+02,  1.4718e+02,  5.0000e-01,  4.7000e-01,  1.0000e+00],\n",
      "       [-2.0542e+02,  2.1287e+02,  1.5000e-01,  1.2000e-01,  1.0000e+00],\n",
      "       [-2.7530e+02,  1.8032e+02,  4.0000e-02,  2.0000e-02,  1.0000e+00],\n",
      "       [-2.7415e+02,  1.7669e+02,  9.3000e-01,  9.4000e-01,  1.0000e+00],\n",
      "       [-3.6622e+02,  3.2994e+02,  8.1000e-01,  8.0000e-01,  0.0000e+00],\n",
      "       [-3.6391e+02,  2.7729e+02,  2.7000e-01,  2.4000e-01,  0.0000e+00],\n",
      "       [-2.3555e+02,  1.9824e+02,  2.2000e-01,  1.8000e-01,  1.0000e+00],\n",
      "       [-4.2041e+02,  2.5177e+02,  4.0000e-02,  2.0000e-02,  0.0000e+00],\n",
      "       [-2.3830e+02,  2.2625e+02,  4.6000e-01,  4.4000e-01,  1.0000e+00],\n",
      "       [-2.7285e+02,  1.7502e+02,  6.0000e-01,  5.7000e-01,  1.0000e+00],\n",
      "       [-3.4091e+02,  3.2692e+02,  1.4000e-01,  1.1000e-01,  0.0000e+00],\n",
      "       [-2.3772e+02,  1.8545e+02,  4.0000e-01,  3.8000e-01,  1.0000e+00],\n",
      "       [-3.9198e+02,  2.6725e+02,  1.2000e-01,  1.0000e-01,  0.0000e+00],\n",
      "       [-3.8789e+02,  2.6092e+02,  1.7000e-01,  1.4000e-01,  0.0000e+00],\n",
      "       [-2.8263e+02,  1.4658e+02,  9.3000e-01,  9.3000e-01,  1.0000e+00],\n",
      "       [-2.6852e+02,  2.0283e+02,  5.8000e-01,  5.5000e-01,  1.0000e+00],\n",
      "       [-2.2920e+02,  1.9670e+02,  5.5000e-01,  5.1000e-01,  1.0000e+00],\n",
      "       [-3.8430e+02,  2.5891e+02,  2.2000e-01,  1.8000e-01,  0.0000e+00],\n",
      "       [-3.8915e+02,  2.8401e+02,  6.0000e-02,  4.0000e-02,  0.0000e+00],\n",
      "       [-2.3660e+02,  1.6848e+02,  7.1000e-01,  7.0000e-01,  1.0000e+00],\n",
      "       [-2.5918e+02,  2.1953e+02,  9.1000e-01,  8.9000e-01,  1.0000e+00],\n",
      "       [-3.1918e+02,  1.8251e+02,  4.0000e-02,  3.0000e-02,  1.0000e+00],\n",
      "       [-4.3331e+02,  3.0151e+02,  2.4000e-01,  2.0000e-01,  0.0000e+00],\n",
      "       [-2.3319e+02,  1.8638e+02,  7.2000e-01,  7.2000e-01,  1.0000e+00],\n",
      "       [-4.6196e+02,  2.7114e+02,  5.0000e-01,  4.6000e-01,  0.0000e+00],\n",
      "       [-2.1395e+02,  2.4139e+02,  6.7000e-01,  6.6000e-01,  1.0000e+00],\n",
      "       [-4.1924e+02,  2.7575e+02,  9.3000e-01,  9.3000e-01,  0.0000e+00],\n",
      "       [-3.4343e+02,  3.3325e+02,  8.1000e-01,  8.1000e-01,  0.0000e+00],\n",
      "       [-3.7896e+02,  3.3218e+02,  7.0000e-02,  5.0000e-02,  0.0000e+00],\n",
      "       [-2.5379e+02,  1.6608e+02,  2.1000e-01,  1.7000e-01,  1.0000e+00],\n",
      "       [-2.1182e+02,  2.0805e+02,  8.0000e-01,  7.9000e-01,  1.0000e+00],\n",
      "       [-3.7833e+02,  3.1947e+02,  3.5000e-01,  3.4000e-01,  0.0000e+00],\n",
      "       [-3.4457e+02,  3.2747e+02,  9.2000e-01,  9.1000e-01,  0.0000e+00],\n",
      "       [-3.9668e+02,  2.4743e+02,  9.2000e-01,  8.9000e-01,  0.0000e+00],\n",
      "       [-2.2510e+02,  1.8950e+02,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
      "       [-2.6288e+02,  1.7305e+02,  6.7000e-01,  6.5000e-01,  1.0000e+00],\n",
      "       [-3.7709e+02,  3.1225e+02,  8.6000e-01,  8.3000e-01,  0.0000e+00],\n",
      "       [-1.9579e+02,  2.0759e+02,  6.7000e-01,  6.4000e-01,  1.0000e+00],\n",
      "       [-3.4557e+02,  2.6966e+02,  3.9000e-01,  3.7000e-01,  0.0000e+00],\n",
      "       [-3.1025e+02,  1.7118e+02,  7.1000e-01,  7.0000e-01,  1.0000e+00],\n",
      "       [-3.8311e+02,  3.0743e+02,  6.9000e-01,  6.8000e-01,  0.0000e+00],\n",
      "       [-5.0820e+02,  2.4509e+02,  4.6000e-01,  4.5000e-01,  0.0000e+00],\n",
      "       [-2.2125e+02,  1.9266e+02,  9.3000e-01,  9.2000e-01,  1.0000e+00],\n",
      "       [-2.0998e+02,  2.4641e+02,  3.1000e-01,  2.9000e-01,  1.0000e+00],\n",
      "       [-2.5319e+02,  2.0001e+02,  7.8000e-01,  7.8000e-01,  1.0000e+00],\n",
      "       [-4.5527e+02,  2.1494e+02,  2.8000e-01,  2.5000e-01,  0.0000e+00],\n",
      "       [-3.7707e+02,  2.8272e+02,  9.7000e-01,  9.8000e-01,  0.0000e+00],\n",
      "       [-3.8894e+02,  3.2891e+02,  6.7000e-01,  6.4000e-01,  0.0000e+00],\n",
      "       [-2.6138e+02,  1.6442e+02,  9.6000e-01,  9.5000e-01,  1.0000e+00],\n",
      "       [-2.7703e+02,  1.5437e+02,  6.9000e-01,  6.8000e-01,  1.0000e+00],\n",
      "       [-4.2975e+02,  2.3156e+02,  3.2000e-01,  3.2000e-01,  0.0000e+00],\n",
      "       [-2.2318e+02,  1.7586e+02,  5.3000e-01,  4.9000e-01,  1.0000e+00],\n",
      "       [-3.9582e+02,  2.4928e+02,  6.0000e-01,  5.7000e-01,  0.0000e+00],\n",
      "       [-4.0286e+02,  2.5090e+02,  9.1000e-01,  8.8000e-01,  0.0000e+00],\n",
      "       [-3.3484e+02,  3.2064e+02,  1.8000e-01,  1.6000e-01,  0.0000e+00],\n",
      "       [-3.3009e+02,  1.2346e+02,  8.9000e-01,  8.6000e-01,  1.0000e+00],\n",
      "       [-3.9221e+02,  2.6899e+02,  3.3000e-01,  3.3000e-01,  0.0000e+00],\n",
      "       [-3.2899e+02,  2.9239e+02,  9.6000e-01,  9.6000e-01,  0.0000e+00],\n",
      "       [-4.0557e+02,  3.1659e+02,  5.2000e-01,  4.8000e-01,  0.0000e+00],\n",
      "       [-2.0667e+02,  2.3932e+02,  1.0000e-01,  6.0000e-02,  1.0000e+00],\n",
      "       [-3.0432e+02,  1.4391e+02,  3.0000e-01,  2.7000e-01,  1.0000e+00],\n",
      "       [-2.1167e+02,  1.8489e+02,  1.7000e-01,  1.5000e-01,  1.0000e+00],\n",
      "       [-3.5388e+02,  2.9447e+02,  3.7000e-01,  3.6000e-01,  0.0000e+00],\n",
      "       [-5.0310e+02,  2.6707e+02,  9.7000e-01,  9.7000e-01,  0.0000e+00],\n",
      "       [-2.1922e+02,  1.9141e+02,  9.5000e-01,  9.5000e-01,  1.0000e+00],\n",
      "       [-3.9357e+02,  3.1264e+02,  7.1000e-01,  7.1000e-01,  0.0000e+00],\n",
      "       [-4.1591e+02,  2.6927e+02,  6.2000e-01,  6.0000e-01,  0.0000e+00],\n",
      "       [-3.4073e+02,  3.3125e+02,  4.2000e-01,  3.9000e-01,  0.0000e+00],\n",
      "       [-3.8700e+02,  3.2228e+02,  5.2000e-01,  4.8000e-01,  0.0000e+00],\n",
      "       [-3.5022e+02,  3.3725e+02,  6.9000e-01,  6.9000e-01,  0.0000e+00],\n",
      "       [-4.6697e+02,  2.6684e+02,  3.8000e-01,  3.7000e-01,  0.0000e+00],\n",
      "       [-4.4072e+02,  2.5546e+02,  6.1000e-01,  5.9000e-01,  0.0000e+00],\n",
      "       [-2.3850e+02,  1.9247e+02,  4.3000e-01,  4.1000e-01,  1.0000e+00],\n",
      "       [-3.8155e+02,  3.0909e+02,  1.6000e-01,  1.4000e-01,  0.0000e+00],\n",
      "       [-2.2722e+02,  1.9940e+02,  1.1000e-01,  7.0000e-02,  1.0000e+00],\n",
      "       [-2.3406e+02,  1.9941e+02,  2.4000e-01,  2.1000e-01,  1.0000e+00],\n",
      "       [-2.4355e+02,  1.8788e+02,  7.9000e-01,  7.9000e-01,  1.0000e+00],\n",
      "       [-4.0382e+02,  2.7271e+02,  8.0000e-01,  8.0000e-01,  0.0000e+00],\n",
      "       [-4.7964e+02,  2.2209e+02,  9.0000e-01,  8.7000e-01,  0.0000e+00],\n",
      "       [-2.4746e+02,  2.1494e+02,  6.4000e-01,  6.2000e-01,  1.0000e+00],\n",
      "       [-2.9767e+02,  1.7732e+02,  1.1000e-01,  8.0000e-02,  1.0000e+00],\n",
      "       [-4.0374e+02,  3.2672e+02,  7.8000e-01,  7.7000e-01,  0.0000e+00],\n",
      "       [-3.8983e+02,  3.0448e+02,  6.4000e-01,  6.3000e-01,  0.0000e+00],\n",
      "       [-2.2891e+02,  1.9535e+02,  3.2000e-01,  3.2000e-01,  1.0000e+00],\n",
      "       [-2.5379e+02,  1.5868e+02,  5.7000e-01,  5.4000e-01,  1.0000e+00],\n",
      "       [-4.0483e+02,  3.2032e+02,  7.2000e-01,  7.3000e-01,  0.0000e+00],\n",
      "       [-3.3193e+02,  3.4161e+02,  2.8000e-01,  2.5000e-01,  0.0000e+00],\n",
      "       [-3.9428e+02,  3.0365e+02,  9.7000e-01,  9.7000e-01,  0.0000e+00],\n",
      "       [-2.5300e+02,  1.8942e+02,  3.0000e-01,  2.8000e-01,  1.0000e+00],\n",
      "       [-3.2936e+02,  3.0629e+02,  9.2000e-01,  9.0000e-01,  0.0000e+00],\n",
      "       [-2.2424e+02,  1.7840e+02,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
      "       [-2.7738e+02,  1.3001e+02,  7.3000e-01,  7.4000e-01,  1.0000e+00],\n",
      "       [-2.2720e+02,  1.9236e+02,  4.2000e-01,  4.1000e-01,  1.0000e+00],\n",
      "       [-2.6450e+02,  1.6443e+02,  5.0000e-01,  4.7000e-01,  1.0000e+00],\n",
      "       [-3.5657e+02,  2.6573e+02,  8.0000e-02,  5.0000e-02,  0.0000e+00],\n",
      "       [-4.1721e+02,  2.4123e+02,  3.0000e-01,  2.9000e-01,  0.0000e+00],\n",
      "       [-1.9666e+02,  2.4456e+02,  2.4000e-01,  2.0000e-01,  1.0000e+00],\n",
      "       [-3.7303e+02,  2.8464e+02,  9.4000e-01,  9.4000e-01,  0.0000e+00],\n",
      "       [-3.9597e+02,  2.9868e+02,  9.2000e-01,  9.1000e-01,  0.0000e+00],\n",
      "       [-2.6848e+02,  1.4997e+02,  4.0000e-01,  3.8000e-01,  1.0000e+00],\n",
      "       [-3.3205e+02,  3.4892e+02,  6.1000e-01,  5.9000e-01,  0.0000e+00],\n",
      "       [-3.7034e+02,  2.8701e+02,  9.8000e-01,  9.9000e-01,  0.0000e+00],\n",
      "       [-2.5353e+02,  1.5731e+02,  6.7000e-01,  6.7000e-01,  1.0000e+00],\n",
      "       [-2.2186e+02,  1.9990e+02,  5.6000e-01,  5.3000e-01,  1.0000e+00],\n",
      "       [-2.4788e+02,  1.6921e+02,  3.0000e-01,  2.7000e-01,  1.0000e+00],\n",
      "       [-3.9408e+02,  2.9417e+02,  9.7000e-01,  9.6000e-01,  0.0000e+00],\n",
      "       [-2.3300e+02,  1.8845e+02,  1.9000e-01,  1.6000e-01,  1.0000e+00],\n",
      "       [-4.0795e+02,  2.6155e+02,  2.5000e-01,  2.2000e-01,  0.0000e+00],\n",
      "       [-2.4245e+02,  1.6555e+02,  3.0000e-01,  2.8000e-01,  1.0000e+00],\n",
      "       [-4.2048e+02,  2.9399e+02,  7.3000e-01,  7.4000e-01,  0.0000e+00],\n",
      "       [-2.2897e+02,  2.0804e+02,  4.4000e-01,  4.3000e-01,  1.0000e+00],\n",
      "       [-2.5346e+02,  1.8878e+02,  8.6000e-01,  8.4000e-01,  1.0000e+00],\n",
      "       [-2.8068e+02,  1.9198e+02,  2.6000e-01,  2.3000e-01,  1.0000e+00],\n",
      "       [-4.1769e+02,  2.5947e+02,  7.9000e-01,  7.8000e-01,  0.0000e+00],\n",
      "       [-4.0190e+02,  2.9817e+02,  1.3000e-01,  1.1000e-01,  0.0000e+00],\n",
      "       [-2.2742e+02,  1.6657e+02,  8.3000e-01,  8.1000e-01,  1.0000e+00],\n",
      "       [-4.0678e+02,  2.8453e+02,  1.1000e-01,  9.0000e-02,  0.0000e+00],\n",
      "       [-4.2755e+02,  2.9034e+02,  9.0000e-01,  8.7000e-01,  0.0000e+00],\n",
      "       [-3.5807e+02,  2.4774e+02,  9.1000e-01,  8.8000e-01,  0.0000e+00],\n",
      "       [-2.8481e+02,  1.2479e+02,  8.7000e-01,  8.5000e-01,  1.0000e+00],\n",
      "       [-3.8235e+02,  2.6629e+02,  7.8000e-01,  7.7000e-01,  0.0000e+00],\n",
      "       [-3.5530e+02,  1.2866e+02,  6.1000e-01,  5.8000e-01,  1.0000e+00],\n",
      "       [-2.4799e+02,  1.8215e+02,  1.6000e-01,  1.3000e-01,  1.0000e+00],\n",
      "       [-4.2586e+02,  2.6043e+02,  9.9000e-01,  9.9000e-01,  0.0000e+00],\n",
      "       [-2.8452e+02,  1.7429e+02,  4.3000e-01,  4.2000e-01,  1.0000e+00],\n",
      "       [-2.3420e+02,  2.1270e+02,  2.9000e-01,  2.6000e-01,  1.0000e+00],\n",
      "       [-3.2334e+02,  1.3313e+02,  1.1000e-01,  9.0000e-02,  1.0000e+00],\n",
      "       [-3.8728e+02,  2.9173e+02,  6.3000e-01,  6.1000e-01,  0.0000e+00],\n",
      "       [-2.6260e+02,  1.8612e+02,  2.0000e-01,  1.7000e-01,  1.0000e+00],\n",
      "       [-4.6285e+02,  2.7241e+02,  5.7000e-01,  5.5000e-01,  0.0000e+00],\n",
      "       [-3.6370e+02,  3.2711e+02,  6.4000e-01,  6.3000e-01,  0.0000e+00],\n",
      "       [-3.7313e+02,  1.5181e+02,  7.5000e-01,  7.5000e-01,  1.0000e+00],\n",
      "       [-2.1328e+02,  2.1649e+02,  3.3000e-01,  3.4000e-01,  1.0000e+00],\n",
      "       [-2.5415e+02,  1.8329e+02,  3.2000e-01,  3.3000e-01,  1.0000e+00],\n",
      "       [-2.3216e+02,  1.9269e+02,  4.1000e-01,  3.9000e-01,  1.0000e+00],\n",
      "       [-3.5679e+02,  3.5276e+02,  2.6000e-01,  2.3000e-01,  0.0000e+00],\n",
      "       [-2.3920e+02,  1.7325e+02,  7.0000e-01,  6.9000e-01,  1.0000e+00],\n",
      "       [-3.8650e+02,  3.1776e+02,  8.7000e-01,  8.5000e-01,  0.0000e+00],\n",
      "       [-2.8648e+02,  1.7891e+02,  3.2000e-01,  3.1000e-01,  1.0000e+00],\n",
      "       [-2.1585e+02,  2.2642e+02,  5.4000e-01,  4.9000e-01,  1.0000e+00],\n",
      "       [-2.5280e+02,  1.9027e+02,  6.9000e-01,  6.7000e-01,  1.0000e+00],\n",
      "       [-3.4603e+02,  3.2298e+02,  7.4000e-01,  7.5000e-01,  0.0000e+00],\n",
      "       [-3.6676e+02,  3.0246e+02,  1.0000e-02,  0.0000e+00,  0.0000e+00],\n",
      "       [-2.7136e+02,  3.6829e+02,  2.8000e-01,  2.5000e-01,  0.0000e+00],\n",
      "       [-4.5247e+02,  2.6679e+02,  4.3000e-01,  4.2000e-01,  0.0000e+00],\n",
      "       [-2.2382e+02,  2.3020e+02,  5.7000e-01,  5.4000e-01,  1.0000e+00],\n",
      "       [-3.4792e+02,  3.0020e+02,  6.2000e-01,  6.1000e-01,  0.0000e+00],\n",
      "       [-2.6277e+02,  1.7718e+02,  8.5000e-01,  8.2000e-01,  1.0000e+00],\n",
      "       [-3.8054e+02,  3.3679e+02,  1.1000e-01,  7.0000e-02,  0.0000e+00],\n",
      "       [-2.3587e+02,  1.8809e+02,  5.4000e-01,  5.0000e-01,  1.0000e+00],\n",
      "       [-4.2465e+02,  3.3494e+02,  3.7000e-01,  3.6000e-01,  0.0000e+00],\n",
      "       [-2.5798e+02,  1.6174e+02,  3.1000e-01,  3.0000e-01,  1.0000e+00],\n",
      "       [-4.1001e+02,  2.8583e+02,  9.3000e-01,  9.2000e-01,  0.0000e+00],\n",
      "       [-3.8159e+02,  2.9546e+02,  9.8000e-01,  9.8000e-01,  0.0000e+00],\n",
      "       [-2.4484e+02,  1.8886e+02,  5.8000e-01,  5.6000e-01,  1.0000e+00],\n",
      "       [-2.8695e+02,  1.5671e+02,  2.3000e-01,  1.9000e-01,  1.0000e+00],\n",
      "       [-4.0266e+02,  2.8107e+02,  4.5000e-01,  4.4000e-01,  0.0000e+00],\n",
      "       [-3.6275e+02,  3.0362e+02,  6.3000e-01,  6.2000e-01,  0.0000e+00],\n",
      "       [-3.9922e+02,  2.6258e+02,  6.1000e-01,  5.8000e-01,  0.0000e+00],\n",
      "       [-2.2921e+02,  1.7711e+02,  9.2000e-01,  9.0000e-01,  1.0000e+00],\n",
      "       [-4.0713e+02,  2.8720e+02,  6.7000e-01,  6.5000e-01,  0.0000e+00],\n",
      "       [-4.4866e+02,  2.8978e+02,  1.8000e-01,  1.5000e-01,  0.0000e+00],\n",
      "       [-2.6448e+02,  1.9348e+02,  8.9000e-01,  8.6000e-01,  1.0000e+00],\n",
      "       [-2.3601e+02,  1.7633e+02,  6.7000e-01,  6.6000e-01,  1.0000e+00],\n",
      "       [-3.5405e+02,  3.2729e+02,  6.2000e-01,  6.0000e-01,  0.0000e+00],\n",
      "       [-4.0524e+02,  2.3124e+02,  7.3000e-01,  7.3000e-01,  0.0000e+00],\n",
      "       [-2.7645e+02,  1.6231e+02,  5.9000e-01,  5.6000e-01,  1.0000e+00],\n",
      "       [-2.7820e+02,  2.1071e+02,  6.0000e-02,  4.0000e-02,  1.0000e+00],\n",
      "       [-3.8246e+02,  2.9525e+02,  9.0000e-02,  6.0000e-02,  0.0000e+00],\n",
      "       [-2.4114e+02,  2.1138e+02,  5.6000e-01,  5.2000e-01,  1.0000e+00],\n",
      "       [-2.9618e+02,  1.6369e+02,  3.5000e-01,  3.5000e-01,  1.0000e+00],\n",
      "       [-3.9195e+02,  2.6504e+02,  8.6000e-01,  8.3000e-01,  0.0000e+00],\n",
      "       [-2.2503e+02,  1.9549e+02,  2.7000e-01,  2.4000e-01,  1.0000e+00],\n",
      "       [-2.3334e+02,  1.9322e+02,  1.1000e-01,  8.0000e-02,  1.0000e+00],\n",
      "       [-3.6210e+02,  3.3298e+02,  1.2000e-01,  1.0000e-01,  0.0000e+00],\n",
      "       [-4.1131e+02,  2.9449e+02,  8.4000e-01,  8.2000e-01,  0.0000e+00],\n",
      "       [-4.1059e+02,  3.1411e+02,  2.0000e-02,  1.0000e-02,  0.0000e+00],\n",
      "       [-3.1745e+02,  1.7154e+02,  2.3000e-01,  1.9000e-01,  1.0000e+00],\n",
      "       [-4.7352e+02,  2.4363e+02,  3.1000e-01,  3.1000e-01,  0.0000e+00],\n",
      "       [-2.0937e+02,  1.9840e+02,  4.8000e-01,  4.6000e-01,  1.0000e+00],\n",
      "       [-5.6130e+02,  2.2022e+02,  3.6000e-01,  3.5000e-01,  0.0000e+00],\n",
      "       [-2.7079e+02,  1.7735e+02,  5.5000e-01,  5.2000e-01,  1.0000e+00],\n",
      "       [-2.5870e+02,  1.6911e+02,  7.2000e-01,  7.2000e-01,  1.0000e+00]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n",
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Layerno: 4\n",
      "Time 123.478542\n",
      "Time per LP neuron 1.234785\n",
      "LP used on 100 neurons.\n",
      "Median global rank: 0.559643\n",
      "Median tigthness of hat bounds: 2917.434404 \n",
      "\n",
      "Min tigthness of hat bounds: 1945.853207 \n",
      "\n",
      "Max tigthness of hat bounds: 3881.432320 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-1.80040e+03,  1.67374e+03,  2.00000e-01,  1.80000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.34836e+03,  7.29860e+02,  7.10000e-01,  7.00000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.19421e+03,  8.82950e+02,  6.30000e-01,  6.00000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.59802e+03,  6.96020e+02,  2.90000e-01,  2.50000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.84804e+03,  1.60536e+03,  5.00000e-01,  4.40000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.42202e+03,  8.26330e+02,  8.00000e-01,  7.80000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.90970e+03,  1.53580e+03,  8.70000e-01,  8.70000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.14473e+03,  1.27170e+03,  6.80000e-01,  6.60000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.30962e+03,  8.18550e+02,  8.50000e-01,  8.60000e-01,\n",
      "         1.00000e+00],\n",
      "       [-9.86840e+02,  1.12337e+03,  7.70000e-01,  7.70000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.63102e+03,  6.31790e+02,  5.70000e-01,  5.00000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.91961e+03,  1.32100e+03,  1.80000e-01,  1.50000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.32432e+03,  9.34580e+02,  6.10000e-01,  5.70000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.07576e+03,  8.70090e+02,  9.90000e-01,  9.80000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.32120e+03,  9.11110e+02,  4.80000e-01,  4.30000e-01,\n",
      "         1.00000e+00],\n",
      "       [-9.76290e+02,  1.10399e+03,  4.60000e-01,  4.10000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.75904e+03,  1.12239e+03,  1.80000e-01,  1.40000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.07585e+03,  9.77180e+02,  7.40000e-01,  7.30000e-01,\n",
      "         1.00000e+00],\n",
      "       [-9.57680e+02,  1.09573e+03,  4.00000e-01,  3.50000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.14190e+03,  8.54160e+02,  9.50000e-01,  9.40000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.88198e+03,  1.60575e+03,  3.30000e-01,  3.00000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.73692e+03,  1.02498e+03,  6.80000e-01,  6.50000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.31794e+03,  9.30420e+02,  3.70000e-01,  3.40000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.25852e+03,  1.39234e+03,  1.40000e-01,  1.10000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.60751e+03,  1.58899e+03,  5.30000e-01,  4.70000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.29648e+03,  1.33894e+03,  6.50000e-01,  6.30000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.40531e+03,  8.37910e+02,  5.00000e-02,  5.00000e-02,\n",
      "         1.00000e+00],\n",
      "       [-2.35577e+03,  1.23674e+03,  6.10000e-01,  5.60000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.08446e+03,  1.35310e+03,  4.90000e-01,  4.30000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.34028e+03,  8.03420e+02,  4.30000e-01,  3.60000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.56311e+03,  1.20206e+03,  4.60000e-01,  4.10000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.99007e+03,  1.59936e+03,  3.60000e-01,  3.30000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.39228e+03,  1.21970e+03,  2.10000e-01,  1.90000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.32187e+03,  8.87950e+02,  6.50000e-01,  6.30000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.27813e+03,  1.32709e+03,  9.40000e-01,  9.30000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.06444e+03,  1.44516e+03,  8.90000e-01,  9.00000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.37843e+03,  1.23919e+03,  3.20000e-01,  2.80000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.63713e+03,  1.67219e+03,  1.60000e-01,  1.20000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.05497e+03,  1.44304e+03,  1.00000e-02,  2.00000e-02,\n",
      "         0.00000e+00],\n",
      "       [-1.90895e+03,  1.31870e+03,  7.50000e-01,  7.50000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.17082e+03,  1.24712e+03,  5.50000e-01,  4.90000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.06665e+03,  1.13689e+03,  9.00000e-01,  9.10000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.29163e+03,  1.54524e+03,  1.50000e-01,  1.20000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.22768e+03,  8.24700e+02,  5.10000e-01,  4.60000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.00153e+03,  1.35060e+03,  8.10000e-01,  8.10000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.35248e+03,  8.88230e+02,  7.60000e-01,  7.70000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.07988e+03,  1.48064e+03,  5.00000e-02,  4.00000e-02,\n",
      "         0.00000e+00],\n",
      "       [-2.40760e+03,  1.24697e+03,  8.00000e-02,  7.00000e-02,\n",
      "         0.00000e+00],\n",
      "       [-1.83907e+03,  1.23390e+03,  4.90000e-01,  4.40000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.24717e+03,  9.41290e+02,  6.40000e-01,  6.20000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.06040e+03,  1.42644e+03,  9.30000e-01,  9.20000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.18747e+03,  1.04215e+03,  2.10000e-01,  1.90000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.19163e+03,  1.07220e+03,  2.90000e-01,  2.60000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.21510e+03,  1.36244e+03,  6.60000e-01,  6.40000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.22174e+03,  1.19883e+03,  2.90000e-01,  2.70000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.09188e+03,  1.11625e+03,  7.10000e-01,  6.90000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.29917e+03,  8.27480e+02,  8.30000e-01,  8.30000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.01591e+03,  1.47802e+03,  7.10000e-01,  7.10000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.19881e+03,  1.21467e+03,  9.10000e-01,  9.10000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.02107e+03,  1.70603e+03,  1.90000e-01,  1.70000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.03860e+03,  1.12965e+03,  9.00000e-02,  8.00000e-02,\n",
      "         1.00000e+00],\n",
      "       [-1.31416e+03,  7.60930e+02,  6.00000e-02,  6.00000e-02,\n",
      "         1.00000e+00],\n",
      "       [-2.13291e+03,  1.27511e+03,  8.00000e-01,  7.90000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.16881e+03,  9.81850e+02,  2.60000e-01,  2.40000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.02048e+03,  1.53362e+03,  9.90000e-01,  9.70000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.26897e+03,  9.23940e+02,  2.60000e-01,  2.30000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.18093e+03,  1.37576e+03,  5.30000e-01,  4.80000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.84793e+03,  1.59076e+03,  4.00000e-01,  3.60000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.03263e+03,  1.20010e+03,  3.50000e-01,  3.20000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.69639e+03,  1.60950e+03,  8.40000e-01,  8.40000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.59378e+03,  6.95190e+02,  9.40000e-01,  9.30000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.95261e+03,  1.55597e+03,  4.30000e-01,  3.70000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.65675e+03,  1.72208e+03,  8.70000e-01,  8.80000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.04475e+03,  1.55062e+03,  5.00000e-01,  4.50000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.01919e+03,  1.53805e+03,  3.40000e-01,  3.20000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.94262e+03,  1.71285e+03,  6.80000e-01,  6.60000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.95847e+03,  1.41171e+03,  9.00000e-02,  8.00000e-02,\n",
      "         0.00000e+00],\n",
      "       [-1.93150e+03,  1.71728e+03,  4.40000e-01,  3.70000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.95992e+03,  1.53417e+03,  2.60000e-01,  2.30000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.91974e+03,  1.53610e+03,  8.20000e-01,  8.30000e-01,\n",
      "         0.00000e+00],\n",
      "       [-9.41320e+02,  1.13998e+03,  9.80000e-01,  9.70000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.26769e+03,  8.85900e+02,  6.00000e-02,  6.00000e-02,\n",
      "         1.00000e+00],\n",
      "       [-1.74788e+03,  1.55971e+03,  8.20000e-01,  8.20000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.27547e+03,  9.49190e+02,  6.60000e-01,  6.40000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.28688e+03,  9.63300e+02,  7.40000e-01,  7.40000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.75105e+03,  1.86277e+03,  8.40000e-01,  8.40000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.72952e+03,  1.77507e+03,  7.20000e-01,  7.20000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.07118e+03,  1.51159e+03,  8.10000e-01,  8.00000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.17921e+03,  1.10851e+03,  7.50000e-01,  7.50000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.43374e+03,  7.89660e+02,  1.00000e-02,  0.00000e+00,\n",
      "         1.00000e+00],\n",
      "       [-1.33420e+03,  8.45010e+02,  7.00000e-01,  6.90000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.91890e+03,  1.43071e+03,  4.50000e-01,  3.90000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.44515e+03,  6.43920e+02,  3.40000e-01,  3.10000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.09930e+03,  1.07910e+03,  5.60000e-01,  5.00000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.26972e+03,  1.35804e+03,  7.50000e-01,  7.50000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.04044e+03,  1.43385e+03,  5.50000e-01,  4.90000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.00650e+03,  1.46316e+03,  1.60000e-01,  1.30000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.07366e+03,  1.44990e+03,  3.00000e-02,  3.00000e-02,\n",
      "         1.00000e+00],\n",
      "       [-1.30423e+03,  9.29550e+02,  7.60000e-01,  7.60000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.20174e+03,  1.46824e+03,  7.00000e-01,  6.80000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.41098e+03,  7.95880e+02,  2.70000e-01,  2.50000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.11669e+03,  1.54911e+03,  1.90000e-01,  1.60000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.12722e+03,  1.54236e+03,  1.00000e+00,  1.00000e+00,\n",
      "         0.00000e+00],\n",
      "       [-1.99172e+03,  1.39335e+03,  5.40000e-01,  4.80000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.62624e+03,  7.83860e+02,  8.00000e-01,  7.90000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.75057e+03,  1.53848e+03,  6.10000e-01,  5.70000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.23680e+03,  1.02228e+03,  8.50000e-01,  8.70000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.43087e+03,  9.68150e+02,  7.00000e-02,  7.00000e-02,\n",
      "         1.00000e+00],\n",
      "       [-1.31783e+03,  8.02510e+02,  1.20000e-01,  9.00000e-02,\n",
      "         1.00000e+00],\n",
      "       [-2.27770e+03,  1.15561e+03,  4.40000e-01,  3.90000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.88065e+03,  1.45588e+03,  5.70000e-01,  5.20000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.31050e+03,  8.86450e+02,  4.60000e-01,  4.00000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.12685e+03,  1.44125e+03,  3.50000e-01,  3.30000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.02663e+03,  9.86050e+02,  2.20000e-01,  2.00000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.93193e+03,  1.60518e+03,  8.10000e-01,  8.00000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.97755e+03,  1.55165e+03,  8.90000e-01,  8.90000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.98418e+03,  1.51479e+03,  2.80000e-01,  2.50000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.86964e+03,  1.51470e+03,  6.20000e-01,  5.80000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.35400e+03,  1.24258e+03,  9.90000e-01,  9.90000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.21756e+03,  9.10410e+02,  1.90000e-01,  1.80000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.10297e+03,  1.07819e+03,  4.40000e-01,  3.80000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.22194e+03,  9.41650e+02,  2.50000e-01,  2.10000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.76499e+03,  1.54688e+03,  5.60000e-01,  5.00000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.09854e+03,  1.12954e+03,  2.20000e-01,  2.00000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.73949e+03,  1.74837e+03,  8.80000e-01,  8.80000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.53762e+03,  1.10947e+03,  2.50000e-01,  2.20000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.11686e+03,  1.19612e+03,  6.30000e-01,  5.90000e-01,\n",
      "         0.00000e+00],\n",
      "       [-8.13150e+02,  1.18275e+03,  1.60000e-01,  1.30000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.67582e+03,  8.01130e+02,  2.60000e-01,  2.40000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.23265e+03,  9.91450e+02,  3.20000e-01,  2.70000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.91306e+03,  1.42278e+03,  7.10000e-01,  7.00000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.48505e+03,  1.29470e+03,  6.40000e-01,  6.10000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.12557e+03,  1.14623e+03,  1.30000e-01,  1.10000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.28115e+03,  1.28781e+03,  8.40000e-01,  8.50000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.20616e+03,  1.34138e+03,  8.10000e-01,  8.10000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.03325e+03,  1.41868e+03,  8.50000e-01,  8.50000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.11485e+03,  1.63836e+03,  3.80000e-01,  3.40000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.36567e+03,  7.53110e+02,  4.00000e-01,  3.50000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.92391e+03,  1.54153e+03,  4.40000e-01,  3.80000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.24122e+03,  8.62660e+02,  6.00000e-02,  5.00000e-02,\n",
      "         1.00000e+00],\n",
      "       [-2.17588e+03,  1.26351e+03,  7.00000e-01,  6.80000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.37231e+03,  6.54900e+02,  6.00000e-01,  5.40000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.27103e+03,  1.43681e+03,  3.40000e-01,  3.10000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.23074e+03,  1.00177e+03,  1.30000e-01,  1.00000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.02998e+03,  1.01618e+03,  1.00000e+00,  9.90000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.48798e+03,  9.25370e+02,  2.00000e-02,  2.00000e-02,\n",
      "         1.00000e+00],\n",
      "       [-2.16211e+03,  1.25776e+03,  8.00000e-01,  7.80000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.91603e+03,  1.51153e+03,  9.10000e-01,  9.20000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.19329e+03,  1.20086e+03,  3.00000e-02,  3.00000e-02,\n",
      "         0.00000e+00],\n",
      "       [-2.03549e+03,  1.41575e+03,  3.30000e-01,  2.90000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.09496e+03,  8.65570e+02,  6.20000e-01,  5.80000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.92246e+03,  1.22576e+03,  6.30000e-01,  6.00000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.11696e+03,  1.02198e+03,  8.50000e-01,  8.60000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.83453e+03,  1.50193e+03,  3.20000e-01,  2.90000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.65313e+03,  6.73320e+02,  8.80000e-01,  8.90000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.94939e+03,  1.50824e+03,  1.80000e-01,  1.50000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.27425e+03,  8.81670e+02,  1.20000e-01,  9.00000e-02,\n",
      "         1.00000e+00],\n",
      "       [-1.94965e+03,  1.25752e+03,  4.60000e-01,  4.00000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.37807e+03,  7.93870e+02,  5.70000e-01,  5.10000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.70534e+03,  6.61420e+02,  7.20000e-01,  7.20000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.85656e+03,  1.38300e+03,  2.20000e-01,  2.10000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.53374e+03,  7.98240e+02,  9.50000e-01,  9.40000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.93008e+03,  1.54980e+03,  1.90000e-01,  1.60000e-01,\n",
      "         0.00000e+00],\n",
      "       [-2.31823e+03,  1.36245e+03,  9.00000e-01,  9.00000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.25666e+03,  8.79150e+02,  6.00000e-01,  5.50000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.01702e+03,  1.36742e+03,  6.00000e-01,  5.50000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.22063e+03,  8.27760e+02,  5.90000e-01,  5.40000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.09623e+03,  9.69730e+02,  9.80000e-01,  9.60000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.82652e+03,  1.67675e+03,  1.70000e-01,  1.40000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.83200e+03,  1.36611e+03,  5.00000e-01,  4.50000e-01,\n",
      "         0.00000e+00],\n",
      "       [-9.99480e+02,  1.33346e+03,  6.30000e-01,  5.90000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.03423e+03,  1.15898e+03,  4.80000e-01,  4.20000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.37666e+03,  6.80280e+02,  6.10000e-01,  5.60000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.42561e+03,  8.87740e+02,  5.80000e-01,  5.20000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.17734e+03,  1.15267e+03,  5.30000e-01,  4.70000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.20481e+03,  1.00563e+03,  3.20000e-01,  2.80000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.03909e+03,  1.00682e+03,  2.50000e-01,  2.20000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.04880e+03,  1.08686e+03,  7.50000e-01,  7.40000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.33602e+03,  1.17111e+03,  9.90000e-01,  9.80000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.22242e+03,  7.77990e+02,  5.00000e-01,  4.60000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.17754e+03,  1.38390e+03,  4.70000e-01,  4.20000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.91949e+03,  1.46255e+03,  6.40000e-01,  6.10000e-01,\n",
      "         0.00000e+00],\n",
      "       [-1.15706e+03,  8.82380e+02,  5.80000e-01,  5.30000e-01,\n",
      "         1.00000e+00],\n",
      "       [-9.89010e+02,  1.09101e+03,  6.90000e-01,  6.70000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.25284e+03,  1.51218e+03,  4.00000e-02,  4.00000e-02,\n",
      "         0.00000e+00],\n",
      "       [-1.00888e+03,  1.13098e+03,  9.70000e-01,  9.50000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.52697e+03,  8.07280e+02,  7.10000e-01,  7.10000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.97064e+03,  1.59841e+03,  6.50000e-01,  6.20000e-01,\n",
      "         0.00000e+00],\n",
      "       [-9.72950e+02,  1.16892e+03,  3.40000e-01,  3.00000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.24657e+03,  9.71300e+02,  1.90000e-01,  1.70000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.20331e+03,  7.62730e+02,  5.80000e-01,  5.30000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.20230e+03,  9.37160e+02,  8.20000e-01,  8.20000e-01,\n",
      "         1.00000e+00],\n",
      "       [-9.64440e+02,  1.25168e+03,  9.70000e-01,  9.60000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.12077e+03,  1.12596e+03,  6.90000e-01,  6.70000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.27407e+03,  1.03836e+03,  7.30000e-01,  7.30000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.06559e+03,  1.15771e+03,  9.60000e-01,  9.50000e-01,\n",
      "         1.00000e+00],\n",
      "       [-1.14741e+03,  9.51760e+02,  1.30000e-01,  1.00000e-01,\n",
      "         1.00000e+00],\n",
      "       [-2.01984e+03,  1.32718e+03,  1.00000e+00,  1.00000e+00,\n",
      "         0.00000e+00],\n",
      "       [-1.10135e+03,  1.19213e+03,  1.00000e-02,  1.00000e-02,\n",
      "         1.00000e+00],\n",
      "       [-1.44308e+03,  8.16010e+02,  6.70000e-01,  6.50000e-01,\n",
      "         1.00000e+00]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n",
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Layerno: 5\n",
      "Time 186.795487\n",
      "Time per LP neuron 1.867955\n",
      "LP used on 100 neurons.\n",
      "Median global rank: 0.481071\n",
      "Median tigthness of hat bounds: 15010.260945 \n",
      "\n",
      "Min tigthness of hat bounds: 9558.808324 \n",
      "\n",
      "Max tigthness of hat bounds: 19438.505239 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-5.793670e+03,  4.611990e+03,  5.000000e-01,  5.200000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.799830e+03,  7.506880e+03,  7.000000e-02,  7.000000e-02,\n",
      "         0.000000e+00],\n",
      "       [-1.074916e+04,  7.651350e+03,  1.400000e-01,  1.300000e-01,\n",
      "         0.000000e+00],\n",
      "       [-7.060760e+03,  4.277710e+03,  5.900000e-01,  6.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-8.654170e+03,  7.161460e+03,  5.300000e-01,  5.600000e-01,\n",
      "         0.000000e+00],\n",
      "       [-6.286640e+03,  4.587980e+03,  4.700000e-01,  4.700000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.057765e+04,  6.621100e+03,  6.300000e-01,  6.600000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.025652e+04,  6.763840e+03,  8.500000e-01,  8.500000e-01,\n",
      "         0.000000e+00],\n",
      "       [-8.200820e+03,  4.114470e+03,  1.000000e-01,  1.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.013916e+04,  7.541870e+03,  3.800000e-01,  3.900000e-01,\n",
      "         0.000000e+00],\n",
      "       [-9.778160e+03,  7.822690e+03,  7.500000e-01,  7.700000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.060068e+04,  7.112600e+03,  4.800000e-01,  4.900000e-01,\n",
      "         0.000000e+00],\n",
      "       [-6.436520e+03,  3.854320e+03,  3.300000e-01,  3.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.855490e+03,  7.838990e+03,  1.600000e-01,  1.500000e-01,\n",
      "         0.000000e+00],\n",
      "       [-9.752150e+03,  6.349170e+03,  6.600000e-01,  7.000000e-01,\n",
      "         0.000000e+00],\n",
      "       [-9.181960e+03,  7.164960e+03,  2.100000e-01,  2.400000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.180876e+04,  6.637250e+03,  9.500000e-01,  9.500000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.172384e+04,  7.714670e+03,  1.300000e-01,  1.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.037697e+04,  8.123880e+03,  3.200000e-01,  3.300000e-01,\n",
      "         0.000000e+00],\n",
      "       [-6.370590e+03,  4.554640e+03,  1.200000e-01,  1.100000e-01,\n",
      "         1.000000e+00],\n",
      "       [-7.948160e+03,  3.655760e+03,  6.600000e-01,  6.900000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.196336e+04,  7.404930e+03,  5.900000e-01,  6.300000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.099910e+04,  6.738210e+03,  2.100000e-01,  2.300000e-01,\n",
      "         0.000000e+00],\n",
      "       [-6.397950e+03,  4.140350e+03,  7.100000e-01,  7.300000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.777480e+03,  3.968110e+03,  7.500000e-01,  7.700000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.071800e+03,  5.136020e+03,  8.600000e-01,  8.600000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.024666e+04,  3.535900e+03,  5.800000e-01,  6.200000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.212770e+03,  5.589650e+03,  6.000000e-01,  6.500000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.086894e+04,  6.699240e+03,  3.000000e-01,  3.100000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.404640e+03,  4.154170e+03,  4.800000e-01,  5.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-6.765140e+03,  4.580440e+03,  7.800000e-01,  8.100000e-01,\n",
      "         1.000000e+00],\n",
      "       [-7.015870e+03,  3.854990e+03,  4.800000e-01,  4.800000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.093649e+04,  3.579010e+03,  1.000000e+00,  9.900000e-01,\n",
      "         1.000000e+00],\n",
      "       [-6.208880e+03,  4.036280e+03,  3.000000e-02,  4.000000e-02,\n",
      "         1.000000e+00],\n",
      "       [-9.531770e+03,  7.598070e+03,  4.900000e-01,  5.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-6.163470e+03,  6.291590e+03,  8.400000e-01,  8.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.862080e+03,  5.060450e+03,  9.200000e-01,  9.300000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.549590e+03,  7.651150e+03,  5.500000e-01,  5.700000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.057187e+04,  5.949290e+03,  5.300000e-01,  5.600000e-01,\n",
      "         0.000000e+00],\n",
      "       [-6.913890e+03,  3.979260e+03,  5.100000e-01,  5.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.557350e+03,  7.893440e+03,  8.900000e-01,  8.800000e-01,\n",
      "         0.000000e+00],\n",
      "       [-9.845670e+03,  6.661250e+03,  5.900000e-01,  6.400000e-01,\n",
      "         0.000000e+00],\n",
      "       [-8.259830e+03,  3.498870e+03,  9.600000e-01,  9.700000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.117320e+03,  8.504210e+03,  1.800000e-01,  1.900000e-01,\n",
      "         0.000000e+00],\n",
      "       [-6.317210e+03,  4.885480e+03,  8.500000e-01,  8.500000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.915730e+03,  7.055060e+03,  2.800000e-01,  2.900000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.761780e+03,  5.467430e+03,  4.800000e-01,  4.900000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.105722e+04,  6.847200e+03,  9.000000e-01,  9.000000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.079130e+04,  5.504670e+03,  6.300000e-01,  6.700000e-01,\n",
      "         0.000000e+00],\n",
      "       [-8.764560e+03,  8.193290e+03,  2.000000e-02,  2.000000e-02,\n",
      "         0.000000e+00],\n",
      "       [-7.200840e+03,  4.450820e+03,  5.500000e-01,  5.800000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.989330e+03,  4.482180e+03,  5.800000e-01,  6.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-8.178720e+03,  3.928540e+03,  1.900000e-01,  2.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-8.496750e+03,  3.657520e+03,  8.600000e-01,  8.700000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.898250e+03,  5.706430e+03,  6.500000e-01,  6.800000e-01,\n",
      "         1.000000e+00],\n",
      "       [-7.071980e+03,  3.777300e+03,  2.100000e-01,  2.300000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.170243e+04,  6.787600e+03,  4.000000e-01,  4.100000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.063327e+04,  7.403690e+03,  8.100000e-01,  8.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.042503e+04,  7.090790e+03,  6.200000e-01,  6.600000e-01,\n",
      "         0.000000e+00],\n",
      "       [-6.809930e+03,  4.305640e+03,  7.400000e-01,  7.500000e-01,\n",
      "         1.000000e+00],\n",
      "       [-6.644000e+03,  4.222930e+03,  1.800000e-01,  1.800000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.702500e+03,  5.991050e+03,  7.000000e-02,  8.000000e-02,\n",
      "         1.000000e+00],\n",
      "       [-1.115402e+04,  3.264950e+03,  7.600000e-01,  7.800000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.008808e+04,  7.758660e+03,  3.400000e-01,  3.500000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.427590e+03,  5.247590e+03,  8.900000e-01,  8.900000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.715380e+03,  8.647240e+03,  3.500000e-01,  3.700000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.261900e+03,  5.238390e+03,  6.300000e-01,  6.700000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.791230e+03,  5.062370e+03,  3.700000e-01,  3.800000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.132657e+04,  6.092280e+03,  3.000000e-01,  3.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-8.070400e+03,  3.728020e+03,  4.300000e-01,  4.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-7.950330e+03,  4.589290e+03,  7.200000e-01,  7.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-8.692690e+03,  7.892990e+03,  9.100000e-01,  9.100000e-01,\n",
      "         0.000000e+00],\n",
      "       [-6.551160e+03,  6.684660e+03,  5.800000e-01,  6.100000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.216603e+04,  5.157670e+03,  4.500000e-01,  4.500000e-01,\n",
      "         0.000000e+00],\n",
      "       [-9.777240e+03,  8.037670e+03,  5.100000e-01,  5.300000e-01,\n",
      "         0.000000e+00],\n",
      "       [-9.846060e+03,  8.122310e+03,  9.200000e-01,  9.300000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.595900e+03,  3.971000e+03,  8.100000e-01,  8.300000e-01,\n",
      "         1.000000e+00],\n",
      "       [-7.001310e+03,  4.030370e+03,  5.400000e-01,  5.700000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.858030e+03,  5.008670e+03,  9.000000e-01,  9.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-6.201100e+03,  5.111760e+03,  5.100000e-01,  5.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-6.373440e+03,  5.004330e+03,  3.500000e-01,  3.600000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.798590e+03,  5.478640e+03,  2.000000e-01,  2.200000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.760070e+03,  6.565990e+03,  1.000000e+00,  1.000000e+00,\n",
      "         0.000000e+00],\n",
      "       [-5.500100e+03,  5.174000e+03,  5.900000e-01,  6.300000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.239270e+04,  5.765330e+03,  5.000000e-01,  5.300000e-01,\n",
      "         0.000000e+00],\n",
      "       [-9.320350e+03,  3.642640e+03,  9.000000e-01,  8.900000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.678660e+03,  5.071110e+03,  4.500000e-01,  4.500000e-01,\n",
      "         1.000000e+00],\n",
      "       [-7.573530e+03,  3.897140e+03,  7.300000e-01,  7.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-7.386870e+03,  4.178370e+03,  3.100000e-01,  3.200000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.004764e+04,  7.322380e+03,  5.800000e-01,  6.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.368911e+04,  5.604790e+03,  6.400000e-01,  6.800000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.028195e+04,  6.432990e+03,  9.500000e-01,  9.600000e-01,\n",
      "         0.000000e+00],\n",
      "       [-7.450430e+03,  3.366710e+03,  4.000000e-01,  4.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-6.506520e+03,  4.501820e+03,  4.900000e-01,  5.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.676970e+03,  2.835130e+03,  6.800000e-01,  7.200000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.008122e+04,  7.929740e+03,  4.900000e-01,  5.100000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.036726e+04,  6.330530e+03,  4.100000e-01,  4.300000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.173503e+04,  6.186420e+03,  3.000000e-02,  5.000000e-02,\n",
      "         0.000000e+00],\n",
      "       [-5.456230e+03,  5.223610e+03,  7.700000e-01,  8.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-8.667530e+03,  3.951700e+03,  9.500000e-01,  9.500000e-01,\n",
      "         1.000000e+00],\n",
      "       [-7.088240e+03,  4.410440e+03,  2.500000e-01,  2.800000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.100546e+04,  7.568950e+03,  8.600000e-01,  8.800000e-01,\n",
      "         0.000000e+00],\n",
      "       [-6.248750e+03,  6.027930e+03,  9.600000e-01,  9.700000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.150290e+03,  8.025990e+03,  4.700000e-01,  4.700000e-01,\n",
      "         0.000000e+00],\n",
      "       [-9.786100e+03,  5.718920e+03,  5.600000e-01,  5.800000e-01,\n",
      "         0.000000e+00],\n",
      "       [-9.724700e+03,  7.375290e+03,  2.000000e-01,  2.100000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.967240e+03,  4.381550e+03,  2.000000e-01,  2.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.233070e+03,  7.582510e+03,  4.500000e-01,  4.600000e-01,\n",
      "         0.000000e+00],\n",
      "       [-9.238360e+03,  6.854860e+03,  2.400000e-01,  2.800000e-01,\n",
      "         0.000000e+00],\n",
      "       [-9.607890e+03,  4.087160e+03,  7.200000e-01,  7.300000e-01,\n",
      "         1.000000e+00],\n",
      "       [-7.857380e+03,  3.320680e+03,  9.100000e-01,  9.200000e-01,\n",
      "         1.000000e+00],\n",
      "       [-7.793440e+03,  3.620180e+03,  4.800000e-01,  4.800000e-01,\n",
      "         1.000000e+00],\n",
      "       [-7.651170e+03,  3.393490e+03,  5.600000e-01,  5.900000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.992500e+03,  8.346710e+03,  2.000000e-02,  1.000000e-02,\n",
      "         0.000000e+00],\n",
      "       [-5.534090e+03,  5.340860e+03,  6.200000e-01,  6.500000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.387010e+03,  7.494020e+03,  6.600000e-01,  6.900000e-01,\n",
      "         0.000000e+00],\n",
      "       [-6.992300e+03,  3.610920e+03,  1.000000e+00,  9.900000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.083780e+03,  6.047760e+03,  7.800000e-01,  8.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.008294e+04,  8.663070e+03,  6.600000e-01,  7.100000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.038476e+04,  6.111040e+03,  2.000000e-02,  2.000000e-02,\n",
      "         0.000000e+00],\n",
      "       [-9.717500e+03,  7.942910e+03,  2.300000e-01,  2.500000e-01,\n",
      "         0.000000e+00],\n",
      "       [-6.065180e+03,  4.332700e+03,  2.800000e-01,  2.900000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.214840e+03,  8.421390e+03,  3.500000e-01,  3.600000e-01,\n",
      "         0.000000e+00],\n",
      "       [-9.479850e+03,  7.382160e+03,  1.600000e-01,  1.600000e-01,\n",
      "         0.000000e+00],\n",
      "       [-9.866470e+03,  2.432610e+03,  9.000000e-01,  9.100000e-01,\n",
      "         1.000000e+00],\n",
      "       [-7.763960e+03,  3.958430e+03,  3.000000e-02,  5.000000e-02,\n",
      "         1.000000e+00],\n",
      "       [-8.232410e+03,  8.461100e+03,  5.800000e-01,  6.100000e-01,\n",
      "         0.000000e+00],\n",
      "       [-9.492930e+03,  8.764610e+03,  7.000000e-02,  7.000000e-02,\n",
      "         0.000000e+00],\n",
      "       [-1.173927e+04,  6.870820e+03,  2.000000e-02,  3.000000e-02,\n",
      "         0.000000e+00],\n",
      "       [-1.055455e+04,  7.020430e+03,  4.100000e-01,  4.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.130193e+04,  5.796920e+03,  9.400000e-01,  9.400000e-01,\n",
      "         0.000000e+00],\n",
      "       [-9.634850e+03,  6.778550e+03,  8.000000e-01,  8.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-7.040590e+03,  3.867330e+03,  9.000000e-02,  1.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.231520e+03,  6.086050e+03,  8.600000e-01,  8.700000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.098923e+04,  6.515170e+03,  9.900000e-01,  9.800000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.069740e+04,  6.946710e+03,  3.200000e-01,  3.300000e-01,\n",
      "         0.000000e+00],\n",
      "       [-6.448800e+03,  7.196810e+03,  9.400000e-01,  9.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-7.834090e+03,  3.701500e+03,  6.000000e-02,  6.000000e-02,\n",
      "         1.000000e+00],\n",
      "       [-1.225441e+04,  6.809810e+03,  9.800000e-01,  9.800000e-01,\n",
      "         0.000000e+00],\n",
      "       [-9.819080e+03,  6.500060e+03,  1.200000e-01,  1.100000e-01,\n",
      "         0.000000e+00],\n",
      "       [-7.980660e+03,  3.277480e+03,  9.500000e-01,  9.600000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.124690e+03,  7.266920e+03,  2.300000e-01,  2.700000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.136268e+04,  6.216880e+03,  7.000000e-01,  7.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.060948e+04,  7.781030e+03,  2.300000e-01,  2.700000e-01,\n",
      "         0.000000e+00],\n",
      "       [-7.828770e+03,  3.354560e+03,  2.900000e-01,  3.100000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.008424e+04,  7.171150e+03,  0.000000e+00,  0.000000e+00,\n",
      "         0.000000e+00],\n",
      "       [-9.489330e+03,  8.563430e+03,  7.700000e-01,  7.900000e-01,\n",
      "         0.000000e+00],\n",
      "       [-7.701670e+03,  3.513980e+03,  4.300000e-01,  4.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.583060e+03,  5.113440e+03,  6.600000e-01,  7.100000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.194370e+03,  4.380060e+03,  8.200000e-01,  8.300000e-01,\n",
      "         1.000000e+00],\n",
      "       [-6.129660e+03,  5.666610e+03,  1.900000e-01,  1.900000e-01,\n",
      "         1.000000e+00],\n",
      "       [-8.438220e+03,  5.211110e+03,  3.300000e-01,  3.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-8.859230e+03,  7.801280e+03,  1.700000e-01,  1.700000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.874310e+03,  7.544830e+03,  3.900000e-01,  3.900000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.214107e+04,  6.331870e+03,  8.000000e-02,  9.000000e-02,\n",
      "         0.000000e+00],\n",
      "       [-5.690470e+03,  5.281690e+03,  7.800000e-01,  8.100000e-01,\n",
      "         1.000000e+00],\n",
      "       [-8.692660e+03,  7.343120e+03,  1.600000e-01,  1.600000e-01,\n",
      "         0.000000e+00],\n",
      "       [-6.348780e+03,  4.206190e+03,  5.700000e-01,  6.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-8.732330e+03,  4.635660e+03,  3.600000e-01,  3.700000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.149357e+04,  6.799740e+03,  2.000000e-01,  2.100000e-01,\n",
      "         0.000000e+00],\n",
      "       [-7.902380e+03,  9.175590e+03,  5.300000e-01,  5.500000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.162674e+04,  7.359440e+03,  2.000000e-02,  3.000000e-02,\n",
      "         0.000000e+00],\n",
      "       [-5.875170e+03,  5.098260e+03,  1.000000e+00,  1.000000e+00,\n",
      "         1.000000e+00],\n",
      "       [-9.739370e+03,  8.514460e+03,  7.400000e-01,  7.500000e-01,\n",
      "         0.000000e+00],\n",
      "       [-8.449310e+03,  7.565750e+03,  4.100000e-01,  4.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.004327e+04,  7.906050e+03,  6.600000e-01,  7.000000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.011162e+04,  8.917090e+03,  5.000000e-02,  6.000000e-02,\n",
      "         0.000000e+00],\n",
      "       [-6.887270e+03,  4.030500e+03,  4.000000e-01,  4.100000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.499970e+03,  7.950450e+03,  7.600000e-01,  7.800000e-01,\n",
      "         0.000000e+00],\n",
      "       [-8.261420e+03,  7.869390e+03,  5.200000e-01,  5.500000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.059414e+04,  6.904850e+03,  1.700000e-01,  1.700000e-01,\n",
      "         0.000000e+00],\n",
      "       [-1.012484e+04,  7.218330e+03,  1.800000e-01,  1.800000e-01,\n",
      "         0.000000e+00],\n",
      "       [-8.771550e+03,  7.655780e+03,  3.400000e-01,  3.500000e-01,\n",
      "         0.000000e+00],\n",
      "       [-6.824520e+03,  4.104860e+03,  2.300000e-01,  2.600000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.895470e+03,  5.561870e+03,  1.400000e-01,  1.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.450170e+03,  7.450480e+03,  3.700000e-01,  3.800000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.890540e+03,  4.486520e+03,  2.900000e-01,  3.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.199190e+03,  6.543520e+03,  8.000000e-02,  8.000000e-02,\n",
      "         0.000000e+00],\n",
      "       [-6.709020e+03,  5.072360e+03,  2.300000e-01,  2.500000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.156920e+03,  7.705330e+03,  3.000000e-02,  4.000000e-02,\n",
      "         0.000000e+00],\n",
      "       [-1.230546e+04,  6.715320e+03,  9.100000e-01,  9.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-6.934970e+03,  4.726010e+03,  7.700000e-01,  7.900000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.069710e+03,  9.197930e+03,  1.300000e-01,  1.300000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.715830e+03,  5.085020e+03,  2.200000e-01,  2.500000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.040084e+04,  7.836830e+03,  7.500000e-01,  7.600000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.307800e+03,  6.495120e+03,  2.100000e-01,  2.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.774910e+03,  8.199760e+03,  8.400000e-01,  8.400000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.569770e+03,  5.459960e+03,  8.500000e-01,  8.600000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.158890e+03,  8.026080e+03,  4.600000e-01,  4.600000e-01,\n",
      "         0.000000e+00],\n",
      "       [-7.576610e+03,  4.050470e+03,  1.500000e-01,  1.500000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.176717e+04,  5.794270e+03,  1.300000e-01,  1.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.530200e+03,  5.804640e+03,  2.900000e-01,  3.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-8.792440e+03,  3.602590e+03,  8.000000e-02,  9.000000e-02,\n",
      "         1.000000e+00],\n",
      "       [-5.753120e+03,  5.100220e+03,  5.700000e-01,  5.900000e-01,\n",
      "         1.000000e+00],\n",
      "       [-9.988180e+03,  7.243020e+03,  4.000000e-01,  4.000000e-01,\n",
      "         0.000000e+00],\n",
      "       [-6.572120e+03,  4.345600e+03,  4.900000e-01,  5.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-6.996260e+03,  4.098000e+03,  4.200000e-01,  4.300000e-01,\n",
      "         1.000000e+00],\n",
      "       [-1.038996e+04,  7.122670e+03,  7.400000e-01,  7.500000e-01,\n",
      "         0.000000e+00],\n",
      "       [-7.990550e+03,  3.038690e+03,  1.400000e-01,  1.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-8.990440e+03,  7.370020e+03,  2.000000e-01,  2.200000e-01,\n",
      "         0.000000e+00]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n",
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Layerno: 6\n",
      "Time 286.558246\n",
      "Time per LP neuron 2.865582\n",
      "LP used on 100 neurons.\n",
      "Median global rank: 0.538214\n",
      "Median tigthness of hat bounds: 77724.690745 \n",
      "\n",
      "Min tigthness of hat bounds: 47594.117378 \n",
      "\n",
      "Max tigthness of hat bounds: 98288.923369 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-4.342127e+04,  3.653225e+04,  5.000000e-02,  7.000000e-02,\n",
      "         0.000000e+00],\n",
      "       [-3.395565e+04,  1.958399e+04,  4.100000e-01,  4.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.576158e+04,  2.138105e+04,  5.300000e-01,  5.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.781152e+04,  2.830942e+04,  5.400000e-01,  5.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.968655e+04,  4.975539e+04,  9.600000e-01,  9.500000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.117071e+04,  3.062729e+04,  3.800000e-01,  3.800000e-01,\n",
      "         0.000000e+00],\n",
      "       [-3.712630e+04,  1.739246e+04,  8.900000e-01,  8.600000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.786739e+04,  2.620744e+04,  6.900000e-01,  6.300000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.869643e+04,  3.815715e+04,  8.200000e-01,  7.800000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.211032e+04,  3.730350e+04,  8.900000e-01,  8.700000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.709961e+04,  4.185262e+04,  4.500000e-01,  4.300000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.791723e+04,  2.314165e+04,  7.600000e-01,  6.800000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.101615e+04,  3.605646e+04,  2.900000e-01,  3.100000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.266792e+04,  3.350835e+04,  8.200000e-01,  7.800000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.753696e+04,  3.509145e+04,  8.400000e-01,  8.000000e-01,\n",
      "         0.000000e+00],\n",
      "       [-3.569289e+04,  1.632415e+04,  9.100000e-01,  8.800000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.554356e+04,  3.520630e+04,  9.700000e-01,  9.600000e-01,\n",
      "         0.000000e+00],\n",
      "       [-3.274070e+04,  2.190830e+04,  9.400000e-01,  9.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-6.117233e+04,  2.739769e+04,  8.600000e-01,  8.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-3.583661e+04,  2.591515e+04,  5.500000e-01,  5.100000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.085482e+04,  3.432548e+04,  5.600000e-01,  5.400000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.135011e+04,  3.997316e+04,  9.100000e-01,  8.900000e-01,\n",
      "         0.000000e+00],\n",
      "       [-3.715194e+04,  4.273494e+04,  9.200000e-01,  9.000000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.772306e+04,  4.029709e+04,  3.800000e-01,  3.800000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.575742e+04,  3.082831e+04,  1.400000e-01,  1.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.715503e+04,  3.051728e+04,  1.700000e-01,  1.800000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.553559e+04,  4.180815e+04,  1.000000e-02,  1.000000e-02,\n",
      "         0.000000e+00],\n",
      "       [-5.231254e+04,  3.141315e+04,  3.200000e-01,  3.400000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.635995e+04,  2.612952e+04,  9.800000e-01,  9.800000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.231071e+04,  3.746963e+04,  8.000000e-02,  7.000000e-02,\n",
      "         0.000000e+00],\n",
      "       [-3.318753e+04,  2.046822e+04,  1.000000e-01,  8.000000e-02,\n",
      "         1.000000e+00],\n",
      "       [-2.425971e+04,  2.693270e+04,  1.600000e-01,  1.700000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.148314e+04,  2.566044e+04,  5.700000e-01,  5.500000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.612716e+04,  2.146696e+04,  1.100000e-01,  1.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.452904e+04,  3.522523e+04,  7.800000e-01,  7.300000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.794974e+04,  2.616492e+04,  1.500000e-01,  1.600000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.767135e+04,  3.836924e+04,  4.400000e-01,  4.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.993553e+04,  2.648551e+04,  3.300000e-01,  3.500000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.845136e+04,  2.672652e+04,  7.300000e-01,  6.700000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.021538e+04,  3.254423e+04,  2.300000e-01,  2.300000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.757496e+04,  3.313751e+04,  4.800000e-01,  4.600000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.970126e+04,  2.448772e+04,  5.300000e-01,  4.900000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.830232e+04,  2.066123e+04,  8.400000e-01,  8.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.978532e+04,  2.535578e+04,  5.500000e-01,  5.300000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.944750e+04,  1.616661e+04,  2.400000e-01,  2.500000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.239172e+04,  3.251454e+04,  1.000000e+00,  1.000000e+00,\n",
      "         0.000000e+00],\n",
      "       [-3.416472e+04,  1.830152e+04,  3.200000e-01,  3.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.293849e+04,  3.860635e+04,  6.200000e-01,  5.800000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.396555e+04,  3.351662e+04,  6.700000e-01,  6.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.282424e+04,  3.642545e+04,  9.600000e-01,  9.500000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.814676e+04,  2.079091e+04,  3.800000e-01,  3.900000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.221862e+04,  2.919612e+04,  3.100000e-01,  3.300000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.188001e+04,  2.108855e+04,  7.700000e-01,  7.100000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.731120e+04,  3.066904e+04,  1.000000e-02,  0.000000e+00,\n",
      "         0.000000e+00],\n",
      "       [-5.588307e+04,  3.140108e+04,  2.200000e-01,  2.100000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.017309e+04,  3.520124e+04,  2.700000e-01,  2.700000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.755288e+04,  2.393836e+04,  6.900000e-01,  6.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.262534e+04,  4.073001e+04,  7.700000e-01,  7.100000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.769873e+04,  3.536892e+04,  6.700000e-01,  6.100000e-01,\n",
      "         0.000000e+00],\n",
      "       [-3.280764e+04,  1.948100e+04,  1.200000e-01,  1.100000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.901088e+04,  1.879814e+04,  2.300000e-01,  2.300000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.550499e+04,  2.515102e+04,  3.900000e-01,  4.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.115082e+04,  3.066161e+04,  7.900000e-01,  7.500000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.076785e+04,  2.177753e+04,  7.900000e-01,  7.500000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.647162e+04,  4.020350e+04,  2.300000e-01,  2.400000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.812928e+04,  2.623826e+04,  8.100000e-01,  7.700000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.544067e+04,  3.397091e+04,  2.300000e-01,  2.400000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.496413e+04,  4.007827e+04,  2.800000e-01,  2.900000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.410155e+04,  3.955464e+04,  4.200000e-01,  4.100000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.548817e+04,  3.004459e+04,  9.200000e-01,  9.100000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.490169e+04,  3.577949e+04,  1.300000e-01,  1.300000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.233971e+04,  3.435219e+04,  6.700000e-01,  6.100000e-01,\n",
      "         0.000000e+00],\n",
      "       [-3.290198e+04,  2.691660e+04,  1.500000e-01,  1.700000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.186500e+04,  2.062762e+04,  8.500000e-01,  8.100000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.648357e+04,  3.281572e+04,  9.700000e-01,  9.700000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.709627e+04,  2.699223e+04,  5.200000e-01,  4.800000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.797624e+04,  2.724112e+04,  3.000000e-02,  5.000000e-02,\n",
      "         1.000000e+00],\n",
      "       [-5.534569e+04,  3.707798e+04,  2.200000e-01,  2.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-3.351587e+04,  2.383097e+04,  1.500000e-01,  1.600000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.998488e+04,  2.281018e+04,  2.700000e-01,  2.800000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.866213e+04,  2.528903e+04,  2.400000e-01,  2.500000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.969901e+04,  4.069908e+04,  2.000000e-01,  2.000000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.387179e+04,  4.061737e+04,  7.700000e-01,  6.900000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.178715e+04,  4.148050e+04,  3.600000e-01,  3.600000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.292642e+04,  3.037122e+04,  7.100000e-01,  6.600000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.001589e+04,  2.400522e+04,  1.000000e-02,  3.000000e-02,\n",
      "         1.000000e+00],\n",
      "       [-3.127652e+04,  2.561900e+04,  5.100000e-01,  4.700000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.983633e+04,  3.922600e+04,  2.800000e-01,  3.000000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.452003e+04,  4.088124e+04,  3.800000e-01,  3.700000e-01,\n",
      "         0.000000e+00],\n",
      "       [-3.109192e+04,  1.933152e+04,  6.800000e-01,  6.200000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.839811e+04,  1.984107e+04,  9.000000e-01,  8.700000e-01,\n",
      "         1.000000e+00],\n",
      "       [-6.810594e+04,  3.018298e+04,  6.300000e-01,  5.900000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.904682e+04,  3.400492e+04,  1.000000e-02,  2.000000e-02,\n",
      "         0.000000e+00],\n",
      "       [-4.632576e+04,  3.795130e+04,  5.900000e-01,  5.600000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.454945e+04,  4.142613e+04,  2.100000e-01,  2.100000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.789534e+04,  2.439855e+04,  8.400000e-01,  8.100000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.621816e+04,  2.822680e+04,  7.000000e-01,  6.500000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.657748e+04,  2.408988e+04,  8.400000e-01,  7.900000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.048408e+04,  3.876681e+04,  1.400000e-01,  1.500000e-01,\n",
      "         0.000000e+00],\n",
      "       [-3.901835e+04,  4.560376e+04,  8.500000e-01,  8.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-3.288699e+04,  2.263755e+04,  1.000000e-02,  2.000000e-02,\n",
      "         1.000000e+00],\n",
      "       [-4.740459e+04,  4.257132e+04,  6.500000e-01,  5.900000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.664130e+04,  3.380384e+04,  9.000000e-02,  8.000000e-02,\n",
      "         0.000000e+00],\n",
      "       [-3.444679e+04,  2.634608e+04,  7.700000e-01,  7.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.355612e+04,  2.885005e+04,  5.500000e-01,  5.200000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.500562e+04,  2.399864e+04,  8.700000e-01,  8.300000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.991265e+04,  2.431340e+04,  3.000000e-02,  4.000000e-02,\n",
      "         1.000000e+00],\n",
      "       [-4.369642e+04,  3.849844e+04,  6.900000e-01,  6.400000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.985261e+04,  3.725932e+04,  7.400000e-01,  6.700000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.626186e+04,  2.833571e+04,  4.600000e-01,  4.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.748925e+04,  3.950537e+04,  4.000000e-02,  5.000000e-02,\n",
      "         0.000000e+00],\n",
      "       [-3.517145e+04,  2.208433e+04,  6.800000e-01,  6.300000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.467482e+04,  3.963814e+04,  1.900000e-01,  1.900000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.743597e+04,  2.714144e+04,  8.300000e-01,  7.900000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.338928e+04,  2.152370e+04,  4.700000e-01,  4.600000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.643411e+04,  2.822968e+04,  5.400000e-01,  5.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.543058e+04,  3.984638e+04,  1.300000e-01,  1.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-3.032857e+04,  2.514486e+04,  4.500000e-01,  4.300000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.008112e+04,  3.066544e+04,  8.800000e-01,  8.500000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.691801e+04,  3.459281e+04,  8.100000e-01,  7.600000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.678471e+04,  3.884955e+04,  9.300000e-01,  9.300000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.437972e+04,  4.003846e+04,  1.900000e-01,  1.900000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.970914e+04,  2.703367e+04,  9.400000e-01,  9.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.519788e+04,  4.705415e+04,  6.500000e-01,  6.000000e-01,\n",
      "         0.000000e+00],\n",
      "       [-3.260687e+04,  2.040863e+04,  2.600000e-01,  2.700000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.610650e+04,  2.027000e+04,  2.500000e-01,  2.600000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.963147e+04,  2.577840e+04,  4.200000e-01,  4.100000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.584674e+04,  3.311053e+04,  9.800000e-01,  9.700000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.246578e+04,  1.921757e+04,  7.900000e-01,  7.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.614804e+04,  2.886418e+04,  9.800000e-01,  9.800000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.770641e+04,  2.433657e+04,  3.000000e-01,  3.200000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.099732e+04,  2.087137e+04,  9.300000e-01,  9.300000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.565423e+04,  2.123550e+04,  5.200000e-01,  4.900000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.556999e+04,  3.450809e+04,  2.400000e-01,  2.500000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.805514e+04,  3.651947e+04,  6.100000e-01,  5.700000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.980059e+04,  3.522462e+04,  7.900000e-01,  7.400000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.241277e+04,  1.807618e+04,  4.000000e-02,  6.000000e-02,\n",
      "         1.000000e+00],\n",
      "       [-3.591702e+04,  2.431052e+04,  1.100000e-01,  9.000000e-02,\n",
      "         1.000000e+00],\n",
      "       [-3.198018e+04,  1.990575e+04,  7.800000e-01,  7.200000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.537149e+04,  3.848879e+04,  7.500000e-01,  6.800000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.559489e+04,  2.713483e+04,  4.700000e-01,  4.500000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.845649e+04,  3.757607e+04,  8.700000e-01,  8.400000e-01,\n",
      "         0.000000e+00],\n",
      "       [-3.974876e+04,  4.692333e+04,  7.300000e-01,  6.600000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.148348e+04,  4.164235e+04,  8.100000e-01,  7.500000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.382682e+04,  3.040315e+04,  3.100000e-01,  3.300000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.372874e+04,  1.852451e+04,  2.700000e-01,  2.800000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.248898e+04,  2.954004e+04,  7.700000e-01,  7.000000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.472990e+04,  2.939439e+04,  1.400000e-01,  1.500000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.067882e+04,  1.977468e+04,  4.500000e-01,  4.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.123462e+04,  3.762240e+04,  1.300000e-01,  1.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.366227e+04,  3.018893e+04,  1.400000e-01,  1.400000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.374689e+04,  2.641054e+04,  1.200000e-01,  1.100000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.596716e+04,  3.216116e+04,  9.900000e-01,  9.900000e-01,\n",
      "         0.000000e+00],\n",
      "       [-3.122781e+04,  2.951407e+04,  3.000000e-02,  4.000000e-02,\n",
      "         1.000000e+00],\n",
      "       [-5.131698e+04,  3.997318e+04,  9.600000e-01,  9.600000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.962275e+04,  3.933191e+04,  1.700000e-01,  1.800000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.753014e+04,  2.463726e+04,  1.000000e+00,  1.000000e+00,\n",
      "         1.000000e+00],\n",
      "       [-4.577105e+04,  3.709805e+04,  1.100000e-01,  1.000000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.497759e+04,  1.770889e+04,  5.800000e-01,  5.500000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.332134e+04,  2.291443e+04,  9.800000e-01,  9.900000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.610136e+04,  3.487258e+04,  3.000000e-01,  3.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-3.247829e+04,  2.325473e+04,  7.800000e-01,  7.300000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.108194e+04,  3.043390e+04,  5.000000e-02,  6.000000e-02,\n",
      "         0.000000e+00],\n",
      "       [-4.694711e+04,  3.241578e+04,  8.900000e-01,  8.600000e-01,\n",
      "         0.000000e+00],\n",
      "       [-6.225515e+04,  1.746679e+04,  7.800000e-01,  7.200000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.684029e+04,  3.350590e+04,  9.100000e-01,  8.900000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.659850e+04,  3.961668e+04,  7.700000e-01,  6.900000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.823049e+04,  2.811338e+04,  3.400000e-01,  3.500000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.921057e+04,  3.397821e+04,  7.000000e-01,  6.500000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.952041e+04,  2.597559e+04,  5.500000e-01,  5.200000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.900524e+04,  4.509357e+04,  9.200000e-01,  9.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.947904e+04,  2.933495e+04,  4.700000e-01,  4.500000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.172218e+04,  3.155599e+04,  9.200000e-01,  9.100000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.214850e+04,  2.139353e+04,  5.500000e-01,  5.300000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.976382e+04,  2.665016e+04,  4.300000e-01,  4.200000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.924152e+04,  3.111760e+04,  8.700000e-01,  8.400000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.099645e+04,  4.127201e+04,  2.200000e-01,  2.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.405477e+04,  1.891439e+04,  1.000000e-01,  9.000000e-02,\n",
      "         1.000000e+00],\n",
      "       [-3.397437e+04,  1.948500e+04,  6.300000e-01,  5.800000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.617955e+04,  1.880514e+04,  6.000000e-01,  5.700000e-01,\n",
      "         1.000000e+00],\n",
      "       [-6.396309e+04,  3.087131e+04,  8.800000e-01,  8.500000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.199422e+04,  3.861238e+04,  3.600000e-01,  3.700000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.789390e+04,  2.890288e+04,  6.500000e-01,  6.000000e-01,\n",
      "         0.000000e+00],\n",
      "       [-3.568239e+04,  1.949678e+04,  4.900000e-01,  4.700000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.137693e+04,  2.543228e+04,  6.000000e-01,  5.600000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.467920e+04,  2.115934e+04,  2.000000e-01,  2.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.340721e+04,  1.851925e+04,  9.000000e-01,  8.800000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.859033e+04,  2.254198e+04,  1.300000e-01,  1.300000e-01,\n",
      "         1.000000e+00],\n",
      "       [-2.474798e+04,  2.706674e+04,  8.200000e-01,  7.700000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.664184e+04,  3.592252e+04,  8.700000e-01,  8.300000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.828620e+04,  3.928795e+04,  9.300000e-01,  9.200000e-01,\n",
      "         0.000000e+00],\n",
      "       [-3.822075e+04,  2.061232e+04,  2.800000e-01,  2.900000e-01,\n",
      "         1.000000e+00],\n",
      "       [-5.372468e+04,  3.448189e+04,  2.800000e-01,  3.000000e-01,\n",
      "         0.000000e+00],\n",
      "       [-4.871650e+04,  2.875264e+04,  3.900000e-01,  3.900000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.843774e+04,  1.988873e+04,  9.100000e-01,  9.000000e-01,\n",
      "         1.000000e+00],\n",
      "       [-3.560108e+04,  1.705336e+04,  2.900000e-01,  3.100000e-01,\n",
      "         1.000000e+00],\n",
      "       [-4.907046e+04,  3.697166e+04,  3.400000e-01,  3.600000e-01,\n",
      "         0.000000e+00],\n",
      "       [-5.331115e+04,  3.761409e+04,  5.200000e-01,  4.800000e-01,\n",
      "         0.000000e+00],\n",
      "       [-2.867106e+04,  2.763554e+04,  2.000000e-02,  3.000000e-02,\n",
      "         1.000000e+00],\n",
      "       [-5.037750e+04,  3.497558e+04,  5.600000e-01,  5.400000e-01,\n",
      "         0.000000e+00]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n",
      "--------------------------\n",
      "Layerno: 7\n",
      "Time 0.353429\n",
      "Median global rank: 0.413929\n",
      "Median tigthness of hat bounds: 463413.247858 \n",
      "\n",
      "Min tigthness of hat bounds: 382541.422341 \n",
      "\n",
      "Max tigthness of hat bounds: 594420.397433 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-2.6219554e+05,  1.7655115e+05,  5.4000000e-01,  6.1000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4391742e+05,  2.3427647e+05,  2.5000000e-01,  2.9000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.0887987e+05,  1.5105707e+05,  4.4000000e-01,  5.3000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.5257208e+05,  1.9102971e+05,  3.4000000e-01,  3.7000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.6012834e+05,  2.2459617e+05,  6.3000000e-01,  7.0000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.0375149e+05,  1.8585105e+05,  7.4000000e-01,  7.5000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.0760474e+05,  1.3441990e+05,  4.1000000e-01,  4.7000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.8083400e+05,  1.8676197e+05,  4.2000000e-01,  5.0000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.7048997e+05,  1.9362020e+05,  8.8000000e-01,  9.2000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.6749645e+05,  1.7346367e+05,  6.9000000e-01,  7.4000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.7116096e+05,  1.5330959e+05,  9.3000000e-01,  9.6000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.2084524e+05,  2.0777550e+05,  2.4000000e-01,  2.8000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.4980381e+05,  1.2801521e+05,  9.0000000e-01,  9.5000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.1076526e+05,  1.5192322e+05,  7.5000000e-01,  7.7000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.7769441e+05,  2.0664340e+05,  5.9000000e-01,  6.5000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-1.9732869e+05,  2.3737663e+05,  1.0000000e-02,  0.0000000e+00,\n",
      "         0.0000000e+00],\n",
      "       [-3.0085311e+05,  1.6354426e+05,  5.6000000e-01,  6.3000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.5172075e+05,  2.2026159e+05,  1.5000000e-01,  2.0000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.9363960e+05,  2.0078079e+05,  4.3000000e-01,  5.2000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-4.3039324e+05,  1.4972559e+05,  3.0000000e-02,  3.0000000e-02,\n",
      "         0.0000000e+00],\n",
      "       [-2.3731635e+05,  1.8559095e+05,  8.2000000e-01,  8.5000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.5651598e+05,  1.9780952e+05,  7.6000000e-01,  7.7000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.6670375e+05,  1.6580559e+05,  3.0000000e-01,  3.3000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.0604635e+05,  1.6436536e+05,  6.0000000e-01,  6.7000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.6561000e+05,  1.7380844e+05,  1.8000000e-01,  2.2000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.9945280e+05,  1.6986677e+05,  7.8000000e-01,  8.0000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.6720391e+05,  1.8289396e+05,  7.4000000e-01,  7.6000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.9800069e+05,  1.5765514e+05,  7.7000000e-01,  7.8000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.1818656e+05,  1.6747055e+05,  3.7000000e-01,  4.3000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.7916640e+05,  1.7122754e+05,  9.6000000e-01,  9.8000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.0125586e+05,  1.6386244e+05,  3.1000000e-01,  3.4000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.7201968e+05,  2.0887658e+05,  8.0000000e-02,  1.1000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.5250789e+05,  1.4953312e+05,  4.7000000e-01,  5.5000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.7605947e+05,  1.5985032e+05,  7.0000000e-02,  8.0000000e-02,\n",
      "         0.0000000e+00],\n",
      "       [-2.9628184e+05,  1.7737952e+05,  2.7000000e-01,  3.1000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.9077313e+05,  2.2264990e+05,  1.0000000e-01,  1.4000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.7233444e+05,  1.8755912e+05,  8.6000000e-01,  9.0000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.2832944e+05,  1.3086402e+05,  1.8000000e-01,  2.1000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.6286551e+05,  1.8911600e+05,  1.2000000e-01,  1.6000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.8054659e+05,  1.8533182e+05,  1.8000000e-01,  2.1000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.2156419e+05,  1.5450938e+05,  5.2000000e-01,  5.8000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.9689789e+05,  1.7944134e+05,  4.1000000e-01,  4.8000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.2472547e+05,  1.7571192e+05,  4.3000000e-01,  5.1000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4035989e+05,  1.9500409e+05,  3.5000000e-01,  3.8000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.2406811e+05,  2.0469392e+05,  2.3000000e-01,  2.7000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-4.2937969e+05,  1.4286113e+05,  2.5000000e-01,  2.9000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.3367719e+05,  1.7852357e+05,  2.5000000e-01,  3.0000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.9317712e+05,  1.4949574e+05,  8.1000000e-01,  8.4000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.6655737e+05,  1.5183467e+05,  7.7000000e-01,  7.8000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.6700369e+05,  1.5741778e+05,  8.3000000e-01,  8.7000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.6169435e+05,  1.5469506e+05,  1.5000000e-01,  1.9000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4317810e+05,  1.3936333e+05,  2.0000000e-02,  2.0000000e-02,\n",
      "         0.0000000e+00],\n",
      "       [-2.7103600e+05,  1.6320178e+05,  3.2000000e-01,  3.5000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.4515292e+05,  1.4320043e+05,  7.7000000e-01,  7.9000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.9164281e+05,  1.7691540e+05,  8.8000000e-01,  9.1000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4935634e+05,  1.9203581e+05,  6.4000000e-01,  7.1000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.3976694e+05,  1.5582977e+05,  2.1000000e-01,  2.5000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.1578604e+05,  1.4730850e+05,  8.3000000e-01,  8.6000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.3949808e+05,  2.3057754e+05,  8.3000000e-01,  8.7000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.8759990e+05,  1.8968889e+05,  3.1000000e-01,  3.5000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.5289407e+05,  2.1809832e+05,  3.8000000e-01,  4.4000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4675385e+05,  1.9299920e+05,  2.4000000e-01,  2.7000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4091561e+05,  1.8095681e+05,  4.0000000e-01,  4.6000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.1041748e+05,  1.9388959e+05,  9.0000000e-02,  1.3000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.3427840e+05,  1.8362682e+05,  8.9000000e-01,  9.4000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.7541398e+05,  2.1820446e+05,  5.1000000e-01,  5.7000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.1552185e+05,  1.3828443e+05,  5.2000000e-01,  5.9000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.9536677e+05,  2.3879648e+05,  9.0000000e-01,  9.4000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-1.9827514e+05,  1.8475082e+05,  5.2000000e-01,  5.8000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.7360551e+05,  1.4466747e+05,  5.7000000e-01,  6.4000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.8459083e+05,  2.0341177e+05,  2.0000000e-01,  2.4000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.8889657e+05,  1.8600803e+05,  6.4000000e-01,  7.1000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.8666611e+05,  2.0355858e+05,  1.0000000e-02,  1.0000000e-02,\n",
      "         0.0000000e+00],\n",
      "       [-3.5623408e+05,  1.5244559e+05,  1.0000000e-01,  1.4000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.9576441e+05,  1.8253103e+05,  5.8000000e-01,  6.5000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4512596e+05,  2.1370578e+05,  4.2000000e-01,  5.0000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.3222887e+05,  1.9992330e+05,  3.8000000e-01,  4.5000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.2761438e+05,  1.5659836e+05,  8.3000000e-01,  8.5000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.9691646e+05,  2.0198260e+05,  8.3000000e-01,  8.6000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.7692256e+05,  1.7955068e+05,  3.8000000e-01,  4.4000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.7476003e+05,  1.7972686e+05,  3.6000000e-01,  3.9000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.5917191e+05,  1.3204087e+05,  8.0000000e-01,  8.1000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.2078363e+05,  1.9996201e+05,  5.0000000e-01,  5.6000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.6452484e+05,  1.8758674e+05,  8.4000000e-01,  8.8000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.8020410e+05,  1.5876958e+05,  4.0000000e-02,  5.0000000e-02,\n",
      "         0.0000000e+00],\n",
      "       [-2.5787082e+05,  1.8149874e+05,  5.1000000e-01,  5.7000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.2291869e+05,  1.8931155e+05,  5.0000000e-02,  6.0000000e-02,\n",
      "         0.0000000e+00],\n",
      "       [-4.2550802e+05,  1.0605697e+05,  5.3000000e-01,  6.0000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.7976425e+05,  1.7745490e+05,  4.3000000e-01,  5.2000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.3360139e+05,  2.2994926e+05,  9.0000000e-02,  1.2000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.5966000e+05,  1.8522419e+05,  7.0000000e-02,  9.0000000e-02,\n",
      "         0.0000000e+00],\n",
      "       [-2.5869912e+05,  1.6012178e+05,  9.4000000e-01,  9.7000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.0408888e+05,  1.7637856e+05,  5.2000000e-01,  5.9000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.2111722e+05,  1.9325482e+05,  6.5000000e-01,  7.2000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.3573401e+05,  2.1723085e+05,  4.0000000e-01,  4.6000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.7641829e+05,  1.9289156e+05,  8.0000000e-02,  1.1000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4964564e+05,  1.8779588e+05,  1.0000000e-01,  1.3000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.0201998e+05,  1.7265906e+05,  1.4000000e-01,  1.8000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.8203748e+05,  1.3857908e+05,  6.5000000e-01,  7.2000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.0516770e+05,  1.8139434e+05,  9.7000000e-01,  9.9000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.1640811e+05,  2.5230793e+05,  5.9000000e-01,  6.6000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.8561196e+05,  1.4885822e+05,  8.8000000e-01,  9.3000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.9661159e+05,  1.6356869e+05,  4.7000000e-01,  5.4000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.6825131e+05,  2.1346303e+05,  9.0000000e-02,  1.2000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.3962542e+05,  1.8871488e+05,  2.0000000e-02,  2.0000000e-02,\n",
      "         0.0000000e+00],\n",
      "       [-2.4126957e+05,  1.9297722e+05,  1.1000000e-01,  1.6000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.6581717e+05,  2.1352162e+05,  5.4000000e-01,  6.1000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.6833082e+05,  2.1634630e+05,  4.5000000e-01,  5.3000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.0758319e+05,  1.5506946e+05,  9.6000000e-01,  9.8000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.1924970e+05,  2.0371523e+05,  3.0000000e-02,  3.0000000e-02,\n",
      "         0.0000000e+00],\n",
      "       [-2.5500174e+05,  2.1211571e+05,  3.5000000e-01,  3.8000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.3158866e+05,  2.7398992e+05,  4.1000000e-01,  5.0000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.7614071e+05,  1.3722404e+05,  2.8000000e-01,  3.2000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.0314893e+05,  2.2449907e+05,  5.9000000e-01,  6.6000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.8876465e+05,  1.7585623e+05,  8.0000000e-01,  8.2000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.9993684e+05,  1.5600019e+05,  1.5000000e-01,  1.9000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.7794731e+05,  1.3435156e+05,  8.0000000e-01,  8.3000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.7508519e+05,  1.8491525e+05,  6.2000000e-01,  6.9000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.0474466e+05,  1.6133120e+05,  7.7000000e-01,  7.9000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.7165384e+05,  1.8516271e+05,  5.4000000e-01,  6.2000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.1164998e+05,  2.1448168e+05,  6.6000000e-01,  7.3000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.8295178e+05,  1.9380734e+05,  3.4000000e-01,  3.6000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.8850004e+05,  1.9367984e+05,  7.0000000e-02,  8.0000000e-02,\n",
      "         0.0000000e+00],\n",
      "       [-2.1766611e+05,  2.0983152e+05,  6.2000000e-01,  7.0000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.5330677e+05,  1.9695347e+05,  1.1000000e-01,  1.5000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-4.0456625e+05,  1.6194588e+05,  6.0000000e-01,  6.8000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.6921260e+05,  1.4933368e+05,  3.3000000e-01,  3.6000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.3367897e+05,  1.7984462e+05,  3.0000000e-02,  4.0000000e-02,\n",
      "         0.0000000e+00],\n",
      "       [-2.4578731e+05,  1.9196708e+05,  1.7000000e-01,  2.0000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.3169063e+05,  2.2700628e+05,  1.3000000e-01,  1.7000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4780955e+05,  2.3080051e+05,  3.7000000e-01,  4.2000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.5809563e+05,  1.8296899e+05,  1.9000000e-01,  2.3000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.6942509e+05,  1.4981253e+05,  5.0000000e-02,  6.0000000e-02,\n",
      "         0.0000000e+00],\n",
      "       [-2.2620963e+05,  2.0837911e+05,  8.3000000e-01,  8.8000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4366199e+05,  2.0449727e+05,  8.8000000e-01,  9.1000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.2148862e+05,  1.9016169e+05,  8.5000000e-01,  8.9000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.6251594e+05,  1.7516410e+05,  3.7000000e-01,  4.2000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.3677929e+05,  1.8919741e+05,  3.6000000e-01,  4.0000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4110001e+05,  2.5025911e+05,  1.0000000e-01,  1.5000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.0772103e+05,  2.5555481e+05,  9.2000000e-01,  9.5000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.3582588e+05,  1.9799811e+05,  4.1000000e-01,  4.9000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.2422993e+05,  1.6388744e+05,  4.1000000e-01,  4.9000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.5737296e+05,  1.7774768e+05,  3.0000000e-01,  3.3000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.6218682e+05,  1.5727398e+05,  7.9000000e-01,  8.1000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.5644956e+05,  1.7054071e+05,  6.0000000e-01,  6.8000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.2406092e+05,  1.3062486e+05,  3.7000000e-01,  4.1000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.0724231e+05,  1.5051603e+05,  1.0000000e+00,  1.0000000e+00,\n",
      "         0.0000000e+00],\n",
      "       [-2.4606937e+05,  2.0511597e+05,  1.2000000e-01,  1.7000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.1001295e+05,  1.9547970e+05,  1.4000000e-01,  1.8000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.7849192e+05,  2.1049184e+05,  9.9000000e-01,  9.9000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.6430634e+05,  1.8536579e+05,  2.4000000e-01,  2.8000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.3105715e+05,  2.4163954e+05,  2.0000000e-01,  2.4000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.6355584e+05,  1.6122380e+05,  4.9000000e-01,  5.5000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.9793166e+05,  1.9327897e+05,  4.0000000e-02,  4.0000000e-02,\n",
      "         0.0000000e+00],\n",
      "       [-1.8838908e+05,  2.2035381e+05,  5.7000000e-01,  6.4000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4078958e+05,  1.8539726e+05,  7.2000000e-01,  7.5000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.5506945e+05,  1.9232628e+05,  3.4000000e-01,  3.7000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.5903369e+05,  1.8574487e+05,  5.9000000e-01,  6.7000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.0407443e+05,  1.5263242e+05,  3.5000000e-01,  3.9000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.2402765e+05,  1.8046173e+05,  8.0000000e-02,  1.0000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.2490284e+05,  1.6819270e+05,  9.5000000e-01,  9.7000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.8024467e+05,  1.5099066e+05,  3.7000000e-01,  4.3000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-4.1792092e+05,  1.3964660e+05,  8.1000000e-01,  8.4000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.2943098e+05,  1.8727721e+05,  4.1000000e-01,  4.8000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.0216164e+05,  1.5834624e+05,  6.0000000e-02,  7.0000000e-02,\n",
      "         0.0000000e+00],\n",
      "       [-2.8758006e+05,  1.5064678e+05,  8.9000000e-01,  9.3000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4010671e+05,  2.2758937e+05,  3.7000000e-01,  4.1000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4179272e+05,  1.9712228e+05,  5.4000000e-01,  6.0000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.2870751e+05,  1.6763813e+05,  8.6000000e-01,  9.0000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4391335e+05,  2.2650255e+05,  3.1000000e-01,  3.4000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.4096174e+05,  1.8267912e+05,  7.8000000e-01,  8.0000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4808974e+05,  2.1627892e+05,  1.8000000e-01,  2.2000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4812829e+05,  1.8255505e+05,  1.0000000e+00,  1.0000000e+00,\n",
      "         0.0000000e+00],\n",
      "       [-3.2243554e+05,  1.5381383e+05,  7.0000000e-02,  9.0000000e-02,\n",
      "         0.0000000e+00],\n",
      "       [-3.0658932e+05,  1.6396774e+05,  6.5000000e-01,  7.3000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.6769011e+05,  2.0016453e+05,  6.9000000e-01,  7.4000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.2601668e+05,  2.0030933e+05,  8.0000000e-01,  8.2000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.7402422e+05,  2.3110543e+05,  2.1000000e-01,  2.5000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.3920017e+05,  2.4751580e+05,  4.6000000e-01,  5.4000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.9626371e+05,  1.7191499e+05,  5.6000000e-01,  6.3000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.4899819e+05,  1.1281809e+05,  7.4000000e-01,  7.5000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.5501340e+05,  1.5440039e+05,  8.4000000e-01,  8.9000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.7652171e+05,  2.0690615e+05,  3.9000000e-01,  4.5000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.8171561e+05,  1.8746475e+05,  5.0000000e-01,  5.6000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.2763386e+05,  2.1339741e+05,  4.1000000e-01,  4.7000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.6410003e+05,  2.0045364e+05,  2.0000000e-01,  2.5000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4086302e+05,  1.7467181e+05,  4.0000000e-02,  5.0000000e-02,\n",
      "         0.0000000e+00],\n",
      "       [-2.1717178e+05,  2.5265086e+05,  2.7000000e-01,  3.1000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.8418881e+05,  1.4699431e+05,  7.0000000e-02,  1.0000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.9405843e+05,  1.7176653e+05,  5.5000000e-01,  6.2000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-3.9985306e+05,  1.4450741e+05,  3.6000000e-01,  4.0000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.5816717e+05,  1.6580941e+05,  2.7000000e-01,  3.2000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.2265000e+05,  2.1853612e+05,  6.1000000e-01,  6.9000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4550916e+05,  2.5894923e+05,  8.0000000e-01,  8.3000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.5361668e+05,  2.3974761e+05,  6.0000000e-02,  7.0000000e-02,\n",
      "         0.0000000e+00],\n",
      "       [-2.4661798e+05,  1.6748520e+05,  2.2000000e-01,  2.6000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.8555409e+05,  1.7405398e+05,  9.4000000e-01,  9.6000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.6733975e+05,  1.6590589e+05,  8.8000000e-01,  9.2000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4282612e+05,  1.8388532e+05,  1.9000000e-01,  2.3000000e-01,\n",
      "         0.0000000e+00],\n",
      "       [-2.4872305e+05,  2.1781417e+05,  2.6000000e-01,  3.0000000e-01,\n",
      "         0.0000000e+00]])\n",
      "--------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Layerno: 8\n",
      "Time 18.958779\n",
      "Time per LP neuron 1.895878\n",
      "LP used on 10 neurons.\n",
      "Median global rank: nan\n",
      "Median tigthness of hat bounds: 1653373.436665 \n",
      "\n",
      "Min tigthness of hat bounds: 1211830.530964 \n",
      "\n",
      "Max tigthness of hat bounds: 5122620.004829 \n",
      "\n",
      "[LB_hat | UB_hat | global_rank | local_rank | use_LP]\n",
      "array([[-5.12262000e+06,  0.00000000e+00,             nan,\n",
      "                    nan,  1.00000000e+00],\n",
      "       [ 0.00000000e+00,  1.47875905e+06,             nan,\n",
      "                    nan,  1.00000000e+00],\n",
      "       [ 0.00000000e+00,  1.83599001e+06,             nan,\n",
      "                    nan,  1.00000000e+00],\n",
      "       [ 0.00000000e+00,  1.96776694e+06,             nan,\n",
      "                    nan,  1.00000000e+00],\n",
      "       [ 0.00000000e+00,  1.63786241e+06,             nan,\n",
      "                    nan,  1.00000000e+00],\n",
      "       [ 0.00000000e+00,  1.51068700e+06,             nan,\n",
      "                    nan,  1.00000000e+00],\n",
      "       [ 0.00000000e+00,  1.66888447e+06,             nan,\n",
      "                    nan,  1.00000000e+00],\n",
      "       [ 0.00000000e+00,  1.21183054e+06,             nan,\n",
      "                    nan,  1.00000000e+00],\n",
      "       [ 0.00000000e+00,  1.56171038e+06,             nan,\n",
      "                    nan,  1.00000000e+00],\n",
      "       [ 0.00000000e+00,  1.72698931e+06,             nan,\n",
      "                    nan,  1.00000000e+00]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -7090386.941794 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -11623.585150\n",
      "\n",
      "Margin per second (more positve is better): -9671.015791\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "can not be verified\n"
     ]
    }
   ],
   "source": [
    "stats = analyse_nn_and_write('mnist_relu_9_100', [10] , 0.1, global_rank_threshold=[0.0, 0.0], \n",
    "                             local_rank_threshold=[0.0, 0.0], tightness_threshold=[0.0, 0.0],\n",
    "                            influence_threshold=[0.5, 0.0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
