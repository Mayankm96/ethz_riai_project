{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../ELINA/python_interface/')\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "from elina_box import *\n",
    "from elina_interval import *\n",
    "from elina_abstract0 import *\n",
    "from elina_manager import *\n",
    "from elina_dimension import *\n",
    "from elina_scalar import *\n",
    "from elina_interval import *\n",
    "from elina_linexpr0 import *\n",
    "from elina_lincons0 import *\n",
    "import ctypes\n",
    "from ctypes.util import find_library\n",
    "from gurobipy import *\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "libc = CDLL(find_library('c'))\n",
    "cstdout = c_void_p.in_dll(libc, 'stdout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for debugging in jupyter notebook\n",
    "from IPython.core.debugger import set_trace #TODO remove at end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layers:\n",
    "    def __init__(self):\n",
    "        self.layertypes = []\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.numlayer = 0\n",
    "        self.ffn_counter = 0\n",
    "        self.rank = []\n",
    "        self.use_LP = []\n",
    "        self.LB_hat = []\n",
    "        self.UB_hat = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bias(text):\n",
    "    if len(text) < 1 or text[0] != '[':\n",
    "        raise Exception(\"expected '['\")\n",
    "    if text[-1] != ']':\n",
    "        raise Exception(\"expected ']'\")\n",
    "    v = np.array([*map(lambda x: np.double(x.strip()), text[1:-1].split(','))])\n",
    "    #return v.reshape((v.size,1))\n",
    "    return v\n",
    "\n",
    "def parse_vector(text):\n",
    "    if len(text) < 1 or text[0] != '[':\n",
    "        raise Exception(\"expected '['\")\n",
    "    if text[-1] != ']':\n",
    "        raise Exception(\"expected ']'\")\n",
    "    v = np.array([*map(lambda x: np.double(x.strip()), text[1:-1].split(','))])\n",
    "    return v.reshape((v.size,1))\n",
    "    #return v\n",
    "    \n",
    "def balanced_split(text):\n",
    "    i = 0\n",
    "    bal = 0\n",
    "    start = 0\n",
    "    result = []\n",
    "    while i < len(text):\n",
    "        if text[i] == '[':\n",
    "            bal += 1\n",
    "        elif text[i] == ']':\n",
    "            bal -= 1\n",
    "        elif text[i] == ',' and bal == 0:\n",
    "            result.append(text[start:i])\n",
    "            start = i+1\n",
    "        i += 1\n",
    "    if start < i:\n",
    "        result.append(text[start:i])\n",
    "    return result\n",
    "\n",
    "def parse_matrix(text):\n",
    "    i = 0\n",
    "    if len(text) < 1 or text[0] != '[':\n",
    "        raise Exception(\"expected '['\")\n",
    "    if text[-1] != ']':\n",
    "        raise Exception(\"expected ']'\")\n",
    "    return np.array([*map(lambda x: parse_vector(x.strip()).flatten(), balanced_split(text[1:-1]))])\n",
    "\n",
    "def parse_net(text):\n",
    "    lines = [*filter(lambda x: len(x) != 0, text.split('\\n'))]\n",
    "    i = 0\n",
    "    res = layers()\n",
    "    while i < len(lines):\n",
    "        if lines[i] in ['ReLU', 'Affine']:\n",
    "            W = parse_matrix(lines[i+1])\n",
    "            b = parse_bias(lines[i+2])\n",
    "            res.layertypes.append(lines[i])\n",
    "            res.weights.append(W)\n",
    "            res.biases.append(b)\n",
    "            res.numlayer+= 1\n",
    "            res.rank.append(np.zeros((W.shape[0],1)))\n",
    "            res.use_LP.append(np.full((W.shape[0],1), False))\n",
    "            res.LB_hat.append(np.full((W.shape[0],1), np.nan))\n",
    "            res.UB_hat.append(np.full((W.shape[0],1), np.nan))\n",
    "            i += 3\n",
    "        else:\n",
    "            raise Exception('parse error: '+lines[i])\n",
    "    return res\n",
    "\n",
    "def parse_spec(text):\n",
    "    text = text.replace(\"[\", \"\")\n",
    "    text = text.replace(\"]\", \"\")\n",
    "    with open('dummy', 'w') as my_file:\n",
    "        my_file.write(text)\n",
    "    data = np.genfromtxt('dummy', delimiter=',',dtype=np.double)\n",
    "    low = copy.deepcopy(data[:,0])\n",
    "    high = copy.deepcopy(data[:,1])\n",
    "    return low,high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perturbed_image(x, epsilon):\n",
    "    image = x[1:len(x)]\n",
    "    num_pixels = len(image)\n",
    "    LB_N0 = image - epsilon\n",
    "    UB_N0 = image + epsilon\n",
    "     \n",
    "    for i in range(num_pixels):\n",
    "        if(LB_N0[i] < 0):\n",
    "            LB_N0[i] = 0\n",
    "        if(UB_N0[i] > 1):\n",
    "            UB_N0[i] = 1\n",
    "    return LB_N0, UB_N0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_linexpr0(weights, bias, size):\n",
    "    linexpr0 = elina_linexpr0_alloc(ElinaLinexprDiscr.ELINA_LINEXPR_DENSE, size)\n",
    "    cst = pointer(linexpr0.contents.cst)\n",
    "    elina_scalar_set_double(cst.contents.val.scalar, bias)\n",
    "    for i in range(size):\n",
    "        elina_linexpr0_set_coeff_scalar_double(linexpr0,i,weights[i])\n",
    "    return linexpr0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(nn, LB_N0, UB_N0, label):   \n",
    "    num_pixels = len(LB_N0)\n",
    "    nn.ffn_counter = 0\n",
    "    numlayer = nn.numlayer \n",
    "    man = elina_box_manager_alloc()\n",
    "    itv = elina_interval_array_alloc(num_pixels)\n",
    "    for i in range(num_pixels):\n",
    "        elina_interval_set_double(itv[i],LB_N0[i],UB_N0[i])\n",
    "\n",
    "    ## construct input abstraction\n",
    "    element = elina_abstract0_of_box(man, 0, num_pixels, itv)\n",
    "    elina_interval_array_free(itv,num_pixels)\n",
    "    for layerno in range(numlayer):\n",
    "        if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "           weights = nn.weights[nn.ffn_counter]\n",
    "           biases = nn.biases[nn.ffn_counter]\n",
    "           dims = elina_abstract0_dimension(man,element)\n",
    "           num_in_pixels = dims.intdim + dims.realdim\n",
    "           num_out_pixels = len(weights)\n",
    "\n",
    "           dimadd = elina_dimchange_alloc(0,num_out_pixels)    \n",
    "           for i in range(num_out_pixels):\n",
    "               dimadd.contents.dim[i] = num_in_pixels\n",
    "           elina_abstract0_add_dimensions(man, True, element, dimadd, False)\n",
    "           elina_dimchange_free(dimadd)\n",
    "           np.ascontiguousarray(weights, dtype=np.double)\n",
    "           np.ascontiguousarray(biases, dtype=np.double)\n",
    "           var = num_in_pixels\n",
    "           # handle affine layer\n",
    "           for i in range(num_out_pixels):\n",
    "               tdim= ElinaDim(var)\n",
    "               linexpr0 = generate_linexpr0(weights[i],biases[i],num_in_pixels)\n",
    "               element = elina_abstract0_assign_linexpr_array(man, True, element, tdim, linexpr0, 1, None)\n",
    "               var+=1\n",
    "           dimrem = elina_dimchange_alloc(0,num_in_pixels)\n",
    "           for i in range(num_in_pixels):\n",
    "               dimrem.contents.dim[i] = i\n",
    "           elina_abstract0_remove_dimensions(man, True, element, dimrem)\n",
    "           elina_dimchange_free(dimrem)\n",
    "           # handle ReLU layer \n",
    "           if(nn.layertypes[layerno]=='ReLU'):\n",
    "              element = relu_box_layerwise(man,True,element,0, num_out_pixels)\n",
    "           nn.ffn_counter+=1 \n",
    "\n",
    "        else:\n",
    "           print(' net type not supported')\n",
    "   \n",
    "    dims = elina_abstract0_dimension(man,element)\n",
    "    output_size = dims.intdim + dims.realdim\n",
    "    # get bounds for each output neuron\n",
    "    bounds = elina_abstract0_to_box(man,element)\n",
    "\n",
    "           \n",
    "    # if epsilon is zero, try to classify else verify robustness \n",
    "    \n",
    "    verified_flag = True\n",
    "    predicted_label = 0\n",
    "    if(LB_N0[0]==UB_N0[0]):\n",
    "        for i in range(output_size):\n",
    "            inf = bounds[i].contents.inf.contents.val.dbl\n",
    "            flag = True\n",
    "            for j in range(output_size):\n",
    "                if(j!=i):\n",
    "                   sup = bounds[j].contents.sup.contents.val.dbl\n",
    "                   if(inf<=sup):\n",
    "                      flag = False\n",
    "                      break\n",
    "            if(flag):\n",
    "                predicted_label = i\n",
    "                break    \n",
    "    else:\n",
    "        inf = bounds[label].contents.inf.contents.val.dbl\n",
    "        for j in range(output_size):\n",
    "            if(j!=label):\n",
    "                sup = bounds[j].contents.sup.contents.val.dbl\n",
    "                if(inf<=sup):\n",
    "                    predicted_label = label\n",
    "                    verified_flag = False\n",
    "                    break\n",
    "\n",
    "    elina_interval_array_free(bounds,output_size)\n",
    "    elina_abstract0_free(man,element)\n",
    "    elina_manager_free(man)        \n",
    "    return predicted_label, verified_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define operations on abstract domain using linear approximations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hidden_constraint(model, layerno, z, z_hat, weights, biases):\n",
    "    \"\"\"\n",
    "    This function computes “which side” of the ReLU the pre-ReLU activations lies on.\n",
    "    INPUT:\n",
    "        - model: gurobi model\n",
    "        - layerno: layer number from which z_hat belong\n",
    "        - z: gurobi variables for hidden layer input\n",
    "        - z_hat: gurobi variables for hidden layer output\n",
    "        - weights: weights for the hidden layer\n",
    "        - bias: bias in the hidden layer\n",
    "    OUTPUT:\n",
    "        - model: gurobi model with new hidden constrains\n",
    "   \"\"\"\n",
    "    # Sanity check!\n",
    "    assert len(z) == weights.shape[1]\n",
    "    assert len(z_hat) == weights.shape[0]\n",
    "    \n",
    "    # add constraint to model\n",
    "    for i_out in range(len(z_hat)):\n",
    "        constr = LinExpr() + np.asscalar(biases[i_out])\n",
    "        for s in range(len(z)):\n",
    "            constr += z[s] * np.asscalar(weights[i_out, s])\n",
    "\n",
    "        model.addConstr(z_hat[i_out] == constr, \\\n",
    "                    name=\"hidden_constr_\" + str(layerno) + \"_\" + str(i_out))\n",
    "    \n",
    "    model.update()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_relu_activation_constraint(model, layerno, z_hat, z, LB, UB):\n",
    "    \"\"\"\n",
    "    This function computes “which side” of the ReLU the pre-ReLU activations lies on.\n",
    "    INPUT:\n",
    "        - model: gurobi model\n",
    "        - layerno: layer number from which z_hat belong\n",
    "        - z_hat: gurobi variables for pre-relu input\n",
    "        - z: gurobi variables for relu output\n",
    "        - LB: lower bound of inputs to a relu layer\n",
    "        - UB: upper bound of inputs to a relu layer\n",
    "    OUTPUT:\n",
    "        - model: gurobi model with new ReLU constrains\n",
    "   \"\"\"\n",
    "    # Sanity check!\n",
    "    assert len(z) == len(UB)\n",
    "    \n",
    "    # iterate over each pre-relu neuron activation\n",
    "    for j in range(len(UB)):\n",
    "        u = np.asscalar(UB[j])\n",
    "        l = np.asscalar(LB[j])\n",
    "\n",
    "        if u <= 0:\n",
    "            model.addConstr(z[j] == 0, \\\n",
    "                        name=\"relu_constr_deac_\" + str(layerno) + \"_\" + str(j))\n",
    "        elif l > 0:\n",
    "            model.addConstr(z[j] == z_hat[j], \\\n",
    "                        name=\"relu_constr_deac_\" + str(layerno) + \"_\" + str(j))\n",
    "        else:\n",
    "            alpha = u/(u - l)\n",
    "            model.addConstr(z[j] >= 0 , \\\n",
    "                         name=\"relu_const_ambi_pos_\" + str(layerno) + \"_\" + str(j))\n",
    "            model.addConstr(z[j] >= z_hat[j], \\\n",
    "                         name=\"relu_const_ambi_hid_\" + str(layerno) + \"_\" + str(j))\n",
    "            model.addConstr(z[j] <= alpha * (z_hat[j] - l), \\\n",
    "                         name=\"relu_const_ambi_lin_\" + str(layerno) + \"_\" + str(j))\n",
    "    model.update()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_linear_solver(model, z_hat, lb_only=False, ub_only=False):\n",
    "    \"\"\"\n",
    "    This function computes lower and upper bound for given objective function and model\n",
    "    INPUT:\n",
    "        - model: gurobi model\n",
    "        - z_hat: gurobi variable to optimize for\n",
    "    OUTPUT:\n",
    "        - LB: lower bound of variable\n",
    "        - UB: upper bound of variable\n",
    "   \"\"\"\n",
    "    # Sanity\n",
    "    assert not lb_only*ub_only\n",
    "    LB, UB = None, None\n",
    "    \n",
    "    if not ub_only:\n",
    "        # Find Lower Bound\n",
    "        model.setObjective(z_hat, GRB.MINIMIZE)\n",
    "        model.update()\n",
    "        model.optimize()\n",
    "\n",
    "        if model.status == GRB.Status.OPTIMAL:\n",
    "            LB = model.objVal\n",
    "        else:\n",
    "            raise(RuntimeError('[Min] Error. Not Able to retrieve bound. Gurobi Model. Not Optimal.'))\n",
    "\n",
    "        # reset model \n",
    "        model.reset()\n",
    "    \n",
    "    if not lb_only:\n",
    "        # Find Upper Bound\n",
    "        model.setObjective(z_hat, GRB.MAXIMIZE)\n",
    "        model.update()\n",
    "        model.optimize()\n",
    "\n",
    "        if model.status == GRB.Status.OPTIMAL:\n",
    "            UB = model.objVal\n",
    "        else:\n",
    "            raise(RuntimeError('[Max] Error. Not Able to retrieve bound. Gurobi Model. Not Optimal.'))\n",
    "\n",
    "        # reset model \n",
    "        model.reset()\n",
    "    \n",
    "    return LB, UB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define operations on abstract domain using Box approximations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relu_bounds_using_box(man, input_LB, input_UB, num_in_pixels):\n",
    "    '''\n",
    "    This function calculates the bounds of a ReLU operation. \n",
    "    INPUT:\n",
    "        - man: pointer to elina manager\n",
    "        - input_LB: lower bound of the inputs to the ReLU\n",
    "        - input_UB: upper bound of the inputs to the ReLU\n",
    "        - num_in_pixels: number of inputs to ReLU\n",
    "    \n",
    "    OUTPUT:\n",
    "        - output_LB: lower bound of the outputs from ReLU layer\n",
    "        - output_UB: upper bound of the outputs from ReLU layer\n",
    "        - num_out_pixels: number of outputs of ReLI layer\n",
    "    '''\n",
    "    itv = elina_interval_array_alloc(num_in_pixels)\n",
    "\n",
    "    ## Populate the interval\n",
    "    for i in range(num_in_pixels):\n",
    "        elina_interval_set_double(itv[i], input_LB[i], input_UB[i])\n",
    "\n",
    "    ## construct input abstraction\n",
    "    element = elina_abstract0_of_box(man, 0, num_in_pixels, itv)\n",
    "    elina_interval_array_free(itv, num_in_pixels)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Handle ReLU Layer\n",
    "    # ------------------------------------------------------------------\n",
    "    num_out_pixels = num_in_pixels\n",
    "    \n",
    "    element = relu_box_layerwise(man, True, element,0, num_in_pixels)\n",
    "    \n",
    "    # get bounds for each output neuron\n",
    "    bounds = elina_abstract0_to_box(man,element)\n",
    "    \n",
    "    # get bounds for each output neuron\n",
    "    bounds = elina_abstract0_to_box(man,element)\n",
    "    \n",
    "    output_LB = np.zeros((num_out_pixels, 1), float)\n",
    "    output_UB = np.zeros((num_out_pixels, 1), float)\n",
    "    for j in range(num_out_pixels):\n",
    "        output_LB[j] = bounds[j].contents.inf.contents.val.dbl\n",
    "        output_UB[j] = bounds[j].contents.sup.contents.val.dbl\n",
    "    \n",
    "    # free out the memory allocations\n",
    "    elina_interval_array_free(bounds, num_out_pixels)\n",
    "    elina_abstract0_free(man, element)\n",
    "    \n",
    "    return output_LB, output_UB, num_out_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_bounds_using_box(man, weights, biases, input_LB, input_UB, num_in_pixels, verbose=False):\n",
    "    '''\n",
    "    This function calculates the bounds of a ReLU operation followed by a hidden layer. \n",
    "    INPUT:\n",
    "        - man: pointer to elina manager\n",
    "        - weights: weights of the hidden layer\n",
    "        - biases: biases of the hidden layer\n",
    "        - input_LB: lower bound of the inputs to the hidden layer\n",
    "        - input_UB: upper bound of the inputs to the hidden layer\n",
    "        - num_in_pixels: number of inputs to the input layer\n",
    "    \n",
    "    OUTPUT:\n",
    "        - output_LB: lower bound of the outputs from hidden layer\n",
    "        - output_UB: upper bound of the outputs from hidden layer\n",
    "        - num_out_pixels: number of outputs of hidden layer\n",
    "    '''\n",
    "    itv = elina_interval_array_alloc(num_in_pixels)\n",
    "\n",
    "    ## Populate the interval\n",
    "    for i in range(num_in_pixels):\n",
    "        elina_interval_set_double(itv[i], input_LB[i], input_UB[i])\n",
    "\n",
    "    ## construct input abstraction\n",
    "    element = elina_abstract0_of_box(man, 0, num_in_pixels, itv)\n",
    "    elina_interval_array_free(itv, num_in_pixels)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Handle Affine Layer\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    # calculate number of outputs\n",
    "    num_out_pixels = len(weights)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"[Network] Input pixels: \" + str(num_in_pixels))\n",
    "        print(\"[Network] Shape of weights: \" + str(np.shape(weights)))\n",
    "        print(\"[Network] Shape of biases: \" + str(np.shape(biases)))\n",
    "        print(\"[Network] Out pixels: \" + str(num_out_pixels))\n",
    "\n",
    "    # Create number of neurons in the layer and populate it\n",
    "    # with the number of inputs to each neuron in the layer\n",
    "    dimadd = elina_dimchange_alloc(0, num_out_pixels)    \n",
    "    for i in range(num_out_pixels):\n",
    "        dimadd.contents.dim[i] = num_in_pixels\n",
    "\n",
    "    # Add dimensions to an ElinaAbstract0 pointer i.e. element\n",
    "    elina_abstract0_add_dimensions(man, True, element, dimadd, False)\n",
    "    elina_dimchange_free(dimadd)\n",
    "\n",
    "    # Create the linear expression associated each neuron\n",
    "    var = num_in_pixels\n",
    "    for i in range(num_out_pixels):\n",
    "        tdim = ElinaDim(var)\n",
    "        linexpr0 = generate_linexpr0(weights[i], biases[i], num_in_pixels)\n",
    "        # Parallel assignment of several dimensions of an ElinaAbstract0 by using an ElinaLinexpr0Array\n",
    "        element = elina_abstract0_assign_linexpr_array(man, True, element, tdim, linexpr0, 1, None)\n",
    "        var += 1\n",
    "\n",
    "    # Pointer to which semantics we want to follow.\n",
    "    dimrem = elina_dimchange_alloc(0, num_in_pixels)\n",
    "    for i in range(num_in_pixels):\n",
    "        dimrem.contents.dim[i] = i\n",
    "        \n",
    "    # Remove dimensions from an ElinaAbstract0\n",
    "    elina_abstract0_remove_dimensions(man, True, element, dimrem)\n",
    "    elina_dimchange_free(dimrem)\n",
    "    \n",
    "    # get bounds for each output neuron\n",
    "    bounds = elina_abstract0_to_box(man,element)\n",
    "    \n",
    "    output_LB = np.zeros((num_out_pixels, 1), float)\n",
    "    output_UB = np.zeros((num_out_pixels, 1), float)\n",
    "    for j in range(num_out_pixels):\n",
    "        output_LB[j] = bounds[j].contents.inf.contents.val.dbl\n",
    "        output_UB[j] = bounds[j].contents.sup.contents.val.dbl    \n",
    "    \n",
    "    # free out the memory allocations\n",
    "    elina_interval_array_free(bounds, num_out_pixels)\n",
    "    elina_abstract0_free(man, element)\n",
    "    \n",
    "    return output_LB, output_UB, num_out_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function to verify the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_network(LB_N0, UB_N0, LB_NN, UB_NN, label, num_input_pixels = 784, num_out_pixels = 10, verbose=False):\n",
    "    '''\n",
    "    This function verifies the network given the bounds of the input layer and the final layer of the network.\n",
    "    INPUT:\n",
    "        - LB_N0: lower bounds of the preturbed input image\n",
    "        - UB_N0: unpper bounds of the preturbed input image\n",
    "        - LB_NN: lower bounds of the final layer of neural network\n",
    "        - UB_NN: upper bounds of the final layer of neural network\n",
    "        - label: true label of the input image\n",
    "        - num_input_pixels: number of pixels in the input image (for MNIST, default: 784)\n",
    "        - num_out_pixels: number of neurons in the last layer of the network  (for MNIST, default: 10)\n",
    "    \n",
    "    OUTPUT:\n",
    "        - predicted_label: label predicted by the neural network\n",
    "        - verified_flag: boolean variable, true if the network is robust to perturbation\n",
    "    '''\n",
    "    \n",
    "    # if epsilon is zero, try to classify else verify robustness \n",
    "    verified_flag = True\n",
    "    predicted_label = 0\n",
    "    if(LB_N0[0]==UB_N0[0]):\n",
    "        for i in range(num_out_pixels):\n",
    "            inf = LB_NN[i]\n",
    "            flag = True\n",
    "            for j in range(num_out_pixels):\n",
    "                if(j!=i):\n",
    "                    sup = UB_NN[j]\n",
    "                    if(inf<=sup):\n",
    "                        flag = False\n",
    "                        break\n",
    "            if(flag):\n",
    "                predicted_label = i\n",
    "                break    \n",
    "    else:\n",
    "        inf = LB_NN[label]\n",
    "        for j in range(num_out_pixels):\n",
    "            if(j!=label):\n",
    "                sup = UB_NN[j]\n",
    "                if(inf<=sup):\n",
    "                    predicted_label = label\n",
    "                    verified_flag = False\n",
    "                    break\n",
    "    \n",
    "    if verbose:\n",
    "        if(verified_flag):\n",
    "            print(\"verified\")\n",
    "        else:\n",
    "            print(\"can not be verified\")  \n",
    "        \n",
    "    return predicted_label, verified_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to perform different analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform box analysis for all layers in the neural network nn\n",
    "def perform_box_analysis(nn, LB_N0, UB_N0, verbose = False):\n",
    "    # create a list to store the bounds found through box approximation\n",
    "    LB_hidden_box_list = []\n",
    "    UB_hidden_box_list = []\n",
    "\n",
    "    # create manager for Elina\n",
    "    man = elina_box_manager_alloc()\n",
    "\n",
    "    # initialize variables for the network iteration\n",
    "    numlayer = nn.numlayer \n",
    "    nn.ffn_counter = 0\n",
    "\n",
    "    # for input image\n",
    "    input_LB = LB_N0.copy()\n",
    "    input_UB = UB_N0.copy()\n",
    "    num_in_pixels = len(LB_N0)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Input Layer, size: \" + str(len(LB_N0)))\n",
    "        print('---------------')\n",
    "\n",
    "    for layerno in range(numlayer):\n",
    "        if verbose:\n",
    "            print(\"Layer Number: \" + str(layerno + 1))\n",
    "\n",
    "        if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "            if verbose:\n",
    "                print(\"Layer Type: %s\" % nn.layertypes[layerno])\n",
    "\n",
    "            # read the layer weights and biases\n",
    "            weights = nn.weights[nn.ffn_counter]\n",
    "            biases = nn.biases[nn.ffn_counter]\n",
    "            np.ascontiguousarray(weights, dtype=np.double)\n",
    "            np.ascontiguousarray(biases, dtype=np.double)\n",
    "\n",
    "            # ------------------------------------------------------------------\n",
    "            # Handle Affine Layer\n",
    "            # ------------------------------------------------------------------\n",
    "            output_LB, output_UB, num_out_pixels = get_hidden_bounds_using_box(man, weights, biases, input_LB, input_UB, num_in_pixels, verbose)\n",
    "\n",
    "            # Add bounds to the list\n",
    "            LB_hidden_box_list.append(output_LB.copy())\n",
    "            UB_hidden_box_list.append(output_UB.copy())\n",
    "            # Prepare variables for next layer\n",
    "            input_LB = output_LB.copy()\n",
    "            input_UB = output_UB.copy()\n",
    "            num_in_pixels = num_out_pixels\n",
    "            nn.ffn_counter += 1 \n",
    "\n",
    "            # ------------------------------------------------------------------\n",
    "            # Handle ReLU Layer\n",
    "            # ------------------------------------------------------------------\n",
    "            if(nn.layertypes[layerno] == \"ReLU\"):\n",
    "                output_LB, output_UB, num_out_pixels = get_relu_bounds_using_box(man, input_LB, input_UB, num_in_pixels)\n",
    "\n",
    "            # Prepare variables for next layer\n",
    "            input_LB = output_LB.copy()\n",
    "            input_UB = output_UB.copy()\n",
    "\n",
    "            if verbose:\n",
    "                print(\"[OUTPUT] Bounds: \")\n",
    "                output_LB, output_UB  = output_LB.squeeze(), output_UB.squeeze()\n",
    "                pprint(np.stack((output_LB, output_UB), axis=1))\n",
    "            \n",
    "            if verbose:\n",
    "                print('---------------')\n",
    "\n",
    "        else:\n",
    "            print(' net type not supported')\n",
    "    if verbose:\n",
    "        print(\"Output Layer, size: \" + str(len(output_LB)))\n",
    "\n",
    "    elina_manager_free(man)\n",
    "    \n",
    "    # for last layer of the netowork is ReLU\n",
    "    LB_NN = LB_hidden_box_list[-1].copy()\n",
    "    UB_NN = UB_hidden_box_list[-1].copy()\n",
    "\n",
    "    if nn.layertypes[-1] == \"ReLU\" :\n",
    "        num_out = len(LB_hidden_box_list[-1])\n",
    "        for i in range(num_out):\n",
    "            if LB_hidden_box_list[-1][i] < 0 :\n",
    "                LB_NN[i] = 0 \n",
    "            if UB_hidden_box_list[-1][i] < 0 :\n",
    "                UB_NN[i] = 0 \n",
    "            \n",
    "    return LB_hidden_box_list, UB_hidden_box_list, LB_NN.squeeze(), UB_NN.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(single_thread=False):\n",
    "    \"\"\"\n",
    "    Get Gurobi model\n",
    "    \"\"\"\n",
    "    m = Model(\"LP\")\n",
    "    m.setParam(\"outputflag\", False)\n",
    "\n",
    "    # disable parallel Gurobi solver\n",
    "    m.setParam(\"Method\", 1)  # dual simplex\n",
    "    if single_thread:\n",
    "        m.setParam(\"Threads\", 1) # only 1 thread\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_all_vars(m, numlayer, LB_N0, UB_N0, UB_hidden_box_list, verbose=False):\n",
    "    \"\"\"\n",
    "    Add and create all variables of neural network to gurobi model.\n",
    "    INPUT:\n",
    "        - m: Gurobi model\n",
    "        - numlayer: Number of Layers\n",
    "        - LB_N0: Lower Bound of perturbed image input\n",
    "        - UB_N0: Upper Bound of perturbed image input\n",
    "        - UB_hidden_box_list: List of upper Bounds from box approximation (needed to set upper bound of ReLU outputs)\n",
    "    OUTPUT:\n",
    "        - m: Gurobi model with newly added variables\n",
    "        - z: List of Gurobi variables corresponding to pre-ReLU Layer (hidden)\n",
    "        - z_hat: List of Gurobi variables corresponding to post-ReLU Layer\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # for output of each ReLU\n",
    "    z = []\n",
    "    # for output of each hidden layer\n",
    "    z_hat = []\n",
    "    \n",
    "    # Create variables of input image\n",
    "    num_in_pixels = len(LB_N0)\n",
    "    img_vars = m.addVars(num_in_pixels, lb=LB_N0, ub=UB_N0, \\\n",
    "                 vtype=GRB.CONTINUOUS, name=\"input_layer\")\n",
    "    z.append(img_vars)\n",
    "    \n",
    "    # Create variables for all layers and append to the list \n",
    "    for i in range(numlayer):\n",
    "        # for layers before the final layer, z_hat and z exists\n",
    "        if i < (numlayer - 1):\n",
    "\n",
    "            UB_relu = UB_hidden_box_list[i].squeeze().copy()\n",
    "            for j in range(len(UB_hidden_box_list[i])):\n",
    "                bound = UB_hidden_box_list[i][j]\n",
    "                UB_relu[j] = max(0, bound)\n",
    "            UB_relu.squeeze() \n",
    "\n",
    "            # middle layer, has both z and z hat\n",
    "            z_hat_hidden = m.addVars(len(UB_hidden_box_list[i]), lb=-np.inf, ub=np.inf, \\\n",
    "                                     vtype=GRB.CONTINUOUS, name=\"hidden_layer_\" + str(i))\n",
    "            z_relu = m.addVars(len(UB_hidden_box_list[i]), lb=0.0, ub = UB_relu,\\\n",
    "                               vtype=GRB.CONTINUOUS, name=\"relu_layer_\" + str(i))\n",
    "            # append to the list\n",
    "            z_hat.append(z_hat_hidden)\n",
    "            z.append(z_relu)\n",
    "        # for last layer, only z_hat exists\n",
    "        else: \n",
    "            z_hat_hidden = m.addVars(len(UB_hidden_box_list[i]), lb=-np.inf, ub=np.inf, \\\n",
    "                                     vtype=GRB.CONTINUOUS, name=\"output_layer\") \n",
    "            # append to the list\n",
    "            z_hat.append(z_hat_hidden)\n",
    "\n",
    "    m.update()\n",
    "    \n",
    "    if verbose:\n",
    "        # Sanity check!\n",
    "        # Size of z should be number of relu activation layers + 1 (for input)\n",
    "        print(\"Number of relu layers: {0}\".format(len(z)))\n",
    "        # Size of z_hat should be number of hidden layers\n",
    "        print(\"Number of hidden layers: {0}\".format(len(z_hat)))\n",
    "        print(\"Size of last hidden layer: {0}\".format(len(z_hat[-1])))\n",
    "    \n",
    "    return m, z, z_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_linear_layerwise(nn, numlayer, LB_N0, UB_N0, lp_list, LB_hidden_box_list, UB_hidden_box_list, \n",
    "                             true_label, influence_threshold=[1.0, 0.0] ,verbose=True, save_stats=False):\n",
    "    \"\"\"\n",
    "    Get final bounds using linear programming layerwise. If lp_freq > 1 linear bounds are only calculated every \n",
    "    lp_freq'th layer.\n",
    "    INPUT:\n",
    "        - m: Gurobi model\n",
    "        - z: List of Gurobi variables corresponding to pre-ReLU Layer (hidden)\n",
    "        - z_hat: List of Gurobi variables corresponding to post-ReLU Laye\n",
    "        - nn: Neural Network as defined in initial code (contains layertypes, weights, etc.)\n",
    "        - numlayer: Number of Layers\n",
    "        - LB_N0: Lower Bound of perturbed image input\n",
    "        - UB_N0: Upper Bound of perturbed image input\n",
    "        - lp_list: Layerno for which to do mainly Linear programming\n",
    "        - LB_hidden_box_list: List of upper Bounds from box approximation\n",
    "        - UB_hidden_box_list: List of upper Bounds from box approximation\n",
    "        - influence_threshold: List of influence threshold where LP is used. First element corresponds \n",
    "                                 to threshold of layers in lp_list, second element to all other layers.\n",
    "                                 Therefore, if a given layer is in lp_list, use LP if rank of Neuron is below \n",
    "                                 influence_threshold[0], default is use LP on ALL neurons of lp_list layer.\n",
    "                                 If layer is not in lp_list, use LP if rank of Neuron is below \n",
    "                                 influence_threshold[1], default do NOT use LP on neurons.\n",
    "                                 \n",
    "    OUTPUT:\n",
    "        - LB_NN: Lower bounds of neural network output\n",
    "        - UB_NN: Upper bounds of neural network output\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sanity check\n",
    "    assert LB_hidden_box_list is not None \n",
    "    assert UB_hidden_box_list is not None\n",
    "    assert all( v <=1.0 or v>=0 for v in influence_threshold)\n",
    "\n",
    "    # create manager for Elina\n",
    "    man = elina_box_manager_alloc()\n",
    "    \n",
    "    # create gurobi model\n",
    "    m = get_model()\n",
    "    \n",
    "    # create all gurobi variables for the network\n",
    "    m, z, z_hat = add_all_vars(m, numlayer, LB_N0, UB_N0, UB_hidden_box_list)\n",
    "    \n",
    "    # initialize counter\n",
    "    nn.ffn_counter = 0\n",
    "    \n",
    "    # Init statistics\n",
    "    stats = {'time': [],\n",
    "        'LB_hat': [],\n",
    "        'UB_hat': [],\n",
    "        'use_LP': [],\n",
    "        'margin': [],\n",
    "        'margin_per_neuron': [],\n",
    "        'margin_per_time': [],\n",
    "        'tightness_hat': [],\n",
    "        'min_tightness_hat': [],\n",
    "        'max_tightness_hat': [],\n",
    "        'median_tightness_hat': [],\n",
    "        }\n",
    "\n",
    "    # Adding weights constraints for k layers\n",
    "    for layerno in range(numlayer):\n",
    "        if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "            t1 = time.time()\n",
    "                        \n",
    "            # read the layer weights and biases\n",
    "            weights = nn.weights[nn.ffn_counter]\n",
    "            biases = nn.biases[nn.ffn_counter]\n",
    "            np.ascontiguousarray(weights, dtype=np.float)\n",
    "            np.ascontiguousarray(biases, dtype=np.float)\n",
    "\n",
    "            # output shape of the layer\n",
    "            n_in = weights.shape[1]\n",
    "            n_out = weights.shape[0]\n",
    "\n",
    "            # create variables to store bounds of hidden layer\n",
    "            LB_hat = np.zeros(n_out, float)\n",
    "            UB_hat = np.zeros(n_out, float)\n",
    "\n",
    "            # add affine constraint\n",
    "            add_hidden_constraint(m, layerno, z[layerno], z_hat[layerno], weights, biases)\n",
    "            \n",
    "            ##########################################\n",
    "            # First layer: Use original BOX bounds   #\n",
    "            ##########################################\n",
    "            if layerno < lp_list[0] or layerno == 0:\n",
    "                use_LP = np.zeros(n_out, dtype=np.bool)\n",
    "                LB_hat, UB_hat = LB_hidden_box_list[layerno].copy() , UB_hidden_box_list[layerno].copy()\n",
    "            \n",
    "            #########################################\n",
    "            # Last Layer: Use Linear Programming    #\n",
    "            #########################################\n",
    "            elif layerno == numlayer - 1:\n",
    "                use_LP = np.ones(n_out, dtype=np.bool)\n",
    "                \n",
    "                # LB: Get lower bound of correct label\n",
    "                LB_hat[true_label], _ = call_linear_solver(m, z_hat[layerno][true_label], lb_only=True)\n",
    "                \n",
    "                # UB: Get upper bound of all other labels    \n",
    "                for i_out in range(n_out):\n",
    "                    if i_out == true_label:\n",
    "                        continue\n",
    "                        \n",
    "                    _, UB_hat[i_out] = call_linear_solver(m, z_hat[layerno][i_out], ub_only=True)\n",
    "                \n",
    "            ######################################################\n",
    "            # All layers inbetween: Decide if we use LP or BOX   #\n",
    "            ######################################################\n",
    "            else:\n",
    "                \n",
    "                # Calculate box to get tigthness\n",
    "                LB, UB, n_out = get_relu_bounds_using_box(man, LB_hat_prev, UB_hat_prev, n_in)\n",
    "                LB_hat, UB_hat, n_out = get_hidden_bounds_using_box(man, weights, biases, \n",
    "                                                                LB, UB, n_out, verbose)\n",
    "                \n",
    "                # Check if Relu will be activated\n",
    "                relu_inactive = UB_hat < 0\n",
    "                relu_inactive = relu_inactive.squeeze()\n",
    "            \n",
    "                # Get Rank of box bound tigthness\n",
    "                tightness_box = UB_hat.squeeze() - LB_hat.squeeze()\n",
    "                tightness_box[relu_inactive] = 0\n",
    "                temp = np.argsort(-tightness_box, axis=0)\n",
    "                tightness_box_rank = np.empty_like(temp)\n",
    "                tightness_box_rank[temp] = np.arange(len(temp))\n",
    "                tightness_box_rank = tightness_box_rank/n_out\n",
    "                \n",
    "                # Get the norm of the weight to determine how important a neuron is.\n",
    "                norm = 1\n",
    "                w = nn.weights[layerno+1]\n",
    "                norms = np.linalg.norm(w, ord=norm, axis=0)\n",
    "                norms[relu_inactive] = 0\n",
    "                \n",
    "                # Rank the influence of the neurons\n",
    "                influence = norms * tightness_box\n",
    "                temp = np.argsort(-influence, axis=0)\n",
    "                influence_rank = np.empty_like(temp)\n",
    "                influence_rank[temp] = np.arange(len(temp))\n",
    "                influence_rank = influence_rank/n_out\n",
    "                \n",
    "                # LP\n",
    "                # If the layer is in the list of layer use LP on ALL neurons\n",
    "                if (layerno in lp_list):\n",
    "                    # Use LP if the influence_rank is below the specified threshold.\n",
    "                    use_LP = (influence_rank < influence_threshold[0])\n",
    "                    \n",
    "                # LP\n",
    "                # If the layer is NOT in list of layer use LP only on high ranking neurons\n",
    "                else:\n",
    "                    # Use LP if the influence_rank is below the specified threshold.\n",
    "                    use_LP = (influence_rank < influence_threshold[1])\n",
    "                \n",
    "                for i_out in range(n_out):\n",
    "                    if use_LP[i_out]:\n",
    "                        LB_hat[i_out], UB_hat[i_out] = call_linear_solver(m, z_hat[layerno][i_out]) \n",
    "            \n",
    "            # Add relu constraint to gurobi model\n",
    "            if layerno < (numlayer - 1) and nn.layertypes[layerno] in [\"ReLU\"]:\n",
    "                add_relu_activation_constraint(m, layerno, z_hat[layerno], z[layerno + 1], LB_hat, UB_hat)\n",
    "            \n",
    "            # preparation for next iteration    \n",
    "            LB_hat_prev, UB_hat_prev = LB_hat.copy(), UB_hat.copy()\n",
    "                \n",
    "            m.update()\n",
    "\n",
    "            # update counter for next iteration\n",
    "            nn.ffn_counter += 1\n",
    "            # Save where we used LP\n",
    "            nn.use_LP[layerno] = use_LP\n",
    "            nn.LB_hat[layerno] = LB_hat\n",
    "            nn.UB_hat[layerno] = UB_hat\n",
    "            \n",
    "            # Save stats\n",
    "            t2 = time.time()\n",
    "            \n",
    "            if save_stats:\n",
    "                stats['time'].append(t2 - t1)\n",
    "                stats['LB_hat'].append(LB_hat.squeeze())\n",
    "                stats['UB_hat'].append(UB_hat.squeeze())\n",
    "                stats['use_LP'].append(use_LP)\n",
    "                tightness = stats['UB_hat'][-1] - stats['LB_hat'][-1]\n",
    "                stats['tightness_hat'].append(tightness)\n",
    "                stats['median_tightness_hat'].append(np.median(tightness))\n",
    "                stats['min_tightness_hat'].append(min(tightness))\n",
    "                stats['max_tightness_hat'].append(max(tightness))\n",
    "\n",
    "                if layerno == (numlayer - 1):\n",
    "                    stats['margin'].append(LB_hat[true_label] - max(UB_hat))\n",
    "                    n_use_lp = sum([sum(lp) for lp in stats['use_LP']])\n",
    "                    tot_time = sum(stats['time'])\n",
    "                    stats['margin_per_neuron'].append( stats['margin'][-1]/n_use_lp )\n",
    "                    stats['margin_per_time'].append(stats['margin'][-1]/tot_time)\n",
    "\n",
    "\n",
    "            \n",
    "            if verbose and save_stats:\n",
    "                decimals=2\n",
    "                print(\"--------------------------\")\n",
    "                print(\"Layerno: %d\" %layerno)\n",
    "                print(\"Time %3f\" % (t2 - t1))\n",
    "                if stats['use_LP'][-1].any():\n",
    "                    print(\"Time per LP neuron %3f\" % ((t2 - t1)/ sum(stats['use_LP'][-1])))\n",
    "                    print(\"LP used on %d neurons.\" % sum(stats['use_LP'][-1]))\n",
    "                print(\"Median tigthness of hat bounds: %3f \\n\" % stats['median_tightness_hat'][-1])\n",
    "                print(\"Min tigthness of hat bounds: %3f \\n\" % stats['min_tightness_hat'][-1])\n",
    "                print(\"Max tigthness of hat bounds: %3f \\n\" % stats['max_tightness_hat'][-1])\n",
    "                print(\"[LB_hat | UB_hat | use_LP]\")\n",
    "                pprint(np.stack([LB_hat.squeeze(), UB_hat.squeeze(), stats['use_LP'][-1]], axis = 1).round(decimals=decimals))\n",
    "                print(\"--------------------------\\n\")\n",
    "\n",
    "                if layerno == (numlayer - 1):\n",
    "                    print(\"----------SUMMARY-----------\\n\")\n",
    "                    print(\"Verification Margin (more positive better): %3f \\n\" % stats['margin'][-1])\n",
    "                    print(\"Margin per LP neuron (more positve is better): %6f\\n\" % stats['margin_per_neuron'][-1])\n",
    "                    print(\"Margin per second (more positve is better): %10f\\n\" % stats['margin_per_time'][-1])\n",
    "                    print(\"----------END SUMMARY--------\\n\")\n",
    "\n",
    "        else:\n",
    "            raise(\"Not a valid layer!\")\n",
    "    \n",
    "    # Set bounds of last performed layer to output\n",
    "    LB_NN = LB_hat\n",
    "    UB_NN = UB_hat\n",
    "    # If last Layer is RELU change last lower and upper bounds accordingly.\n",
    "    if nn.layertypes[-1] == \"ReLU\" :\n",
    "        num_out = len(UB_hat)\n",
    "        for i in range(num_out):\n",
    "            if LB_hat[i] < 0 :\n",
    "                LB_NN[i] = 0 \n",
    "            if UB_hat[i] < 0 :\n",
    "                UB_NN[i] = 0 \n",
    "           \n",
    "    return LB_NN, UB_NN, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nn(netname, specname, epsilon, verbose=False):\n",
    "    flag_wrong_label = False\n",
    "    \n",
    "    with open(netname, 'r') as netfile:\n",
    "        netstring = netfile.read()\n",
    "    with open(specname, 'r') as specfile:\n",
    "        specstring = specfile.read()\n",
    "    nn = parse_net(netstring)\n",
    "    x0_low, x0_high = parse_spec(specstring)\n",
    "    LB_N0, UB_N0 = get_perturbed_image(x0_low,0)\n",
    "    \n",
    "    label, _ = analyze(nn,LB_N0,UB_N0,0) # Get label of unperturbed image, i.e. eps=0\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"True label: \" + str(label))\n",
    "    if(label == int(x0_low[0])):\n",
    "        LB_N0, UB_N0 = get_perturbed_image(x0_low, epsilon)\n",
    "    else:\n",
    "        print(\"image not correctly classified by the network. expected label \",int(x0_low[0]), \" classified label: \", label)\n",
    "        flag_wrong_label =  True\n",
    "        \n",
    "    return LB_N0, UB_N0, nn, label, flag_wrong_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Testing Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_nn_and_write(net_code, img_nrs, epsilon, lp_list, log_file=None, verbose=True, write=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Analyse Neural Network and write the result to a log file. Code heuristic yourself in this function\n",
    "    INPUT:\n",
    "        - net_code: Neural Network code, e.g. mnist_relu_4_1024\n",
    "        - img_nrs: List of image nrs, e.g [0,1,2,3]\n",
    "        - epsilon: Perturbation\n",
    "        - log_file: File to write results\n",
    "    OUTPUT:\n",
    "        - verified_flag: Verification flag. True if network was verified against perturbation.\n",
    "    \"\"\"\n",
    "    nn_root_path = '/home/riai2018/mnist_nets'\n",
    "    img_root_path = '/home/riai2018/mnist_images'\n",
    "    log_root_path = '/home/riai2018/log'\n",
    "    log_base_name = 'log_'\n",
    "    verified_counter, true_label_counter = 0, 0\n",
    "    stamp = '_{:%Y-%m-%d_%H:%M:%S}'.format(datetime.now())\n",
    "    if not os.path.isdir(log_root_path):\n",
    "        os.makedirs(log_root_path)\n",
    "    net_path = os.path.join(nn_root_path, net_code + '.txt')\n",
    "    \n",
    "    if write:\n",
    "        if log_file is None:\n",
    "            log_file = os.path.join(log_root_path, log_base_name + net_code + '_epsilon_' + str(epsilon))\n",
    "            if kwargs is not None:\n",
    "                log_file = log_file + '_'  + str(kwargs) + \"_\"\n",
    "            log_file = log_file + stamp +'.txt'\n",
    "\n",
    "        with open(log_file, \"+a\") as f:\n",
    "            f.write(\"Epsilon %s kwargs: %s \\n\\n\" % (epsilon, kwargs))\n",
    "        \n",
    "    assert max(img_nrs) <= 99\n",
    "    assert min(img_nrs) >= 0\n",
    "    t_start = time.time()\n",
    "    \n",
    "    runtimes = []\n",
    "    statistics = []\n",
    "    \n",
    "    for img_nr in img_nrs:\n",
    "        img_path = os.path.join(img_root_path, 'img' + str(img_nr) + '.txt')\n",
    "\n",
    "        # Load NN and perturbe image\n",
    "        LB_N0, UB_N0, nn, label, flag_wrong_label = load_nn(net_path, img_path, epsilon)\n",
    "        true_label_counter += int(not flag_wrong_label)\n",
    "        numlayer = nn.numlayer\n",
    "\n",
    "        # Get Bounds\n",
    "        t1 =time.time()\n",
    "        LB_hidden_box_list, UB_hidden_box_list, LB_NN, UB_NN = perform_box_analysis(nn, LB_N0, UB_N0, verbose = False)\n",
    "        LB_NN, UB_NN, stats = perform_linear_layerwise(nn, numlayer, LB_N0, UB_N0, lp_list,\n",
    "                                     LB_hidden_box_list, UB_hidden_box_list, label, verbose=verbose, save_stats=True,\n",
    "                                                       **kwargs)\n",
    "        statistics.append(stats)\n",
    "        # Check if NN was verified\n",
    "        _, verified_flag = verify_network(LB_N0, UB_N0, LB_NN, UB_NN, label, num_input_pixels = len(LB_N0), num_out_pixels = 10)\n",
    "        verified_counter += int(verified_flag)\n",
    "       \n",
    "        t2 = time.time()\n",
    "        \n",
    "        runtimes.append(t2-t1)\n",
    "        \n",
    "        # Write to logfile\n",
    "        if write:\n",
    "            with open(log_file, \"+a\") as f:\n",
    "                if not flag_wrong_label and verified_flag:\n",
    "                    line = \"{:>10} img_{:>2} verified label {:>2} time {:>5.4f} s\\n\\n\".format(net_code, img_nr, label, t2-t1)\n",
    "                elif not flag_wrong_label and not verified_flag:\n",
    "                    line = \"{:>10} img_{:>2} failed label {:>2} time {:>5.4f} s\\n\\n\".format(net_code, img_nr, label, t2-t1)\n",
    "                else:\n",
    "                    line = \"{:>10} img_{:>2} not considered\\n\\n\".format(net_code, img_nr)\n",
    "                f.write(line)\n",
    "                f.write(\"Layerwise_time: %s \\n\" % stats['time'])\n",
    "                bounds = np.stack([stats['LB_hat'][-1], stats['UB_hat'][-1]], axis = 1) \n",
    "                f.write(\"Final Bounds: %s \\n\" % (bounds))\n",
    "                f.write(\"Final Verification Margin (negative is not verified): %3f \\n\" % stats['margin'][-1])\n",
    "                f.write(\"Margin per Neuron (more positive is better): %9f \\n\" % stats['margin_per_neuron'][-1])\n",
    "                f.write(\"Margin per Second (more positve is better): %10f\\n\" % stats['margin_per_time'][-1])\n",
    "                f.write(\"\\n-------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "    if write:       \n",
    "        with open(log_file, \"+a\") as f:\n",
    "            line = []\n",
    "            line.append(\"\\n--------------------- \\n\")\n",
    "            line.append(\"analysis precision  {:>2} /  {:>2}\\n\".format(verified_counter, true_label_counter))\n",
    "            line.append(\"Average Time: {:>5.4f} \\n\".format((time.time() - t_start)/len(img_nrs)))\n",
    "            line.append(\"Max Time: {:>5.4f} \\n\".format(max(runtimes)))\n",
    "            line.append(\"Min Time: {:>5.4f} \\n\".format(min(runtimes)))\n",
    "            for l in line:\n",
    "                f.write(l)\n",
    "\n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Neural Networks: ['mnist_relu_3_10', 'mnist_relu_3_20', 'mnist_relu_3_50', 'mnist_relu_4_1024', 'mnist_relu_6_100', 'mnist_relu_6_20', 'mnist_relu_6_200', 'mnist_relu_6_50', 'mnist_relu_9_100', 'mnist_relu_9_200']\n"
     ]
    }
   ],
   "source": [
    "# # Create list of all NN and images\n",
    "\n",
    "# directory = '../mnist_nets/'\n",
    "# nn_list  = os.listdir(directory)\n",
    "# nn_list = [f.replace('.txt','') for f in nn_list]\n",
    "# nn_list.sort()\n",
    "# print(\"All Neural Networks: %s\" % nn_list)\n",
    "# directory = '../mnist_images/'\n",
    "# img_nrs  = np.arange(100).tolist()\n",
    "# verbose = False\n",
    "# # Create list of all groundtruth NN and epsilons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Layerno: 0\n",
      "Time 0.300119\n",
      "Median tigthness of hat bounds: 1.026251 \n",
      "\n",
      "Min tigthness of hat bounds: 0.939134 \n",
      "\n",
      "Max tigthness of hat bounds: 1.384131 \n",
      "\n",
      "[LB_hat | UB_hat | use_LP]\n",
      "array([[-3.46, -2.35,  0.  ],\n",
      "       [-1.3 , -0.28,  0.  ],\n",
      "       [-4.93, -3.86,  0.  ],\n",
      "       [-5.26, -4.13,  0.  ],\n",
      "       [-1.57, -0.51,  0.  ],\n",
      "       [-1.89, -0.94,  0.  ],\n",
      "       [-1.74, -0.72,  0.  ],\n",
      "       [ 1.85,  3.06,  0.  ],\n",
      "       [-2.17, -1.18,  0.  ],\n",
      "       [-0.61,  0.38,  0.  ],\n",
      "       [-6.76, -5.6 ,  0.  ],\n",
      "       [-1.73, -0.71,  0.  ],\n",
      "       [ 0.89,  2.08,  0.  ],\n",
      "       [-8.35, -7.16,  0.  ],\n",
      "       [-4.77, -3.7 ,  0.  ],\n",
      "       [-2.88, -1.91,  0.  ],\n",
      "       [ 4.69,  5.81,  0.  ],\n",
      "       [-1.65, -0.65,  0.  ],\n",
      "       [-3.1 , -2.03,  0.  ],\n",
      "       [-3.31, -2.3 ,  0.  ],\n",
      "       [-1.9 , -0.93,  0.  ],\n",
      "       [-1.89, -0.89,  0.  ],\n",
      "       [-0.9 ,  0.24,  0.  ],\n",
      "       [ 0.2 ,  1.29,  0.  ],\n",
      "       [-1.77, -0.78,  0.  ],\n",
      "       [-5.02, -4.01,  0.  ],\n",
      "       [-1.05, -0.11,  0.  ],\n",
      "       [-3.96, -2.96,  0.  ],\n",
      "       [-2.63, -1.62,  0.  ],\n",
      "       [-2.36, -1.36,  0.  ],\n",
      "       [-1.51, -0.51,  0.  ],\n",
      "       [-4.06, -2.99,  0.  ],\n",
      "       [-1.18, -0.18,  0.  ],\n",
      "       [-3.9 , -2.8 ,  0.  ],\n",
      "       [-1.56, -0.62,  0.  ],\n",
      "       [-6.44, -5.21,  0.  ],\n",
      "       [-0.7 ,  0.29,  0.  ],\n",
      "       [-1.4 , -0.35,  0.  ],\n",
      "       [ 1.04,  2.09,  0.  ],\n",
      "       [ 0.59,  1.59,  0.  ],\n",
      "       [-0.88,  0.14,  0.  ],\n",
      "       [-3.94, -2.79,  0.  ],\n",
      "       [-3.52, -2.45,  0.  ],\n",
      "       [-2.3 , -1.26,  0.  ],\n",
      "       [-2.09, -1.1 ,  0.  ],\n",
      "       [-1.7 , -0.73,  0.  ],\n",
      "       [ 0.53,  1.55,  0.  ],\n",
      "       [-1.36, -0.38,  0.  ],\n",
      "       [-2.87, -1.9 ,  0.  ],\n",
      "       [-0.8 ,  0.33,  0.  ],\n",
      "       [-3.26, -2.17,  0.  ],\n",
      "       [-2.52, -1.55,  0.  ],\n",
      "       [-2.54, -1.57,  0.  ],\n",
      "       [-2.53, -1.54,  0.  ],\n",
      "       [-2.35, -1.34,  0.  ],\n",
      "       [-2.  , -1.02,  0.  ],\n",
      "       [-2.58, -1.61,  0.  ],\n",
      "       [-4.17, -3.03,  0.  ],\n",
      "       [-1.83, -0.83,  0.  ],\n",
      "       [-0.79,  0.37,  0.  ],\n",
      "       [-1.84, -0.87,  0.  ],\n",
      "       [-3.51, -2.45,  0.  ],\n",
      "       [-0.87,  0.16,  0.  ],\n",
      "       [-1.87, -0.84,  0.  ],\n",
      "       [-2.85, -1.75,  0.  ],\n",
      "       [-0.86,  0.1 ,  0.  ],\n",
      "       [-2.76, -1.72,  0.  ],\n",
      "       [-1.64, -0.69,  0.  ],\n",
      "       [-2.83, -1.8 ,  0.  ],\n",
      "       [-0.77,  0.28,  0.  ],\n",
      "       [-0.02,  0.99,  0.  ],\n",
      "       [-2.41, -1.41,  0.  ],\n",
      "       [-0.92,  0.09,  0.  ],\n",
      "       [-1.54, -0.56,  0.  ],\n",
      "       [-1.51, -0.54,  0.  ],\n",
      "       [-0.92,  0.25,  0.  ],\n",
      "       [-0.87,  0.16,  0.  ],\n",
      "       [-4.11, -2.97,  0.  ],\n",
      "       [ 0.75,  2.02,  0.  ],\n",
      "       [-1.85, -0.86,  0.  ],\n",
      "       [-1.05,  0.07,  0.  ],\n",
      "       [-6.36, -5.18,  0.  ],\n",
      "       [-4.61, -3.46,  0.  ],\n",
      "       [-3.28, -2.23,  0.  ],\n",
      "       [-1.67, -0.68,  0.  ],\n",
      "       [-1.09, -0.13,  0.  ],\n",
      "       [-2.99, -2.  ,  0.  ],\n",
      "       [-4.77, -3.58,  0.  ],\n",
      "       [-2.63, -1.61,  0.  ],\n",
      "       [-6.9 , -5.58,  0.  ],\n",
      "       [-3.04, -2.1 ,  0.  ],\n",
      "       [-0.97,  0.03,  0.  ],\n",
      "       [-1.09, -0.  ,  0.  ],\n",
      "       [-2.48, -1.32,  0.  ],\n",
      "       [-1.65, -0.63,  0.  ],\n",
      "       [-4.36, -3.33,  0.  ],\n",
      "       [ 0.74,  1.77,  0.  ],\n",
      "       [-2.56, -1.3 ,  0.  ],\n",
      "       [-0.76,  0.27,  0.  ],\n",
      "       [-4.61, -3.61,  0.  ],\n",
      "       [-3.36, -2.35,  0.  ],\n",
      "       [-2.49, -1.51,  0.  ],\n",
      "       [-1.51, -0.5 ,  0.  ],\n",
      "       [-1.71, -0.71,  0.  ],\n",
      "       [-1.52, -0.51,  0.  ],\n",
      "       [-3.27, -2.27,  0.  ],\n",
      "       [-1.62, -0.6 ,  0.  ],\n",
      "       [-2.58, -1.59,  0.  ],\n",
      "       [-0.3 ,  0.73,  0.  ],\n",
      "       [-1.11, -0.1 ,  0.  ],\n",
      "       [-8.38, -7.2 ,  0.  ],\n",
      "       [-1.36, -0.31,  0.  ],\n",
      "       [-3.22, -2.25,  0.  ],\n",
      "       [-0.32,  0.66,  0.  ],\n",
      "       [-3.74, -2.56,  0.  ],\n",
      "       [-0.99,  0.05,  0.  ],\n",
      "       [-1.31, -0.21,  0.  ],\n",
      "       [-2.36, -1.41,  0.  ],\n",
      "       [-1.55, -0.55,  0.  ],\n",
      "       [-1.54, -0.48,  0.  ],\n",
      "       [-1.85, -0.79,  0.  ],\n",
      "       [-4.22, -2.94,  0.  ],\n",
      "       [-1.7 , -0.7 ,  0.  ],\n",
      "       [-3.2 , -2.2 ,  0.  ],\n",
      "       [-2.42, -1.33,  0.  ],\n",
      "       [-0.59,  0.41,  0.  ],\n",
      "       [-2.02, -0.78,  0.  ],\n",
      "       [-1.32, -0.25,  0.  ],\n",
      "       [ 1.65,  2.8 ,  0.  ],\n",
      "       [-2.53, -1.57,  0.  ],\n",
      "       [-2.89, -1.83,  0.  ],\n",
      "       [-1.04, -0.06,  0.  ],\n",
      "       [-1.29, -0.21,  0.  ],\n",
      "       [-2.15, -1.12,  0.  ],\n",
      "       [-4.96, -3.8 ,  0.  ],\n",
      "       [-1.22, -0.25,  0.  ],\n",
      "       [-1.4 , -0.36,  0.  ],\n",
      "       [-4.3 , -3.19,  0.  ],\n",
      "       [-2.85, -1.79,  0.  ],\n",
      "       [-5.02, -3.91,  0.  ],\n",
      "       [-1.2 , -0.19,  0.  ],\n",
      "       [-1.33, -0.32,  0.  ],\n",
      "       [-0.74,  0.29,  0.  ],\n",
      "       [-0.46,  0.57,  0.  ],\n",
      "       [-3.54, -2.5 ,  0.  ],\n",
      "       [-2.1 , -1.04,  0.  ],\n",
      "       [-0.78,  0.21,  0.  ],\n",
      "       [-2.21, -1.13,  0.  ],\n",
      "       [-1.96, -0.91,  0.  ],\n",
      "       [-3.07, -2.12,  0.  ],\n",
      "       [-0.49,  0.47,  0.  ],\n",
      "       [-0.88,  0.27,  0.  ],\n",
      "       [-1.47, -0.37,  0.  ],\n",
      "       [-1.22, -0.22,  0.  ],\n",
      "       [-0.67,  0.3 ,  0.  ],\n",
      "       [-4.32, -3.14,  0.  ],\n",
      "       [-3.21, -2.14,  0.  ],\n",
      "       [-2.97, -2.02,  0.  ],\n",
      "       [-0.6 ,  0.36,  0.  ],\n",
      "       [-1.03,  0.18,  0.  ],\n",
      "       [-3.48, -2.42,  0.  ],\n",
      "       [-1.91, -0.95,  0.  ],\n",
      "       [-2.29, -1.28,  0.  ],\n",
      "       [-4.98, -3.86,  0.  ],\n",
      "       [ 4.08,  5.32,  0.  ],\n",
      "       [-3.84, -2.78,  0.  ],\n",
      "       [ 1.46,  2.57,  0.  ],\n",
      "       [-2.02, -1.06,  0.  ],\n",
      "       [-1.32, -0.32,  0.  ],\n",
      "       [-2.36, -1.31,  0.  ],\n",
      "       [-0.18,  0.82,  0.  ],\n",
      "       [-1.86, -0.85,  0.  ],\n",
      "       [-2.56, -1.53,  0.  ],\n",
      "       [-2.2 , -0.81,  0.  ],\n",
      "       [ 1.58,  2.61,  0.  ],\n",
      "       [-1.78, -0.75,  0.  ],\n",
      "       [-1.66, -0.48,  0.  ],\n",
      "       [-0.87,  0.15,  0.  ],\n",
      "       [-2.16, -1.13,  0.  ],\n",
      "       [-4.84, -3.81,  0.  ],\n",
      "       [-3.78, -2.76,  0.  ],\n",
      "       [-1.41, -0.43,  0.  ],\n",
      "       [-0.62,  0.42,  0.  ],\n",
      "       [-1.32, -0.34,  0.  ],\n",
      "       [-3.99, -2.97,  0.  ],\n",
      "       [-1.73, -0.69,  0.  ],\n",
      "       [-2.32, -1.35,  0.  ],\n",
      "       [-3.47, -2.43,  0.  ],\n",
      "       [ 1.01,  2.14,  0.  ],\n",
      "       [-1.87, -0.86,  0.  ],\n",
      "       [-1.72, -0.71,  0.  ],\n",
      "       [-0.94,  0.03,  0.  ],\n",
      "       [-2.53, -1.51,  0.  ],\n",
      "       [-0.2 ,  0.84,  0.  ],\n",
      "       [ 3.98,  5.12,  0.  ],\n",
      "       [-2.09, -1.01,  0.  ],\n",
      "       [-2.62, -1.63,  0.  ],\n",
      "       [-0.76,  0.35,  0.  ],\n",
      "       [-2.23, -1.26,  0.  ],\n",
      "       [ 4.04,  5.28,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n",
      "--------------------------\n",
      "Layerno: 1\n",
      "Time 8.194542\n",
      "Time per LP neuron 0.081945\n",
      "LP used on 100 neurons.\n",
      "Median tigthness of hat bounds: 1.489952 \n",
      "\n",
      "Min tigthness of hat bounds: 0.637632 \n",
      "\n",
      "Max tigthness of hat bounds: 3.399756 \n",
      "\n",
      "[LB_hat | UB_hat | use_LP]\n",
      "array([[-2.83, -0.42,  0.  ],\n",
      "       [-3.63, -0.84,  0.  ],\n",
      "       [-1.12, -0.4 ,  1.  ],\n",
      "       [-3.14, -0.43,  0.  ],\n",
      "       [ 0.53,  1.39,  1.  ],\n",
      "       [-3.85, -1.51,  0.  ],\n",
      "       [-1.23, -0.39,  1.  ],\n",
      "       [-1.3 , -0.47,  1.  ],\n",
      "       [-4.27, -1.8 ,  0.  ],\n",
      "       [ 0.1 ,  0.88,  1.  ],\n",
      "       [-2.65, -0.2 ,  0.  ],\n",
      "       [-3.03, -0.82,  0.  ],\n",
      "       [ 2.84,  4.06,  1.  ],\n",
      "       [-0.46,  0.4 ,  1.  ],\n",
      "       [-0.69,  0.13,  1.  ],\n",
      "       [-1.09, -0.33,  1.  ],\n",
      "       [-1.17, -0.27,  1.  ],\n",
      "       [-0.83,  0.05,  1.  ],\n",
      "       [-2.34, -0.18,  0.  ],\n",
      "       [-1.22, -0.5 ,  1.  ],\n",
      "       [ 1.52,  2.26,  1.  ],\n",
      "       [-3.03, -0.25,  0.  ],\n",
      "       [-2.79, -0.64,  0.  ],\n",
      "       [ 0.55,  1.52,  1.  ],\n",
      "       [-3.64, -1.29,  0.  ],\n",
      "       [ 0.8 ,  1.54,  1.  ],\n",
      "       [ 0.96,  1.78,  1.  ],\n",
      "       [-4.49, -1.61,  0.  ],\n",
      "       [-1.6 , -0.69,  1.  ],\n",
      "       [-0.45,  0.31,  1.  ],\n",
      "       [-5.59, -2.63,  0.  ],\n",
      "       [-1.05, -0.2 ,  1.  ],\n",
      "       [-2.92, -0.83,  0.  ],\n",
      "       [-1.36, -0.28,  1.  ],\n",
      "       [-3.83, -1.44,  0.  ],\n",
      "       [-2.47, -0.14,  0.  ],\n",
      "       [-0.51,  0.21,  1.  ],\n",
      "       [-3.23, -0.47,  0.  ],\n",
      "       [-2.5 , -0.17,  0.  ],\n",
      "       [-3.66, -1.02,  0.  ],\n",
      "       [ 1.43,  2.25,  1.  ],\n",
      "       [-3.14, -0.97,  0.  ],\n",
      "       [-1.5 , -0.48,  1.  ],\n",
      "       [-2.46, -0.  ,  0.  ],\n",
      "       [-0.44,  0.48,  1.  ],\n",
      "       [ 0.81,  1.87,  1.  ],\n",
      "       [-0.47,  0.21,  1.  ],\n",
      "       [-1.58, -0.52,  1.  ],\n",
      "       [-0.92, -0.17,  1.  ],\n",
      "       [ 0.88,  1.97,  1.  ],\n",
      "       [-1.04, -0.24,  1.  ],\n",
      "       [-0.91, -0.13,  1.  ],\n",
      "       [-0.92, -0.28,  1.  ],\n",
      "       [-2.93, -0.23,  0.  ],\n",
      "       [-0.92, -0.14,  1.  ],\n",
      "       [ 0.25,  1.14,  1.  ],\n",
      "       [-0.29,  0.55,  1.  ],\n",
      "       [-2.99, -0.84,  0.  ],\n",
      "       [-0.13,  0.56,  1.  ],\n",
      "       [-2.27, -0.11,  0.  ],\n",
      "       [-0.96, -0.2 ,  1.  ],\n",
      "       [-3.92, -0.96,  0.  ],\n",
      "       [-3.58, -1.14,  0.  ],\n",
      "       [-0.95, -0.06,  1.  ],\n",
      "       [-1.14, -0.27,  1.  ],\n",
      "       [-0.  ,  0.87,  1.  ],\n",
      "       [-0.74, -0.06,  1.  ],\n",
      "       [-1.17, -0.36,  1.  ],\n",
      "       [-0.79, -0.06,  1.  ],\n",
      "       [-0.7 , -0.03,  1.  ],\n",
      "       [-3.79, -0.95,  0.  ],\n",
      "       [-3.  , -0.74,  0.  ],\n",
      "       [-2.69, -0.36,  0.  ],\n",
      "       [-4.71, -2.11,  0.  ],\n",
      "       [ 2.37,  3.36,  1.  ],\n",
      "       [-2.3 , -0.18,  0.  ],\n",
      "       [-1.59, -0.68,  1.  ],\n",
      "       [-2.88, -0.5 ,  0.  ],\n",
      "       [-3.17, -1.03,  0.  ],\n",
      "       [-0.8 ,  0.15,  1.  ],\n",
      "       [ 1.31,  2.44,  1.  ],\n",
      "       [-2.6 , -0.29,  0.  ],\n",
      "       [ 3.39,  4.75,  1.  ],\n",
      "       [-2.63, -0.38,  0.  ],\n",
      "       [-0.77,  0.08,  1.  ],\n",
      "       [-1.34, -0.51,  1.  ],\n",
      "       [ 0.36,  1.13,  1.  ],\n",
      "       [-3.56, -0.8 ,  0.  ],\n",
      "       [-3.75, -0.81,  0.  ],\n",
      "       [-4.43, -1.38,  0.  ],\n",
      "       [-4.04, -1.19,  0.  ],\n",
      "       [-1.53, -0.68,  1.  ],\n",
      "       [-3.45, -1.21,  0.  ],\n",
      "       [-3.08, -0.7 ,  0.  ],\n",
      "       [ 2.13,  3.27,  1.  ],\n",
      "       [-0.55,  0.33,  1.  ],\n",
      "       [-2.63, -0.85,  0.  ],\n",
      "       [-4.03, -1.25,  0.  ],\n",
      "       [-3.51, -1.3 ,  0.  ],\n",
      "       [ 0.47,  1.21,  1.  ],\n",
      "       [-0.92, -0.08,  1.  ],\n",
      "       [-3.59, -1.05,  0.  ],\n",
      "       [-3.85, -1.22,  0.  ],\n",
      "       [-2.57, -0.26,  0.  ],\n",
      "       [-3.43, -0.73,  0.  ],\n",
      "       [-2.16, -0.22,  0.  ],\n",
      "       [-2.71, -0.7 ,  0.  ],\n",
      "       [-3.24, -0.45,  0.  ],\n",
      "       [-1.15, -0.29,  1.  ],\n",
      "       [-4.76, -2.15,  0.  ],\n",
      "       [-3.03, -0.65,  0.  ],\n",
      "       [ 2.84,  3.99,  1.  ],\n",
      "       [-1.94, -0.26,  0.  ],\n",
      "       [-0.08,  0.66,  1.  ],\n",
      "       [-1.15, -0.43,  1.  ],\n",
      "       [ 1.99,  2.79,  1.  ],\n",
      "       [-1.36, -0.62,  1.  ],\n",
      "       [-1.19, -0.52,  1.  ],\n",
      "       [-2.2 , -0.58,  0.  ],\n",
      "       [-2.35, -0.44,  0.  ],\n",
      "       [-0.25,  0.53,  1.  ],\n",
      "       [-3.43, -0.75,  0.  ],\n",
      "       [-1.14, -0.18,  1.  ],\n",
      "       [-2.7 , -0.91,  0.  ],\n",
      "       [-5.17, -2.34,  0.  ],\n",
      "       [-1.63, -0.68,  1.  ],\n",
      "       [ 1.78,  2.7 ,  1.  ],\n",
      "       [-2.73, -0.56,  0.  ],\n",
      "       [ 4.01,  5.25,  1.  ],\n",
      "       [-0.57,  0.2 ,  1.  ],\n",
      "       [-2.9 , -0.84,  0.  ],\n",
      "       [-3.18, -1.19,  0.  ],\n",
      "       [-3.41, -0.87,  0.  ],\n",
      "       [-2.73, -0.92,  0.  ],\n",
      "       [-3.52, -1.05,  0.  ],\n",
      "       [-2.13, -0.09,  0.  ],\n",
      "       [-0.81, -0.05,  1.  ],\n",
      "       [-2.51, -0.63,  0.  ],\n",
      "       [-3.93, -0.98,  0.  ],\n",
      "       [-2.35, -0.16,  0.  ],\n",
      "       [-0.93, -0.19,  1.  ],\n",
      "       [-3.72, -1.16,  0.  ],\n",
      "       [-0.65,  0.03,  1.  ],\n",
      "       [ 0.53,  1.26,  1.  ],\n",
      "       [ 0.25,  0.96,  1.  ],\n",
      "       [-3.06, -0.6 ,  0.  ],\n",
      "       [-0.25,  0.65,  1.  ],\n",
      "       [ 0.52,  1.51,  1.  ],\n",
      "       [-1.38, -0.59,  1.  ],\n",
      "       [-3.81, -0.65,  0.  ],\n",
      "       [-2.55, -0.43,  0.  ],\n",
      "       [-0.7 ,  0.11,  1.  ],\n",
      "       [-3.55, -1.32,  0.  ],\n",
      "       [-3.31, -0.98,  0.  ],\n",
      "       [-2.2 , -1.5 ,  1.  ],\n",
      "       [-4.36, -1.34,  0.  ],\n",
      "       [-2.77, -0.8 ,  0.  ],\n",
      "       [-0.82, -0.  ,  1.  ],\n",
      "       [-1.49, -0.59,  1.  ],\n",
      "       [-3.01, -0.75,  0.  ],\n",
      "       [-2.43, -0.22,  0.  ],\n",
      "       [-2.62, -0.44,  0.  ],\n",
      "       [ 1.94,  2.88,  1.  ],\n",
      "       [-2.6 , -0.5 ,  0.  ],\n",
      "       [-0.55,  0.31,  1.  ],\n",
      "       [-2.84, -0.87,  0.  ],\n",
      "       [-2.  , -0.15,  0.  ],\n",
      "       [-2.8 , -0.11,  0.  ],\n",
      "       [-1.15, -0.45,  1.  ],\n",
      "       [-3.03, -0.83,  0.  ],\n",
      "       [-0.96, -0.15,  1.  ],\n",
      "       [-1.58, -0.68,  1.  ],\n",
      "       [-1.  , -0.25,  1.  ],\n",
      "       [-0.04,  0.7 ,  1.  ],\n",
      "       [-0.36,  0.57,  1.  ],\n",
      "       [-1.78, -0.84,  1.  ],\n",
      "       [-0.45,  0.27,  1.  ],\n",
      "       [-5.35, -2.66,  0.  ],\n",
      "       [-2.43, -0.19,  0.  ],\n",
      "       [ 0.13,  1.01,  1.  ],\n",
      "       [-3.44, -1.22,  0.  ],\n",
      "       [-4.05, -1.78,  0.  ],\n",
      "       [-2.97, -0.19,  0.  ],\n",
      "       [-1.45, -0.61,  1.  ],\n",
      "       [-5.78, -2.49,  0.  ],\n",
      "       [-4.09, -1.45,  0.  ],\n",
      "       [ 0.99,  1.93,  1.  ],\n",
      "       [ 0.96,  1.86,  1.  ],\n",
      "       [ 0.44,  1.1 ,  1.  ],\n",
      "       [-2.34, -0.19,  0.  ],\n",
      "       [-0.37,  0.42,  1.  ],\n",
      "       [ 0.48,  1.22,  1.  ],\n",
      "       [-0.93, -0.17,  1.  ],\n",
      "       [-2.84, -0.66,  0.  ],\n",
      "       [-5.51, -2.11,  0.  ],\n",
      "       [-3.98, -1.46,  0.  ],\n",
      "       [-2.66, -0.39,  0.  ],\n",
      "       [-4.96, -2.65,  0.  ],\n",
      "       [-2.75, -0.06,  0.  ],\n",
      "       [-3.45, -0.41,  0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Layerno: 2\n",
      "Time 13.367824\n",
      "Time per LP neuron 0.133678\n",
      "LP used on 100 neurons.\n",
      "Median tigthness of hat bounds: 1.910528 \n",
      "\n",
      "Min tigthness of hat bounds: 0.493175 \n",
      "\n",
      "Max tigthness of hat bounds: 3.533973 \n",
      "\n",
      "[LB_hat | UB_hat | use_LP]\n",
      "array([[-0.81, -0.02,  1.  ],\n",
      "       [-0.87, -0.12,  1.  ],\n",
      "       [-3.53, -1.01,  0.  ],\n",
      "       [ 2.17,  3.11,  1.  ],\n",
      "       [-0.09,  0.68,  1.  ],\n",
      "       [-2.71, -0.24,  0.  ],\n",
      "       [-0.41,  0.15,  1.  ],\n",
      "       [-3.55, -0.44,  0.  ],\n",
      "       [-3.03, -0.31,  0.  ],\n",
      "       [ 1.31,  2.18,  1.  ],\n",
      "       [-3.11, -0.14,  0.  ],\n",
      "       [-0.21,  2.37,  0.  ],\n",
      "       [-1.09,  1.07,  0.  ],\n",
      "       [ 0.45,  1.17,  1.  ],\n",
      "       [-1.3 , -0.42,  1.  ],\n",
      "       [-2.8 , -0.01,  0.  ],\n",
      "       [-0.14,  2.28,  0.  ],\n",
      "       [ 3.04,  4.33,  1.  ],\n",
      "       [ 3.56,  5.02,  1.  ],\n",
      "       [-1.58, -0.81,  1.  ],\n",
      "       [-2.14,  0.25,  0.  ],\n",
      "       [-3.75, -1.24,  0.  ],\n",
      "       [ 1.18,  2.05,  1.  ],\n",
      "       [-3.54, -0.37,  0.  ],\n",
      "       [-0.35,  0.46,  1.  ],\n",
      "       [-1.7 ,  0.4 ,  0.  ],\n",
      "       [-4.11, -0.84,  0.  ],\n",
      "       [-0.9 , -0.31,  1.  ],\n",
      "       [-3.36, -0.54,  0.  ],\n",
      "       [-1.33, -0.64,  1.  ],\n",
      "       [-1.63, -0.84,  1.  ],\n",
      "       [-0.29,  0.33,  1.  ],\n",
      "       [-2.08,  0.14,  0.  ],\n",
      "       [-0.85, -0.19,  1.  ],\n",
      "       [-4.56, -1.26,  0.  ],\n",
      "       [-1.95, -1.05,  1.  ],\n",
      "       [-3.08, -0.12,  0.  ],\n",
      "       [-5.64, -2.38,  0.  ],\n",
      "       [-2.98, -0.28,  0.  ],\n",
      "       [ 0.3 ,  1.07,  1.  ],\n",
      "       [-1.42, -0.63,  1.  ],\n",
      "       [-3.41, -0.84,  0.  ],\n",
      "       [-1.48, -0.8 ,  1.  ],\n",
      "       [-4.52, -1.55,  0.  ],\n",
      "       [-3.38, -0.76,  0.  ],\n",
      "       [ 2.08,  3.16,  1.  ],\n",
      "       [-1.47, -0.74,  1.  ],\n",
      "       [-1.61,  1.01,  0.  ],\n",
      "       [-1.44, -0.72,  1.  ],\n",
      "       [-3.07, -0.26,  0.  ],\n",
      "       [-0.77, -0.15,  1.  ],\n",
      "       [-2.25,  0.67,  0.  ],\n",
      "       [-2.06,  0.34,  0.  ],\n",
      "       [-1.76, -0.91,  1.  ],\n",
      "       [-3.57, -1.24,  0.  ],\n",
      "       [-2.35,  0.08,  0.  ],\n",
      "       [-3.41, -0.58,  0.  ],\n",
      "       [ 1.55,  2.7 ,  1.  ],\n",
      "       [-2.12,  0.29,  0.  ],\n",
      "       [-2.23,  0.52,  0.  ],\n",
      "       [-3.48, -0.46,  0.  ],\n",
      "       [ 4.11,  5.94,  1.  ],\n",
      "       [-3.22, -0.28,  0.  ],\n",
      "       [-4.91, -1.93,  0.  ],\n",
      "       [-1.22, -0.46,  1.  ],\n",
      "       [-1.27,  0.72,  0.  ],\n",
      "       [-3.31, -0.51,  0.  ],\n",
      "       [ 0.91,  1.62,  1.  ],\n",
      "       [-1.06, -0.39,  1.  ],\n",
      "       [-1.63,  0.82,  0.  ],\n",
      "       [ 1.8 ,  3.06,  1.  ],\n",
      "       [ 0.09,  0.63,  1.  ],\n",
      "       [-2.99, -0.29,  0.  ],\n",
      "       [-3.23, -0.04,  0.  ],\n",
      "       [-3.81, -0.94,  0.  ],\n",
      "       [ 1.26,  2.11,  1.  ],\n",
      "       [-1.24, -0.56,  1.  ],\n",
      "       [ 0.15,  0.83,  1.  ],\n",
      "       [-3.2 , -0.61,  0.  ],\n",
      "       [-1.36, -0.58,  1.  ],\n",
      "       [-3.  , -0.61,  0.  ],\n",
      "       [-1.78,  0.53,  0.  ],\n",
      "       [-3.56, -0.46,  0.  ],\n",
      "       [-0.71, -0.04,  1.  ],\n",
      "       [ 0.56,  1.54,  1.  ],\n",
      "       [-1.44, -0.88,  1.  ],\n",
      "       [-1.38, -0.68,  1.  ],\n",
      "       [-4.4 , -0.86,  0.  ],\n",
      "       [-3.47, -0.16,  0.  ],\n",
      "       [-4.11, -1.22,  0.  ],\n",
      "       [-1.18, -0.34,  1.  ],\n",
      "       [-3.1 , -0.46,  0.  ],\n",
      "       [-3.11, -0.06,  0.  ],\n",
      "       [ 1.45,  2.23,  1.  ],\n",
      "       [-1.4 ,  1.18,  0.  ],\n",
      "       [-3.08, -0.25,  0.  ],\n",
      "       [-0.32,  0.31,  1.  ],\n",
      "       [-0.98, -0.4 ,  1.  ],\n",
      "       [-1.58,  0.9 ,  0.  ],\n",
      "       [-2.26,  0.31,  0.  ],\n",
      "       [ 2.35,  3.78,  1.  ],\n",
      "       [-0.48,  1.88,  0.  ],\n",
      "       [-2.75, -0.25,  0.  ],\n",
      "       [-1.31, -0.51,  1.  ],\n",
      "       [-1.79,  0.63,  0.  ],\n",
      "       [-0.13,  0.54,  1.  ],\n",
      "       [-0.51,  0.25,  1.  ],\n",
      "       [-1.16,  1.34,  0.  ],\n",
      "       [-0.9 , -0.24,  1.  ],\n",
      "       [-1.17, -0.33,  1.  ],\n",
      "       [-0.54,  0.13,  1.  ],\n",
      "       [-1.84, -0.96,  1.  ],\n",
      "       [-2.15,  0.18,  0.  ],\n",
      "       [ 1.36,  2.07,  1.  ],\n",
      "       [-1.35, -0.71,  1.  ],\n",
      "       [-2.55, -0.31,  0.  ],\n",
      "       [-1.79, -1.01,  1.  ],\n",
      "       [-0.73,  1.49,  0.  ],\n",
      "       [-2.36, -0.  ,  0.  ],\n",
      "       [-1.06, -0.27,  1.  ],\n",
      "       [-4.28, -0.95,  0.  ],\n",
      "       [-1.89,  0.26,  0.  ],\n",
      "       [-1.7 ,  1.03,  0.  ],\n",
      "       [-1.13, -0.26,  1.  ],\n",
      "       [-0.94, -0.16,  1.  ],\n",
      "       [-3.41, -0.91,  0.  ],\n",
      "       [-1.57,  0.94,  0.  ],\n",
      "       [-3.17, -0.39,  0.  ],\n",
      "       [-1.53,  0.69,  0.  ],\n",
      "       [-0.03,  0.57,  1.  ],\n",
      "       [-1.77,  0.73,  0.  ],\n",
      "       [-0.59,  0.2 ,  1.  ],\n",
      "       [-3.03, -0.03,  0.  ],\n",
      "       [-1.72, -0.98,  1.  ],\n",
      "       [-1.61,  1.  ,  0.  ],\n",
      "       [-0.37,  2.28,  0.  ],\n",
      "       [-1.47, -0.67,  1.  ],\n",
      "       [-0.91, -0.39,  1.  ],\n",
      "       [ 1.12,  1.92,  1.  ],\n",
      "       [-1.57, -0.44,  1.  ],\n",
      "       [ 0.99,  3.66,  0.  ],\n",
      "       [-2.75, -0.1 ,  0.  ],\n",
      "       [-1.2 , -0.34,  1.  ],\n",
      "       [-1.21, -0.4 ,  1.  ],\n",
      "       [-1.07, -0.44,  1.  ],\n",
      "       [ 0.05,  0.6 ,  1.  ],\n",
      "       [-1.48, -0.78,  1.  ],\n",
      "       [-3.29, -0.66,  0.  ],\n",
      "       [-2.96, -0.58,  0.  ],\n",
      "       [ 1.15,  2.04,  1.  ],\n",
      "       [ 0.1 ,  0.81,  1.  ],\n",
      "       [-5.01, -1.7 ,  0.  ],\n",
      "       [ 0.43,  1.34,  1.  ],\n",
      "       [-4.52, -1.34,  0.  ],\n",
      "       [-0.97, -0.36,  1.  ],\n",
      "       [-1.69, -0.86,  1.  ],\n",
      "       [-6.11, -2.82,  0.  ],\n",
      "       [-1.6 , -0.91,  1.  ],\n",
      "       [-1.64,  0.94,  0.  ],\n",
      "       [-4.39, -0.92,  0.  ],\n",
      "       [-1.19, -0.42,  1.  ],\n",
      "       [-1.59, -0.91,  1.  ],\n",
      "       [-1.17, -0.41,  1.  ],\n",
      "       [-0.8 , -0.11,  1.  ],\n",
      "       [ 0.14,  2.8 ,  0.  ],\n",
      "       [-0.98, -0.49,  1.  ],\n",
      "       [-3.16, -0.29,  0.  ],\n",
      "       [-0.64,  0.16,  1.  ],\n",
      "       [-3.82, -1.05,  0.  ],\n",
      "       [-3.33, -0.32,  0.  ],\n",
      "       [-2.58, -0.16,  0.  ],\n",
      "       [-2.25,  0.05,  0.  ],\n",
      "       [-1.69, -0.99,  1.  ],\n",
      "       [ 2.08,  3.35,  1.  ],\n",
      "       [-0.03,  2.26,  0.  ],\n",
      "       [-2.94, -0.06,  0.  ],\n",
      "       [-2.71, -0.3 ,  0.  ],\n",
      "       [-1.55, -0.89,  1.  ],\n",
      "       [-0.39,  0.17,  1.  ],\n",
      "       [-0.02,  0.74,  1.  ],\n",
      "       [-1.55, -0.83,  1.  ],\n",
      "       [-3.59, -0.73,  0.  ],\n",
      "       [-3.8 , -0.82,  0.  ],\n",
      "       [-1.69, -1.  ,  1.  ],\n",
      "       [-0.5 ,  0.04,  1.  ],\n",
      "       [-0.34,  0.32,  1.  ],\n",
      "       [-1.43,  0.97,  0.  ],\n",
      "       [-3.16, -0.63,  0.  ],\n",
      "       [-0.64, -0.04,  1.  ],\n",
      "       [-0.81, -0.19,  1.  ],\n",
      "       [ 0.86,  1.91,  1.  ],\n",
      "       [-4.32, -0.97,  0.  ],\n",
      "       [-1.31, -0.63,  1.  ],\n",
      "       [-2.98, -0.05,  0.  ],\n",
      "       [-0.86, -0.22,  1.  ],\n",
      "       [-1.64, -1.01,  1.  ],\n",
      "       [-2.97, -0.51,  0.  ],\n",
      "       [-0.6 ,  1.64,  0.  ],\n",
      "       [-2.88, -0.22,  0.  ],\n",
      "       [ 1.01,  1.89,  1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n",
      "--------------------------\n",
      "Layerno: 3\n",
      "Time 28.930114\n",
      "Time per LP neuron 0.289301\n",
      "LP used on 100 neurons.\n",
      "Median tigthness of hat bounds: 3.136771 \n",
      "\n",
      "Min tigthness of hat bounds: 1.098080 \n",
      "\n",
      "Max tigthness of hat bounds: 6.207601 \n",
      "\n",
      "[LB_hat | UB_hat | use_LP]\n",
      "array([[-2.23,  2.29,  0.  ],\n",
      "       [-3.96,  0.74,  0.  ],\n",
      "       [-2.18, -0.93,  1.  ],\n",
      "       [-2.14, -0.73,  1.  ],\n",
      "       [-1.19,  0.49,  1.  ],\n",
      "       [-2.84, -1.2 ,  1.  ],\n",
      "       [-2.19,  2.23,  0.  ],\n",
      "       [-1.83,  2.54,  0.  ],\n",
      "       [-1.57,  2.49,  0.  ],\n",
      "       [-1.25,  0.2 ,  1.  ],\n",
      "       [-0.04,  1.28,  1.  ],\n",
      "       [-2.97, -1.12,  1.  ],\n",
      "       [ 2.95,  5.14,  1.  ],\n",
      "       [-2.46, -0.68,  1.  ],\n",
      "       [-1.82, -0.45,  1.  ],\n",
      "       [-2.22, -0.82,  1.  ],\n",
      "       [-6.24, -0.59,  0.  ],\n",
      "       [-3.4 ,  1.29,  0.  ],\n",
      "       [ 2.39,  4.5 ,  1.  ],\n",
      "       [-0.94,  0.39,  1.  ],\n",
      "       [-1.69, -0.26,  1.  ],\n",
      "       [-2.27,  2.27,  0.  ],\n",
      "       [-2.32,  2.04,  0.  ],\n",
      "       [-1.04,  0.3 ,  1.  ],\n",
      "       [-1.5 ,  2.98,  0.  ],\n",
      "       [-1.68, -0.28,  1.  ],\n",
      "       [-5.85, -0.21,  0.  ],\n",
      "       [ 0.9 ,  2.41,  1.  ],\n",
      "       [-2.47, -0.63,  1.  ],\n",
      "       [-3.97,  0.16,  0.  ],\n",
      "       [-2.11,  1.86,  0.  ],\n",
      "       [-1.53,  0.05,  1.  ],\n",
      "       [-1.27,  0.2 ,  1.  ],\n",
      "       [-1.94, -0.44,  1.  ],\n",
      "       [-2.86,  1.32,  0.  ],\n",
      "       [-2.99,  2.14,  0.  ],\n",
      "       [-1.66, -0.22,  1.  ],\n",
      "       [-2.53, -0.95,  1.  ],\n",
      "       [-5.79, -0.17,  0.  ],\n",
      "       [-1.01,  0.27,  1.  ],\n",
      "       [-1.41, -0.01,  1.  ],\n",
      "       [-2.49,  2.83,  0.  ],\n",
      "       [-0.64,  0.9 ,  1.  ],\n",
      "       [-1.76, -0.4 ,  1.  ],\n",
      "       [-2.65,  2.41,  0.  ],\n",
      "       [ 0.19,  1.43,  1.  ],\n",
      "       [-5.78, -0.04,  0.  ],\n",
      "       [ 0.46,  2.14,  1.  ],\n",
      "       [-2.75,  1.38,  0.  ],\n",
      "       [ 0.35,  5.05,  0.  ],\n",
      "       [-3.61,  1.03,  0.  ],\n",
      "       [-2.01,  2.58,  0.  ],\n",
      "       [-2.07, -0.57,  1.  ],\n",
      "       [-2.82,  1.51,  0.  ],\n",
      "       [-3.09,  1.33,  0.  ],\n",
      "       [-3.2 ,  1.39,  0.  ],\n",
      "       [-5.14,  0.09,  0.  ],\n",
      "       [-2.78,  2.28,  0.  ],\n",
      "       [-6.6 , -0.85,  0.  ],\n",
      "       [-2.25, -0.72,  1.  ],\n",
      "       [-2.89, -1.13,  1.  ],\n",
      "       [-6.34, -0.7 ,  0.  ],\n",
      "       [-3.1 ,  0.94,  0.  ],\n",
      "       [-1.29, -0.2 ,  1.  ],\n",
      "       [-3.05,  1.89,  0.  ],\n",
      "       [-3.24,  1.11,  0.  ],\n",
      "       [-1.61, -0.11,  1.  ],\n",
      "       [-3.18,  1.36,  0.  ],\n",
      "       [-2.75,  1.61,  0.  ],\n",
      "       [-4.  ,  0.81,  0.  ],\n",
      "       [-2.81,  1.91,  0.  ],\n",
      "       [ 2.68,  4.59,  1.  ],\n",
      "       [-4.63,  0.22,  0.  ],\n",
      "       [-0.91,  3.54,  0.  ],\n",
      "       [-3.36,  0.55,  0.  ],\n",
      "       [-0.05,  1.48,  1.  ],\n",
      "       [ 2.55,  4.72,  1.  ],\n",
      "       [-6.4 , -0.27,  0.  ],\n",
      "       [-2.42,  2.13,  0.  ],\n",
      "       [-2.83,  1.76,  0.  ],\n",
      "       [-2.23, -0.68,  1.  ],\n",
      "       [-2.52, -1.16,  1.  ],\n",
      "       [-4.42,  0.69,  0.  ],\n",
      "       [-3.24,  1.53,  0.  ],\n",
      "       [-2.81,  1.85,  0.  ],\n",
      "       [-2.19, -0.61,  1.  ],\n",
      "       [ 1.01,  2.76,  1.  ],\n",
      "       [-3.97,  1.22,  0.  ],\n",
      "       [-2.64, -0.97,  1.  ],\n",
      "       [-4.83, -0.12,  0.  ],\n",
      "       [-3.2 ,  1.37,  0.  ],\n",
      "       [ 3.55,  5.91,  1.  ],\n",
      "       [-1.49, -0.14,  1.  ],\n",
      "       [ 0.21,  1.46,  1.  ],\n",
      "       [-5.92, -0.97,  0.  ],\n",
      "       [-4.3 ,  0.39,  0.  ],\n",
      "       [-1.88, -0.3 ,  1.  ],\n",
      "       [-3.47, -1.73,  1.  ],\n",
      "       [-3.7 ,  1.28,  0.  ],\n",
      "       [-5.03, -0.31,  0.  ],\n",
      "       [-2.1 , -0.5 ,  1.  ],\n",
      "       [-5.29, -0.86,  0.  ],\n",
      "       [-5.88, -0.3 ,  0.  ],\n",
      "       [-0.59,  4.17,  0.  ],\n",
      "       [-3.07,  1.69,  0.  ],\n",
      "       [-1.52, -0.03,  1.  ],\n",
      "       [-2.56,  2.21,  0.  ],\n",
      "       [-1.66, -0.31,  1.  ],\n",
      "       [-3.18, -1.56,  1.  ],\n",
      "       [ 2.17,  4.04,  1.  ],\n",
      "       [-1.62, -0.07,  1.  ],\n",
      "       [ 1.84,  3.62,  1.  ],\n",
      "       [-4.16,  0.39,  0.  ],\n",
      "       [-1.84, -0.51,  1.  ],\n",
      "       [-3.57,  1.26,  0.  ],\n",
      "       [-2.3 , -0.78,  1.  ],\n",
      "       [-1.89, -0.54,  1.  ],\n",
      "       [-0.64,  0.61,  1.  ],\n",
      "       [-2.82,  1.97,  0.  ],\n",
      "       [-3.52, -1.67,  1.  ],\n",
      "       [-2.07, -0.4 ,  1.  ],\n",
      "       [-1.4 , -0.09,  1.  ],\n",
      "       [-1.31, -0.02,  1.  ],\n",
      "       [-1.9 , -0.63,  1.  ],\n",
      "       [-3.31,  0.72,  0.  ],\n",
      "       [-4.1 ,  0.47,  0.  ],\n",
      "       [-3.5 ,  1.44,  0.  ],\n",
      "       [-2.47, -0.91,  1.  ],\n",
      "       [-0.23,  1.22,  1.  ],\n",
      "       [-1.61, -0.09,  1.  ],\n",
      "       [-3.98,  0.69,  0.  ],\n",
      "       [ 2.54,  4.67,  1.  ],\n",
      "       [-1.99, -0.62,  1.  ],\n",
      "       [-2.36, -0.98,  1.  ],\n",
      "       [-2.82,  1.96,  0.  ],\n",
      "       [-2.78,  1.55,  0.  ],\n",
      "       [-4.09,  0.33,  0.  ],\n",
      "       [-2.83,  1.99,  0.  ],\n",
      "       [-3.16, -1.54,  1.  ],\n",
      "       [-3.09, -1.42,  1.  ],\n",
      "       [-3.7 ,  1.25,  0.  ],\n",
      "       [-2.43, -0.82,  1.  ],\n",
      "       [-2.47, -0.96,  1.  ],\n",
      "       [-5.94, -0.36,  0.  ],\n",
      "       [-4.03,  0.68,  0.  ],\n",
      "       [-1.62, -0.3 ,  1.  ],\n",
      "       [-2.49,  2.77,  0.  ],\n",
      "       [-4.19,  1.04,  0.  ],\n",
      "       [-6.66, -0.45,  0.  ],\n",
      "       [-2.74, -0.85,  1.  ],\n",
      "       [-1.96, -0.29,  1.  ],\n",
      "       [ 0.27,  1.82,  1.  ],\n",
      "       [-0.  ,  4.97,  0.  ],\n",
      "       [-3.5 ,  0.92,  0.  ],\n",
      "       [-3.97,  0.94,  0.  ],\n",
      "       [-3.25, -1.6 ,  1.  ],\n",
      "       [-1.87, -0.38,  1.  ],\n",
      "       [-1.25,  0.2 ,  1.  ],\n",
      "       [ 2.5 ,  4.57,  1.  ],\n",
      "       [-2.52,  2.31,  0.  ],\n",
      "       [-0.98,  3.47,  0.  ],\n",
      "       [-3.31,  1.3 ,  0.  ],\n",
      "       [-1.65, -0.09,  1.  ],\n",
      "       [-4.61,  0.32,  0.  ],\n",
      "       [-1.12,  0.29,  1.  ],\n",
      "       [-2.03, -0.48,  1.  ],\n",
      "       [-1.93, -0.5 ,  1.  ],\n",
      "       [-3.41,  2.18,  0.  ],\n",
      "       [-2.09, -0.61,  1.  ],\n",
      "       [-3.56,  1.27,  0.  ],\n",
      "       [-4.43,  0.54,  0.  ],\n",
      "       [-2.4 , -1.01,  1.  ],\n",
      "       [-2.63, -0.95,  1.  ],\n",
      "       [-2.13,  2.25,  0.  ],\n",
      "       [-2.66,  2.24,  0.  ],\n",
      "       [-2.94, -1.34,  1.  ],\n",
      "       [-0.97,  0.26,  1.  ],\n",
      "       [-2.55,  2.18,  0.  ],\n",
      "       [-5.65, -0.48,  0.  ],\n",
      "       [ 0.21,  1.9 ,  1.  ],\n",
      "       [-5.07, -0.1 ,  0.  ],\n",
      "       [ 0.79,  5.76,  0.  ],\n",
      "       [-4.  ,  0.86,  0.  ],\n",
      "       [-4.55,  0.28,  0.  ],\n",
      "       [-2.65, -1.  ,  1.  ],\n",
      "       [-4.06,  0.86,  0.  ],\n",
      "       [ 0.97,  2.76,  1.  ],\n",
      "       [-1.68, -0.42,  1.  ],\n",
      "       [-0.87,  0.32,  1.  ],\n",
      "       [-2.44, -0.78,  1.  ],\n",
      "       [-1.24, -0.09,  1.  ],\n",
      "       [ 1.12,  6.24,  0.  ],\n",
      "       [-3.64,  1.61,  0.  ],\n",
      "       [-2.15,  2.78,  0.  ],\n",
      "       [-6.74, -0.98,  0.  ],\n",
      "       [-2.96,  1.29,  0.  ],\n",
      "       [-1.63, -0.09,  1.  ],\n",
      "       [-6.45, -1.53,  0.  ],\n",
      "       [-2.54, -0.79,  1.  ],\n",
      "       [-3.48, -1.5 ,  1.  ]])\n",
      "--------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n",
      "--------------------------\n",
      "Layerno: 4\n",
      "Time 48.056383\n",
      "Time per LP neuron 0.480564\n",
      "LP used on 100 neurons.\n",
      "Median tigthness of hat bounds: 8.857419 \n",
      "\n",
      "Min tigthness of hat bounds: 4.511966 \n",
      "\n",
      "Max tigthness of hat bounds: 14.479289 \n",
      "\n",
      "[LB_hat | UB_hat | use_LP]\n",
      "array([[ -6.29,  -0.75,   1.  ],\n",
      "       [ -2.25,   2.26,   1.  ],\n",
      "       [ -3.1 ,   1.85,   1.  ],\n",
      "       [ -5.11,   0.23,   1.  ],\n",
      "       [ -4.89,   8.01,   0.  ],\n",
      "       [ -7.92,   4.6 ,   0.  ],\n",
      "       [ -7.69,   4.03,   0.  ],\n",
      "       [ -5.52,  -0.19,   1.  ],\n",
      "       [ -3.99,   1.33,   1.  ],\n",
      "       [ -2.08,   2.94,   1.  ],\n",
      "       [-10.84,   2.5 ,   0.  ],\n",
      "       [ -9.48,   2.61,   0.  ],\n",
      "       [ -4.5 ,   1.42,   1.  ],\n",
      "       [ -3.93,   0.74,   1.  ],\n",
      "       [ -8.19,   4.92,   0.  ],\n",
      "       [  0.22,   6.13,   1.  ],\n",
      "       [ -5.33,   8.22,   0.  ],\n",
      "       [ -2.82,   1.87,   1.  ],\n",
      "       [  1.43,   7.71,   1.  ],\n",
      "       [ -6.94,   4.65,   0.  ],\n",
      "       [ -6.58,   5.87,   0.  ],\n",
      "       [ -8.13,  -1.02,   1.  ],\n",
      "       [  0.38,   6.5 ,   1.  ],\n",
      "       [ -4.4 ,   1.16,   1.  ],\n",
      "       [ -5.27,   6.58,   0.  ],\n",
      "       [ -8.57,   5.58,   0.  ],\n",
      "       [ -2.4 ,   2.73,   1.  ],\n",
      "       [ -9.45,   3.29,   0.  ],\n",
      "       [ -3.03,   1.72,   1.  ],\n",
      "       [ -3.08,   1.64,   1.  ],\n",
      "       [ -6.33,  -0.79,   1.  ],\n",
      "       [ -3.77,   1.5 ,   1.  ],\n",
      "       [ -6.69,   5.17,   0.  ],\n",
      "       [ -4.82,   0.73,   1.  ],\n",
      "       [ -4.58,   0.73,   1.  ],\n",
      "       [ -8.62,   3.97,   0.  ],\n",
      "       [ -4.26,   1.06,   1.  ],\n",
      "       [ -3.27,   9.22,   0.  ],\n",
      "       [ -8.42,   4.93,   0.  ],\n",
      "       [ -8.06,   3.16,   0.  ],\n",
      "       [-10.77,   2.93,   0.  ],\n",
      "       [ -7.85,   4.05,   0.  ],\n",
      "       [ -3.55,   1.46,   1.  ],\n",
      "       [ -5.94,  -0.22,   1.  ],\n",
      "       [ -8.43,   4.55,   0.  ],\n",
      "       [ -6.21,  -0.67,   1.  ],\n",
      "       [ -5.14,   7.84,   0.  ],\n",
      "       [ -8.73,   4.42,   0.  ],\n",
      "       [ -8.66,   3.39,   0.  ],\n",
      "       [ -3.28,   1.79,   1.  ],\n",
      "       [ -5.31,   0.76,   1.  ],\n",
      "       [ -9.79,   3.01,   0.  ],\n",
      "       [ -5.53,   0.02,   1.  ],\n",
      "       [-10.75,   3.25,   0.  ],\n",
      "       [ -8.35,   5.31,   0.  ],\n",
      "       [ -4.12,   1.07,   1.  ],\n",
      "       [ -3.77,   1.35,   1.  ],\n",
      "       [ -7.61,   6.01,   0.  ],\n",
      "       [ -9.95,   3.03,   0.  ],\n",
      "       [ -9.68,   3.34,   0.  ],\n",
      "       [ -2.4 ,   3.27,   1.  ],\n",
      "       [ -3.  ,   1.94,   1.  ],\n",
      "       [ -8.12,   5.1 ,   0.  ],\n",
      "       [ -8.36,   4.14,   0.  ],\n",
      "       [ -9.14,   4.42,   0.  ],\n",
      "       [ -4.02,   1.54,   1.  ],\n",
      "       [ -8.77,   4.47,   0.  ],\n",
      "       [ -2.67,   1.96,   1.  ],\n",
      "       [ -8.71,   3.04,   0.  ],\n",
      "       [ -5.07,   7.68,   0.  ],\n",
      "       [ -2.97,   2.29,   1.  ],\n",
      "       [ -7.21,   5.97,   0.  ],\n",
      "       [ -3.81,   8.94,   0.  ],\n",
      "       [ -5.67,  -0.25,   1.  ],\n",
      "       [ -5.41,   6.12,   0.  ],\n",
      "       [ -5.94,   7.67,   0.  ],\n",
      "       [ -6.57,   5.75,   0.  ],\n",
      "       [ -1.94,   3.09,   1.  ],\n",
      "       [ -6.21,   6.09,   0.  ],\n",
      "       [ -8.9 ,   2.88,   0.  ],\n",
      "       [ -1.87,   3.07,   1.  ],\n",
      "       [ -3.66,   1.89,   1.  ],\n",
      "       [ -6.27,   5.32,   0.  ],\n",
      "       [  0.12,   6.52,   1.  ],\n",
      "       [ -2.42,   2.74,   1.  ],\n",
      "       [  0.63,   7.11,   1.  ],\n",
      "       [ -3.09,   2.42,   1.  ],\n",
      "       [ -7.78,   5.52,   0.  ],\n",
      "       [ -2.46,   3.29,   1.  ],\n",
      "       [ -6.4 ,   6.61,   0.  ],\n",
      "       [ -4.31,   1.19,   1.  ],\n",
      "       [ -7.94,   5.08,   0.  ],\n",
      "       [ -4.21,   0.89,   1.  ],\n",
      "       [ -7.91,   5.17,   0.  ],\n",
      "       [ -5.4 ,   0.47,   1.  ],\n",
      "       [ -4.28,   1.04,   1.  ],\n",
      "       [ -6.04,   6.39,   0.  ],\n",
      "       [ -3.44,   2.77,   1.  ],\n",
      "       [ -5.37,   0.24,   1.  ],\n",
      "       [ -8.89,   5.11,   0.  ],\n",
      "       [ -5.65,  -0.11,   1.  ],\n",
      "       [ -7.82,   4.67,   0.  ],\n",
      "       [-10.45,   4.03,   0.  ],\n",
      "       [ -7.65,   4.53,   0.  ],\n",
      "       [ -3.19,   2.09,   1.  ],\n",
      "       [ -3.27,   8.39,   0.  ],\n",
      "       [ -1.41,   4.38,   1.  ],\n",
      "       [ -6.23,   0.26,   1.  ],\n",
      "       [ -2.92,   1.88,   1.  ],\n",
      "       [-10.35,   3.38,   0.  ],\n",
      "       [ -6.64,   6.36,   0.  ],\n",
      "       [ -7.83,   5.14,   0.  ],\n",
      "       [ -8.92,   4.52,   0.  ],\n",
      "       [ -3.9 ,   0.78,   1.  ],\n",
      "       [ -3.66,   1.73,   1.  ],\n",
      "       [ -7.89,   5.42,   0.  ],\n",
      "       [ -6.21,   6.61,   0.  ],\n",
      "       [ -5.4 ,   8.36,   0.  ],\n",
      "       [ -8.89,   3.05,   0.  ],\n",
      "       [ -5.76,  -0.39,   1.  ],\n",
      "       [ -0.21,   5.45,   1.  ],\n",
      "       [ -4.06,   1.28,   1.  ],\n",
      "       [ -7.6 ,   3.02,   0.  ],\n",
      "       [  1.83,   7.84,   1.  ],\n",
      "       [ -7.28,   5.11,   0.  ],\n",
      "       [ -3.7 ,   2.03,   1.  ],\n",
      "       [ -9.15,   3.64,   0.  ],\n",
      "       [ -2.15,   2.56,   1.  ],\n",
      "       [ -8.78,  -2.09,   1.  ],\n",
      "       [ -5.47,   0.72,   1.  ],\n",
      "       [ -7.51,   5.42,   0.  ],\n",
      "       [ -8.45,   5.4 ,   0.  ],\n",
      "       [ -3.2 ,   1.69,   1.  ],\n",
      "       [ -9.21,   3.68,   0.  ],\n",
      "       [-11.72,   2.39,   0.  ],\n",
      "       [ -9.15,   2.77,   0.  ],\n",
      "       [ -8.71,   5.13,   0.  ],\n",
      "       [ -3.67,   1.65,   1.  ],\n",
      "       [ -5.97,   5.74,   0.  ],\n",
      "       [ -9.69,   1.63,   0.  ],\n",
      "       [ -8.  ,   4.33,   0.  ],\n",
      "       [ -4.77,   0.73,   1.  ],\n",
      "       [ -8.24,   4.98,   0.  ],\n",
      "       [ -4.51,   0.94,   1.  ],\n",
      "       [ -4.31,   0.96,   1.  ],\n",
      "       [ -7.25,  -1.22,   1.  ],\n",
      "       [ -8.87,   4.32,   0.  ],\n",
      "       [ -5.65,   7.24,   0.  ],\n",
      "       [ -7.25,   4.46,   0.  ],\n",
      "       [ -8.38,   5.22,   0.  ],\n",
      "       [ -6.26,   4.39,   0.  ],\n",
      "       [ -8.2 ,   3.43,   0.  ],\n",
      "       [ -2.89,   2.09,   1.  ],\n",
      "       [ -4.4 ,   7.71,   0.  ],\n",
      "       [ -6.14,  -0.17,   1.  ],\n",
      "       [ -6.97,   5.27,   0.  ],\n",
      "       [ -3.14,   1.69,   1.  ],\n",
      "       [ -7.68,   4.36,   0.  ],\n",
      "       [ -8.22,   3.83,   0.  ],\n",
      "       [ -6.85,  -0.97,   1.  ],\n",
      "       [ -6.86,   4.63,   0.  ],\n",
      "       [ -5.85,  -0.19,   1.  ],\n",
      "       [ -8.14,   5.23,   0.  ],\n",
      "       [ -8.76,   5.15,   0.  ],\n",
      "       [ -3.49,   1.49,   1.  ],\n",
      "       [ -8.01,   4.51,   0.  ],\n",
      "       [ -3.08,   1.65,   1.  ],\n",
      "       [ -2.74,   2.31,   1.  ],\n",
      "       [ -7.44,   5.8 ,   0.  ],\n",
      "       [ -5.67,   6.75,   0.  ],\n",
      "       [  0.49,   6.98,   1.  ],\n",
      "       [ -1.41,   3.99,   1.  ],\n",
      "       [ -6.08,   6.15,   0.  ],\n",
      "       [ -5.27,   0.84,   1.  ],\n",
      "       [ -2.05,   2.9 ,   1.  ],\n",
      "       [ -4.51,   0.87,   1.  ],\n",
      "       [ -6.1 ,   5.97,   0.  ],\n",
      "       [ -3.92,   1.08,   1.  ],\n",
      "       [ -5.05,   1.05,   1.  ],\n",
      "       [ -4.36,   1.04,   1.  ],\n",
      "       [ -6.97,   6.13,   0.  ],\n",
      "       [ -6.64,   5.09,   0.  ],\n",
      "       [ -4.07,   0.89,   1.  ],\n",
      "       [ -4.89,   0.44,   1.  ],\n",
      "       [ -3.18,   2.22,   1.  ],\n",
      "       [ -1.41,   4.04,   1.  ],\n",
      "       [ -4.54,   0.97,   1.  ],\n",
      "       [ -4.46,   8.66,   0.  ],\n",
      "       [ -6.29,   6.38,   0.  ],\n",
      "       [ -5.09,   0.7 ,   1.  ],\n",
      "       [ -5.17,   5.44,   0.  ],\n",
      "       [ -5.56,   6.87,   0.  ],\n",
      "       [ -4.29,   1.13,   1.  ],\n",
      "       [ -5.62,   7.24,   0.  ],\n",
      "       [ -2.93,   2.62,   1.  ],\n",
      "       [ -3.18,   2.34,   1.  ],\n",
      "       [ -3.09,   1.66,   1.  ],\n",
      "       [ -7.67,   4.76,   0.  ],\n",
      "       [ -1.5 ,   3.51,   1.  ],\n",
      "       [ -2.48,   2.49,   1.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n",
      "--------------------------\n",
      "Layerno: 5\n",
      "Time 101.276062\n",
      "Time per LP neuron 1.012761\n",
      "LP used on 100 neurons.\n",
      "Median tigthness of hat bounds: 37.663995 \n",
      "\n",
      "Min tigthness of hat bounds: 23.534304 \n",
      "\n",
      "Max tigthness of hat bounds: 56.581397 \n",
      "\n",
      "[LB_hat | UB_hat | use_LP]\n",
      "array([[-15.99,   8.9 ,   1.  ],\n",
      "       [-28.05,  21.86,   0.  ],\n",
      "       [-15.24,  10.61,   1.  ],\n",
      "       [-15.85,  11.01,   1.  ],\n",
      "       [-25.22,  23.11,   0.  ],\n",
      "       [-11.35,  14.38,   1.  ],\n",
      "       [-30.86,  18.25,   0.  ],\n",
      "       [-29.68,  21.03,   0.  ],\n",
      "       [-20.12,   7.69,   1.  ],\n",
      "       [-27.89,  21.66,   0.  ],\n",
      "       [-30.58,  20.64,   0.  ],\n",
      "       [-34.2 ,  16.81,   0.  ],\n",
      "       [-15.6 ,   9.25,   1.  ],\n",
      "       [-32.55,  18.91,   0.  ],\n",
      "       [-29.28,  18.07,   0.  ],\n",
      "       [-27.36,  21.85,   0.  ],\n",
      "       [-30.68,  20.53,   0.  ],\n",
      "       [-30.62,  25.96,   0.  ],\n",
      "       [-29.95,  24.78,   0.  ],\n",
      "       [-16.37,  10.47,   1.  ],\n",
      "       [-30.68,  21.24,   0.  ],\n",
      "       [-34.99,  21.01,   0.  ],\n",
      "       [-33.29,  19.99,   0.  ],\n",
      "       [-15.73,   9.56,   1.  ],\n",
      "       [-15.48,   8.27,   1.  ],\n",
      "       [-12.6 ,  11.18,   1.  ],\n",
      "       [-23.95,   7.62,   1.  ],\n",
      "       [-14.78,  12.13,   1.  ],\n",
      "       [-30.44,  19.7 ,   0.  ],\n",
      "       [-14.12,   9.75,   1.  ],\n",
      "       [-18.26,   9.55,   1.  ],\n",
      "       [-19.27,   6.67,   1.  ],\n",
      "       [-25.59,   7.18,   1.  ],\n",
      "       [-16.24,   8.31,   1.  ],\n",
      "       [-30.08,  18.97,   0.  ],\n",
      "       [-16.67,  11.92,   1.  ],\n",
      "       [-15.51,  11.06,   1.  ],\n",
      "       [-27.67,  21.67,   0.  ],\n",
      "       [-31.06,  15.6 ,   0.  ],\n",
      "       [-16.1 ,   9.8 ,   1.  ],\n",
      "       [-24.65,  23.19,   0.  ],\n",
      "       [-29.83,  19.06,   0.  ],\n",
      "       [-38.34,  16.42,   0.  ],\n",
      "       [-21.82,  28.71,   0.  ],\n",
      "       [-14.86,  12.  ,   1.  ],\n",
      "       [-27.02,  20.92,   0.  ],\n",
      "       [-11.86,  14.  ,   1.  ],\n",
      "       [-34.03,  19.46,   0.  ],\n",
      "       [-31.13,  17.  ,   0.  ],\n",
      "       [-24.87,  23.72,   0.  ],\n",
      "       [-16.92,  10.9 ,   1.  ],\n",
      "       [-15.66,  10.71,   1.  ],\n",
      "       [-18.44,   9.43,   1.  ],\n",
      "       [-21.98,   6.4 ,   1.  ],\n",
      "       [-12.37,  14.18,   1.  ],\n",
      "       [-15.66,   9.57,   1.  ],\n",
      "       [-32.89,  19.29,   0.  ],\n",
      "       [-32.13,  20.66,   0.  ],\n",
      "       [-31.4 ,  19.8 ,   0.  ],\n",
      "       [-15.47,  10.66,   1.  ],\n",
      "       [-16.66,   9.66,   1.  ],\n",
      "       [-11.19,  16.95,   1.  ],\n",
      "       [-23.06,   7.51,   1.  ],\n",
      "       [-30.5 ,  22.83,   0.  ],\n",
      "       [-11.01,  14.21,   1.  ],\n",
      "       [-27.35,  28.19,   0.  ],\n",
      "       [-11.59,  14.43,   1.  ],\n",
      "       [-14.87,  10.94,   1.  ],\n",
      "       [-27.21,  20.84,   0.  ],\n",
      "       [-37.03,  18.78,   0.  ],\n",
      "       [-19.79,   9.09,   1.  ],\n",
      "       [-24.39,  23.54,   0.  ],\n",
      "       [-16.78,  12.64,   1.  ],\n",
      "       [-37.65,  13.84,   0.  ],\n",
      "       [-28.79,  23.43,   0.  ],\n",
      "       [-14.53,  11.17,   1.  ],\n",
      "       [-15.49,   8.49,   1.  ],\n",
      "       [-14.06,  12.41,   1.  ],\n",
      "       [-15.93,  10.41,   1.  ],\n",
      "       [-13.98,  12.01,   1.  ],\n",
      "       [-15.97,  11.48,   1.  ],\n",
      "       [ -8.16,  20.32,   1.  ],\n",
      "       [-25.8 ,  22.02,   0.  ],\n",
      "       [-12.17,  12.54,   1.  ],\n",
      "       [-35.1 ,  15.14,   0.  ],\n",
      "       [-22.85,   8.33,   1.  ],\n",
      "       [-15.19,  10.88,   1.  ],\n",
      "       [-22.18,   5.86,   1.  ],\n",
      "       [-15.66,  11.18,   1.  ],\n",
      "       [-28.38,  18.85,   0.  ],\n",
      "       [-37.98,  17.48,   0.  ],\n",
      "       [-29.73,  18.4 ,   0.  ],\n",
      "       [-18.57,   6.85,   1.  ],\n",
      "       [-13.78,  12.94,   1.  ],\n",
      "       [-25.09,   4.89,   1.  ],\n",
      "       [-30.42,  22.15,   0.  ],\n",
      "       [-31.8 ,  16.09,   0.  ],\n",
      "       [-33.22,  16.94,   0.  ],\n",
      "       [-17.21,   8.74,   1.  ],\n",
      "       [-18.76,   9.35,   1.  ],\n",
      "       [-15.59,  10.9 ,   1.  ],\n",
      "       [-17.87,   9.25,   1.  ],\n",
      "       [-16.22,  12.44,   1.  ],\n",
      "       [-24.98,  23.12,   0.  ],\n",
      "       [-26.65,  15.9 ,   0.  ],\n",
      "       [-27.66,  22.48,   0.  ],\n",
      "       [-16.44,   9.15,   1.  ],\n",
      "       [-26.06,  22.36,   0.  ],\n",
      "       [-27.97,  19.14,   0.  ],\n",
      "       [-19.93,  10.06,   1.  ],\n",
      "       [-19.88,   6.15,   1.  ],\n",
      "       [-18.86,   8.75,   1.  ],\n",
      "       [-16.48,   8.67,   1.  ],\n",
      "       [-30.98,  22.96,   0.  ],\n",
      "       [-14.44,  12.67,   1.  ],\n",
      "       [-27.24,  22.44,   0.  ],\n",
      "       [-18.08,   7.73,   1.  ],\n",
      "       [-12.3 ,  14.54,   1.  ],\n",
      "       [-28.18,  25.5 ,   0.  ],\n",
      "       [-26.96,  19.9 ,   0.  ],\n",
      "       [-28.33,  22.22,   0.  ],\n",
      "       [-15.77,   9.28,   1.  ],\n",
      "       [-26.22,  23.53,   0.  ],\n",
      "       [-25.32,  25.39,   0.  ],\n",
      "       [-25.47,   4.59,   1.  ],\n",
      "       [-17.54,   9.62,   1.  ],\n",
      "       [-23.7 ,  23.04,   0.  ],\n",
      "       [-28.6 ,  26.41,   0.  ],\n",
      "       [-34.55,  20.59,   0.  ],\n",
      "       [-28.4 ,  21.44,   0.  ],\n",
      "       [-17.69,   7.35,   1.  ],\n",
      "       [-29.21,  19.56,   0.  ],\n",
      "       [-21.15,   6.19,   1.  ],\n",
      "       [-13.82,  12.27,   1.  ],\n",
      "       [-29.54,  18.46,   0.  ],\n",
      "       [-31.29,  19.63,   0.  ],\n",
      "       [-16.93,  14.85,   1.  ],\n",
      "       [-16.06,  10.36,   1.  ],\n",
      "       [-15.33,  11.45,   1.  ],\n",
      "       [-28.32,  18.11,   0.  ],\n",
      "       [-20.85,   6.56,   1.  ],\n",
      "       [-28.33,  18.21,   0.  ],\n",
      "       [-31.55,  19.44,   0.  ],\n",
      "       [-30.59,  22.08,   0.  ],\n",
      "       [-20.07,   6.41,   1.  ],\n",
      "       [-29.49,  19.29,   0.  ],\n",
      "       [-26.91,  24.35,   0.  ],\n",
      "       [-19.43,   6.92,   1.  ],\n",
      "       [-14.28,  11.22,   1.  ],\n",
      "       [-12.44,  11.09,   1.  ],\n",
      "       [-16.38,  10.74,   1.  ],\n",
      "       [-16.84,  12.23,   1.  ],\n",
      "       [-25.12,  21.9 ,   0.  ],\n",
      "       [-14.12,  14.54,   1.  ],\n",
      "       [-32.17,  20.05,   0.  ],\n",
      "       [-14.49,  11.73,   1.  ],\n",
      "       [-25.96,  21.13,   0.  ],\n",
      "       [-15.11,  10.59,   1.  ],\n",
      "       [-19.11,  11.16,   1.  ],\n",
      "       [-31.37,  19.31,   0.  ],\n",
      "       [-21.42,  26.9 ,   0.  ],\n",
      "       [-33.63,  20.72,   0.  ],\n",
      "       [-16.31,  10.51,   1.  ],\n",
      "       [-27.44,  23.94,   0.  ],\n",
      "       [-21.51,  23.54,   0.  ],\n",
      "       [-33.05,  22.55,   0.  ],\n",
      "       [-27.13,  24.89,   0.  ],\n",
      "       [-18.1 ,   7.84,   1.  ],\n",
      "       [-28.93,  22.27,   0.  ],\n",
      "       [-24.2 ,  20.23,   0.  ],\n",
      "       [-30.52,  18.18,   0.  ],\n",
      "       [-27.15,  21.58,   0.  ],\n",
      "       [-26.56,  20.52,   0.  ],\n",
      "       [-12.2 ,  14.09,   1.  ],\n",
      "       [-16.1 ,  11.44,   1.  ],\n",
      "       [-29.11,  20.35,   0.  ],\n",
      "       [-15.54,  10.4 ,   1.  ],\n",
      "       [-24.01,  18.8 ,   0.  ],\n",
      "       [-17.  ,  11.23,   1.  ],\n",
      "       [-26.71,  23.56,   0.  ],\n",
      "       [-34.33,  18.38,   0.  ],\n",
      "       [-14.43,  12.73,   1.  ],\n",
      "       [-27.34,  26.2 ,   0.  ],\n",
      "       [-13.4 ,  12.16,   1.  ],\n",
      "       [-28.16,  22.94,   0.  ],\n",
      "       [-12.85,  14.23,   1.  ],\n",
      "       [-29.13,  24.82,   0.  ],\n",
      "       [-16.96,  10.19,   1.  ],\n",
      "       [-23.68,  25.01,   0.  ],\n",
      "       [-33.89,  22.43,   0.  ],\n",
      "       [-34.22,  15.06,   0.  ],\n",
      "       [-24.28,  25.14,   0.  ],\n",
      "       [-21.26,   7.48,   1.  ],\n",
      "       [-11.82,  15.23,   1.  ],\n",
      "       [-30.04,  19.97,   0.  ],\n",
      "       [-16.67,   9.4 ,   1.  ],\n",
      "       [-16.9 ,  10.  ,   1.  ],\n",
      "       [-29.67,  20.06,   0.  ],\n",
      "       [-20.17,   5.91,   1.  ],\n",
      "       [-25.01,  21.27,   0.  ]])\n",
      "--------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n",
      "--------------------------\n",
      "Layerno: 6\n",
      "Time 111.070193\n",
      "Time per LP neuron 1.110702\n",
      "LP used on 100 neurons.\n",
      "Median tigthness of hat bounds: 197.969264 \n",
      "\n",
      "Min tigthness of hat bounds: 124.064717 \n",
      "\n",
      "Max tigthness of hat bounds: 255.218738 \n",
      "\n",
      "[LB_hat | UB_hat | use_LP]\n",
      "array([[-114.51,  100.13,    0.  ],\n",
      "       [ -86.71,   50.66,    1.  ],\n",
      "       [ -87.45,   58.1 ,    1.  ],\n",
      "       [ -72.13,   73.57,    1.  ],\n",
      "       [-108.93,  131.25,    0.  ],\n",
      "       [-135.01,   82.35,    0.  ],\n",
      "       [ -93.74,   45.96,    1.  ],\n",
      "       [ -72.46,   68.43,    1.  ],\n",
      "       [-128.96,  101.6 ,    0.  ],\n",
      "       [-133.69,  100.81,    0.  ],\n",
      "       [-127.64,  106.61,    0.  ],\n",
      "       [ -71.51,   59.04,    1.  ],\n",
      "       [-133.29,   94.97,    0.  ],\n",
      "       [-139.08,   89.17,    0.  ],\n",
      "       [-125.43,   91.38,    0.  ],\n",
      "       [ -88.9 ,   43.05,    1.  ],\n",
      "       [-141.25,   94.41,    0.  ],\n",
      "       [ -85.72,   56.09,    1.  ],\n",
      "       [-155.35,   72.69,    0.  ],\n",
      "       [ -86.77,   68.58,    1.  ],\n",
      "       [-135.38,   91.16,    0.  ],\n",
      "       [-132.94,  106.43,    0.  ],\n",
      "       [ -97.37,  110.46,    0.  ],\n",
      "       [-121.08,  108.12,    0.  ],\n",
      "       [ -64.91,   80.23,    1.  ],\n",
      "       [-152.87,   77.83,    0.  ],\n",
      "       [-119.62,  112.14,    0.  ],\n",
      "       [-138.86,   84.02,    0.  ],\n",
      "       [ -70.05,   66.54,    1.  ],\n",
      "       [-111.99,   99.5 ,    0.  ],\n",
      "       [ -86.58,   53.5 ,    1.  ],\n",
      "       [ -59.93,   71.54,    1.  ],\n",
      "       [ -80.15,   66.23,    1.  ],\n",
      "       [ -68.66,   55.41,    1.  ],\n",
      "       [-115.95,   93.63,    0.  ],\n",
      "       [ -69.99,   67.21,    1.  ],\n",
      "       [-151.31,  103.91,    0.  ],\n",
      "       [ -75.61,   66.81,    1.  ],\n",
      "       [ -73.02,   68.92,    1.  ],\n",
      "       [ -79.65,   49.  ,    1.  ],\n",
      "       [-122.44,   90.11,    0.  ],\n",
      "       [ -75.86,   63.36,    1.  ],\n",
      "       [ -96.39,   53.65,    1.  ],\n",
      "       [ -76.32,   66.46,    1.  ],\n",
      "       [ -98.36,   42.42,    1.  ],\n",
      "       [-136.38,   87.84,    0.  ],\n",
      "       [ -87.86,   47.68,    1.  ],\n",
      "       [-117.21,  100.9 ,    0.  ],\n",
      "       [-144.93,   87.36,    0.  ],\n",
      "       [-138.54,   93.04,    0.  ],\n",
      "       [ -73.85,   53.65,    1.  ],\n",
      "       [ -81.41,   72.84,    1.  ],\n",
      "       [-107.03,   53.7 ,    1.  ],\n",
      "       [-123.77,   80.33,    0.  ],\n",
      "       [-145.26,   85.51,    0.  ],\n",
      "       [-130.77,   91.13,    0.  ],\n",
      "       [ -69.47,   62.06,    1.  ],\n",
      "       [-113.14,  107.2 ,    0.  ],\n",
      "       [-145.71,   99.36,    0.  ],\n",
      "       [ -83.35,   48.83,    1.  ],\n",
      "       [-100.82,   47.08,    1.  ],\n",
      "       [ -66.32,   65.45,    1.  ],\n",
      "       [ -79.7 ,   74.58,    1.  ],\n",
      "       [ -81.81,   52.76,    1.  ],\n",
      "       [-123.77,  105.86,    0.  ],\n",
      "       [ -73.95,   68.71,    1.  ],\n",
      "       [-145.7 ,   88.3 ,    0.  ],\n",
      "       [-116.93,  105.14,    0.  ],\n",
      "       [-112.76,  106.17,    0.  ],\n",
      "       [-144.86,   79.69,    0.  ],\n",
      "       [-118.39,   91.8 ,    0.  ],\n",
      "       [-137.66,   89.67,    0.  ],\n",
      "       [ -84.61,   68.9 ,    1.  ],\n",
      "       [-122.66,   55.53,    1.  ],\n",
      "       [-149.13,   86.54,    0.  ],\n",
      "       [ -70.79,   70.2 ,    1.  ],\n",
      "       [ -71.47,   73.36,    1.  ],\n",
      "       [-148.82,   97.48,    0.  ],\n",
      "       [-148.81,  104.34,    0.  ],\n",
      "       [-129.35,  103.53,    0.  ],\n",
      "       [-115.3 ,  115.98,    0.  ],\n",
      "       [-133.84,  108.75,    0.  ],\n",
      "       [-113.62,  109.03,    0.  ],\n",
      "       [-106.71,  113.08,    0.  ],\n",
      "       [ -58.06,   81.62,    1.  ],\n",
      "       [ -77.02,   62.4 ,    1.  ],\n",
      "       [ -81.06,   63.44,    1.  ],\n",
      "       [-133.08,  107.66,    0.  ],\n",
      "       [-115.65,  110.77,    0.  ],\n",
      "       [ -78.51,   50.44,    1.  ],\n",
      "       [ -92.46,   52.9 ,    1.  ],\n",
      "       [-171.96,   82.14,    0.  ],\n",
      "       [-128.75,   91.62,    0.  ],\n",
      "       [-124.12,   94.73,    0.  ],\n",
      "       [-118.21,  111.54,    0.  ],\n",
      "       [ -71.09,   64.5 ,    1.  ],\n",
      "       [ -68.28,   69.18,    1.  ],\n",
      "       [ -68.92,   59.67,    1.  ],\n",
      "       [-133.44,  102.26,    0.  ],\n",
      "       [-103.51,  118.99,    0.  ],\n",
      "       [ -81.86,   61.23,    1.  ],\n",
      "       [-126.31,  110.7 ,    0.  ],\n",
      "       [-120.28,   90.31,    0.  ],\n",
      "       [ -83.44,   70.27,    1.  ],\n",
      "       [-102.15,   76.69,    1.  ],\n",
      "       [-107.82,   64.82,    1.  ],\n",
      "       [ -77.7 ,   63.47,    1.  ],\n",
      "       [-115.7 ,  101.94,    0.  ],\n",
      "       [-129.47,   99.75,    0.  ],\n",
      "       [ -66.47,   72.73,    1.  ],\n",
      "       [-125.41,  105.14,    0.  ],\n",
      "       [ -91.93,   57.93,    1.  ],\n",
      "       [-121.16,  103.33,    0.  ],\n",
      "       [-150.83,   71.75,    0.  ],\n",
      "       [-108.81,   55.93,    1.  ],\n",
      "       [ -69.19,   72.89,    1.  ],\n",
      "       [-146.55,  104.12,    0.  ],\n",
      "       [ -74.93,   66.61,    1.  ],\n",
      "       [-129.86,   82.77,    0.  ],\n",
      "       [-144.52,   94.41,    0.  ],\n",
      "       [-122.58,  102.27,    0.  ],\n",
      "       [-117.21,  106.95,    0.  ],\n",
      "       [ -75.53,   68.2 ,    1.  ],\n",
      "       [ -67.08,   73.71,    1.  ],\n",
      "       [ -83.97,   52.78,    1.  ],\n",
      "       [ -89.25,   54.53,    1.  ],\n",
      "       [ -78.58,   65.7 ,    1.  ],\n",
      "       [ -65.64,   84.44,    1.  ],\n",
      "       [ -84.84,   49.69,    1.  ],\n",
      "       [ -66.97,   74.11,    1.  ],\n",
      "       [ -72.1 ,   63.84,    1.  ],\n",
      "       [-101.4 ,   53.74,    1.  ],\n",
      "       [ -93.26,   51.39,    1.  ],\n",
      "       [-143.7 ,   96.86,    0.  ],\n",
      "       [-126.58,   97.64,    0.  ],\n",
      "       [-155.56,   93.46,    0.  ],\n",
      "       [-108.64,   46.9 ,    1.  ],\n",
      "       [ -93.05,   59.65,    1.  ],\n",
      "       [ -81.3 ,   51.77,    1.  ],\n",
      "       [-140.85,  104.14,    0.  ],\n",
      "       [ -65.66,   70.98,    1.  ],\n",
      "       [-124.12,   99.75,    0.  ],\n",
      "       [ -59.25,   73.39,    1.  ],\n",
      "       [-107.28,  112.15,    0.  ],\n",
      "       [-142.84,   82.36,    0.  ],\n",
      "       [-103.81,   49.7 ,    1.  ],\n",
      "       [-140.83,   79.85,    0.  ],\n",
      "       [ -63.61,   75.33,    1.  ],\n",
      "       [ -79.58,   48.87,    1.  ],\n",
      "       [-109.83,   98.57,    0.  ],\n",
      "       [ -61.65,   75.53,    1.  ],\n",
      "       [ -59.27,   70.28,    1.  ],\n",
      "       [-148.52,   87.32,    0.  ],\n",
      "       [ -81.19,   72.76,    1.  ],\n",
      "       [-131.94,  106.85,    0.  ],\n",
      "       [-131.58,  100.84,    0.  ],\n",
      "       [ -72.22,   63.15,    1.  ],\n",
      "       [-119.04,  100.15,    0.  ],\n",
      "       [-105.49,   46.84,    1.  ],\n",
      "       [ -80.56,   59.77,    1.  ],\n",
      "       [-144.71,   93.11,    0.  ],\n",
      "       [ -78.25,   62.09,    1.  ],\n",
      "       [-135.4 ,   81.15,    0.  ],\n",
      "       [-125.27,   86.1 ,    0.  ],\n",
      "       [-147.95,   46.12,    1.  ],\n",
      "       [-146.12,   89.6 ,    0.  ],\n",
      "       [-125.76,  103.95,    0.  ],\n",
      "       [ -69.55,   72.91,    1.  ],\n",
      "       [-129.64,   90.15,    0.  ],\n",
      "       [ -74.32,   68.63,    1.  ],\n",
      "       [-128.53,  119.39,    0.  ],\n",
      "       [-127.84,   79.28,    0.  ],\n",
      "       [-137.22,   86.71,    0.  ],\n",
      "       [-101.84,   56.9 ,    1.  ],\n",
      "       [ -75.55,   71.01,    1.  ],\n",
      "       [-155.25,   85.62,    0.  ],\n",
      "       [-134.32,  111.75,    0.  ],\n",
      "       [-111.49,   50.65,    1.  ],\n",
      "       [-148.47,   83.55,    0.  ],\n",
      "       [ -93.43,   48.39,    1.  ],\n",
      "       [ -95.77,   49.65,    1.  ],\n",
      "       [-136.19,  107.89,    0.  ],\n",
      "       [-156.73,   74.95,    0.  ],\n",
      "       [-149.26,   89.55,    0.  ],\n",
      "       [ -77.37,   68.58,    1.  ],\n",
      "       [ -85.4 ,   55.07,    1.  ],\n",
      "       [ -83.74,   49.06,    1.  ],\n",
      "       [ -76.86,   54.38,    1.  ],\n",
      "       [ -62.13,   70.26,    1.  ],\n",
      "       [-120.61,   95.58,    0.  ],\n",
      "       [ -73.13,   60.74,    1.  ],\n",
      "       [ -96.18,   54.06,    1.  ],\n",
      "       [-139.74,   92.  ,    0.  ],\n",
      "       [-122.42,   79.45,    0.  ],\n",
      "       [ -74.67,   49.4 ,    1.  ],\n",
      "       [ -91.76,   43.95,    1.  ],\n",
      "       [-132.39,   95.06,    0.  ],\n",
      "       [-137.77,  100.08,    0.  ],\n",
      "       [ -74.44,   70.13,    1.  ],\n",
      "       [-134.65,   88.98,    0.  ]])\n",
      "--------------------------\n",
      "\n",
      "[Network] Input pixels: 200\n",
      "[Network] Shape of weights: (200, 200)\n",
      "[Network] Shape of biases: (200,)\n",
      "[Network] Out pixels: 200\n",
      "--------------------------\n",
      "Layerno: 7\n",
      "Time 178.189862\n",
      "Time per LP neuron 1.781899\n",
      "LP used on 100 neurons.\n",
      "Median tigthness of hat bounds: 958.210260 \n",
      "\n",
      "Min tigthness of hat bounds: 632.172910 \n",
      "\n",
      "Max tigthness of hat bounds: 1401.439422 \n",
      "\n",
      "[LB_hat | UB_hat | use_LP]\n",
      "array([[-6.85640e+02,  4.59050e+02,  0.00000e+00],\n",
      "       [-3.78600e+02,  3.57080e+02,  1.00000e+00],\n",
      "       [-4.78390e+02,  2.30620e+02,  1.00000e+00],\n",
      "       [-5.40660e+02,  3.04590e+02,  1.00000e+00],\n",
      "       [-4.04290e+02,  3.40460e+02,  1.00000e+00],\n",
      "       [-4.62560e+02,  2.86010e+02,  1.00000e+00],\n",
      "       [-4.67090e+02,  2.04830e+02,  1.00000e+00],\n",
      "       [-7.23940e+02,  4.94940e+02,  0.00000e+00],\n",
      "       [-4.08680e+02,  3.02220e+02,  1.00000e+00],\n",
      "       [-4.06150e+02,  2.70660e+02,  1.00000e+00],\n",
      "       [-7.09270e+02,  3.99650e+02,  0.00000e+00],\n",
      "       [-5.70920e+02,  5.49000e+02,  0.00000e+00],\n",
      "       [-9.13430e+02,  3.35750e+02,  0.00000e+00],\n",
      "       [-4.82800e+02,  2.30100e+02,  1.00000e+00],\n",
      "       [-7.30130e+02,  5.38810e+02,  0.00000e+00],\n",
      "       [-3.06300e+02,  3.68990e+02,  1.00000e+00],\n",
      "       [-7.93830e+02,  4.33540e+02,  0.00000e+00],\n",
      "       [-3.76700e+02,  3.43440e+02,  1.00000e+00],\n",
      "       [-5.93780e+02,  3.18890e+02,  1.00000e+00],\n",
      "       [-6.69270e+02,  2.28440e+02,  1.00000e+00],\n",
      "       [-6.18780e+02,  4.95370e+02,  0.00000e+00],\n",
      "       [-6.73470e+02,  5.10340e+02,  0.00000e+00],\n",
      "       [-7.07560e+02,  4.30110e+02,  0.00000e+00],\n",
      "       [-7.98290e+02,  4.34650e+02,  0.00000e+00],\n",
      "       [-3.97510e+02,  2.72390e+02,  1.00000e+00],\n",
      "       [-7.81670e+02,  4.46110e+02,  0.00000e+00],\n",
      "       [-4.04620e+02,  2.81820e+02,  1.00000e+00],\n",
      "       [-7.90630e+02,  4.09240e+02,  0.00000e+00],\n",
      "       [-4.91890e+02,  2.60910e+02,  1.00000e+00],\n",
      "       [-7.18700e+02,  4.54790e+02,  0.00000e+00],\n",
      "       [-4.59010e+02,  2.53700e+02,  1.00000e+00],\n",
      "       [-4.02760e+02,  3.25860e+02,  1.00000e+00],\n",
      "       [-5.46220e+02,  2.31530e+02,  1.00000e+00],\n",
      "       [-7.28930e+02,  4.12520e+02,  0.00000e+00],\n",
      "       [-7.78010e+02,  4.78610e+02,  0.00000e+00],\n",
      "       [-4.26270e+02,  3.53160e+02,  1.00000e+00],\n",
      "       [-7.15490e+02,  4.94460e+02,  0.00000e+00],\n",
      "       [-5.02430e+02,  2.02410e+02,  1.00000e+00],\n",
      "       [-6.80200e+02,  4.99980e+02,  0.00000e+00],\n",
      "       [-4.17530e+02,  2.91950e+02,  1.00000e+00],\n",
      "       [-4.88210e+02,  2.42270e+02,  1.00000e+00],\n",
      "       [-7.65360e+02,  4.82300e+02,  0.00000e+00],\n",
      "       [-5.87350e+02,  4.63430e+02,  0.00000e+00],\n",
      "       [-6.40090e+02,  5.13290e+02,  0.00000e+00],\n",
      "       [-4.86330e+02,  3.20920e+02,  1.00000e+00],\n",
      "       [-6.58510e+02,  2.14590e+02,  1.00000e+00],\n",
      "       [-4.93060e+02,  2.86560e+02,  1.00000e+00],\n",
      "       [-7.63920e+02,  3.96300e+02,  0.00000e+00],\n",
      "       [-6.98630e+02,  4.01550e+02,  0.00000e+00],\n",
      "       [-7.02750e+02,  4.17350e+02,  0.00000e+00],\n",
      "       [-6.92120e+02,  3.95930e+02,  0.00000e+00],\n",
      "       [-6.38520e+02,  3.65240e+02,  0.00000e+00],\n",
      "       [-7.15730e+02,  4.27320e+02,  0.00000e+00],\n",
      "       [-5.25380e+02,  2.21650e+02,  1.00000e+00],\n",
      "       [-5.85000e+02,  2.84280e+02,  1.00000e+00],\n",
      "       [-3.78610e+02,  2.95110e+02,  1.00000e+00],\n",
      "       [-8.93410e+02,  4.04300e+02,  0.00000e+00],\n",
      "       [-8.23260e+02,  3.93900e+02,  0.00000e+00],\n",
      "       [-5.27900e+02,  3.49740e+02,  1.00000e+00],\n",
      "       [-4.32940e+02,  2.94830e+02,  1.00000e+00],\n",
      "       [-6.57150e+02,  5.77080e+02,  0.00000e+00],\n",
      "       [-6.32270e+02,  5.09010e+02,  0.00000e+00],\n",
      "       [-6.24430e+02,  4.82500e+02,  0.00000e+00],\n",
      "       [-4.61520e+02,  3.02100e+02,  1.00000e+00],\n",
      "       [-6.10430e+02,  4.86710e+02,  0.00000e+00],\n",
      "       [-7.26390e+02,  5.78900e+02,  0.00000e+00],\n",
      "       [-4.70880e+02,  2.16010e+02,  1.00000e+00],\n",
      "       [-4.37310e+02,  3.78770e+02,  1.00000e+00],\n",
      "       [-5.23840e+02,  4.88710e+02,  0.00000e+00],\n",
      "       [-5.83700e+02,  2.17500e+02,  1.00000e+00],\n",
      "       [-4.20890e+02,  3.15820e+02,  1.00000e+00],\n",
      "       [-4.29510e+02,  2.87280e+02,  1.00000e+00],\n",
      "       [-4.40240e+02,  3.14520e+02,  1.00000e+00],\n",
      "       [-5.50840e+02,  2.25740e+02,  1.00000e+00],\n",
      "       [-5.89000e+02,  2.85870e+02,  1.00000e+00],\n",
      "       [-6.43410e+02,  5.63510e+02,  0.00000e+00],\n",
      "       [-6.07270e+02,  5.25030e+02,  0.00000e+00],\n",
      "       [-8.53660e+02,  4.12790e+02,  0.00000e+00],\n",
      "       [-7.75830e+02,  5.37600e+02,  0.00000e+00],\n",
      "       [-5.65770e+02,  2.92530e+02,  1.00000e+00],\n",
      "       [-4.17070e+02,  2.83810e+02,  1.00000e+00],\n",
      "       [-9.49260e+02,  3.43880e+02,  0.00000e+00],\n",
      "       [-4.96550e+02,  3.03760e+02,  1.00000e+00],\n",
      "       [-6.95610e+02,  4.88970e+02,  0.00000e+00],\n",
      "       [-4.19590e+02,  2.49010e+02,  1.00000e+00],\n",
      "       [-3.86180e+02,  2.77230e+02,  1.00000e+00],\n",
      "       [-5.93260e+02,  4.84900e+02,  0.00000e+00],\n",
      "       [-1.09513e+03,  2.77440e+02,  0.00000e+00],\n",
      "       [-7.44460e+02,  4.63180e+02,  0.00000e+00],\n",
      "       [-6.23320e+02,  6.06310e+02,  0.00000e+00],\n",
      "       [-6.73130e+02,  4.87670e+02,  0.00000e+00],\n",
      "       [-6.67290e+02,  4.18600e+02,  0.00000e+00],\n",
      "       [-4.56380e+02,  2.77690e+02,  1.00000e+00],\n",
      "       [-3.35340e+02,  2.99530e+02,  1.00000e+00],\n",
      "       [-6.22940e+02,  5.68300e+02,  0.00000e+00],\n",
      "       [-4.21190e+02,  2.95230e+02,  1.00000e+00],\n",
      "       [-6.59980e+02,  4.85410e+02,  0.00000e+00],\n",
      "       [-7.75360e+02,  4.59720e+02,  0.00000e+00],\n",
      "       [-4.29190e+02,  2.13670e+02,  1.00000e+00],\n",
      "       [-4.56070e+02,  2.86320e+02,  1.00000e+00],\n",
      "       [-3.38220e+02,  3.81470e+02,  1.00000e+00],\n",
      "       [-7.34880e+02,  3.95420e+02,  0.00000e+00],\n",
      "       [-4.54900e+02,  2.53370e+02,  1.00000e+00],\n",
      "       [-4.01980e+02,  3.28910e+02,  1.00000e+00],\n",
      "       [-6.17590e+02,  5.00130e+02,  0.00000e+00],\n",
      "       [-6.33120e+02,  5.04430e+02,  0.00000e+00],\n",
      "       [-7.00520e+02,  5.56070e+02,  0.00000e+00],\n",
      "       [-4.10080e+02,  3.24320e+02,  1.00000e+00],\n",
      "       [-8.03520e+02,  4.07380e+02,  0.00000e+00],\n",
      "       [-5.63610e+02,  5.43110e+02,  0.00000e+00],\n",
      "       [-3.96980e+02,  3.25510e+02,  1.00000e+00],\n",
      "       [-3.48940e+02,  4.32400e+02,  1.00000e+00],\n",
      "       [-7.26260e+02,  3.60000e+02,  0.00000e+00],\n",
      "       [-4.62350e+02,  3.46750e+02,  1.00000e+00],\n",
      "       [-7.71370e+02,  4.62620e+02,  0.00000e+00],\n",
      "       [-4.49880e+02,  2.35290e+02,  1.00000e+00],\n",
      "       [-5.78720e+02,  2.05600e+02,  1.00000e+00],\n",
      "       [-7.28900e+02,  4.82830e+02,  0.00000e+00],\n",
      "       [-4.59590e+02,  2.44190e+02,  1.00000e+00],\n",
      "       [-7.09540e+02,  4.82880e+02,  0.00000e+00],\n",
      "       [-3.22490e+02,  3.31750e+02,  1.00000e+00],\n",
      "       [-7.49890e+02,  5.05170e+02,  0.00000e+00],\n",
      "       [-4.22380e+02,  3.07340e+02,  1.00000e+00],\n",
      "       [-5.72010e+02,  5.57060e+02,  0.00000e+00],\n",
      "       [-6.58310e+02,  5.19180e+02,  0.00000e+00],\n",
      "       [-6.19730e+02,  2.45430e+02,  1.00000e+00],\n",
      "       [-9.75990e+02,  3.90620e+02,  0.00000e+00],\n",
      "       [-6.02490e+02,  4.86460e+02,  0.00000e+00],\n",
      "       [-6.58020e+02,  4.93230e+02,  0.00000e+00],\n",
      "       [-6.15020e+02,  5.95680e+02,  0.00000e+00],\n",
      "       [-3.81500e+02,  3.51180e+02,  1.00000e+00],\n",
      "       [-6.72580e+02,  4.79200e+02,  0.00000e+00],\n",
      "       [-6.99590e+02,  3.97600e+02,  0.00000e+00],\n",
      "       [-5.83400e+02,  5.64530e+02,  0.00000e+00],\n",
      "       [-6.35850e+02,  5.48190e+02,  0.00000e+00],\n",
      "       [-3.35140e+02,  2.97030e+02,  1.00000e+00],\n",
      "       [-6.85630e+02,  4.76240e+02,  0.00000e+00],\n",
      "       [-6.24690e+02,  4.96710e+02,  0.00000e+00],\n",
      "       [-3.63380e+02,  3.93780e+02,  1.00000e+00],\n",
      "       [-3.10240e+02,  3.93020e+02,  1.00000e+00],\n",
      "       [-3.60200e+02,  3.02680e+02,  1.00000e+00],\n",
      "       [-8.52330e+02,  4.25830e+02,  0.00000e+00],\n",
      "       [-6.75230e+02,  4.68710e+02,  0.00000e+00],\n",
      "       [-5.41530e+02,  2.44060e+02,  1.00000e+00],\n",
      "       [-6.74000e+02,  4.54970e+02,  0.00000e+00],\n",
      "       [-4.98220e+02,  1.97330e+02,  1.00000e+00],\n",
      "       [-4.61710e+02,  2.29770e+02,  1.00000e+00],\n",
      "       [-6.42840e+02,  5.29480e+02,  0.00000e+00],\n",
      "       [-8.04670e+02,  5.08110e+02,  0.00000e+00],\n",
      "       [-7.40290e+02,  5.46910e+02,  0.00000e+00],\n",
      "       [-6.90130e+02,  4.82860e+02,  0.00000e+00],\n",
      "       [-3.58330e+02,  3.60700e+02,  1.00000e+00],\n",
      "       [-5.51840e+02,  2.46450e+02,  1.00000e+00],\n",
      "       [-4.53220e+02,  2.96350e+02,  1.00000e+00],\n",
      "       [-4.93370e+02,  5.71690e+02,  0.00000e+00],\n",
      "       [-6.39820e+02,  4.85990e+02,  0.00000e+00],\n",
      "       [-3.79110e+02,  3.01720e+02,  1.00000e+00],\n",
      "       [-6.73940e+02,  4.89370e+02,  0.00000e+00],\n",
      "       [-4.43240e+02,  2.40340e+02,  1.00000e+00],\n",
      "       [-4.84200e+02,  2.86570e+02,  1.00000e+00],\n",
      "       [-5.05820e+02,  2.49470e+02,  1.00000e+00],\n",
      "       [-1.00407e+03,  3.97370e+02,  0.00000e+00],\n",
      "       [-6.46940e+02,  2.18830e+02,  1.00000e+00],\n",
      "       [-6.01730e+02,  5.04350e+02,  0.00000e+00],\n",
      "       [-4.64850e+02,  2.45900e+02,  1.00000e+00],\n",
      "       [-7.58140e+02,  4.04250e+02,  0.00000e+00],\n",
      "       [-3.67970e+02,  3.47200e+02,  1.00000e+00],\n",
      "       [-6.27380e+02,  5.18990e+02,  0.00000e+00],\n",
      "       [-4.83950e+02,  2.60210e+02,  1.00000e+00],\n",
      "       [-3.63400e+02,  3.48380e+02,  1.00000e+00],\n",
      "       [-5.14550e+02,  2.79410e+02,  1.00000e+00],\n",
      "       [-3.71840e+02,  3.39330e+02,  1.00000e+00],\n",
      "       [-6.44160e+02,  4.92440e+02,  0.00000e+00],\n",
      "       [-4.99130e+02,  2.40680e+02,  1.00000e+00],\n",
      "       [-8.04540e+02,  4.37430e+02,  0.00000e+00],\n",
      "       [-4.13460e+02,  2.93750e+02,  1.00000e+00],\n",
      "       [-5.06880e+02,  3.15980e+02,  1.00000e+00],\n",
      "       [-4.17370e+02,  3.59600e+02,  1.00000e+00],\n",
      "       [-3.66690e+02,  3.68850e+02,  1.00000e+00],\n",
      "       [-7.86130e+02,  4.41600e+02,  0.00000e+00],\n",
      "       [-5.38140e+02,  1.77440e+02,  1.00000e+00],\n",
      "       [-6.64640e+02,  4.14080e+02,  0.00000e+00],\n",
      "       [-7.15740e+02,  5.49720e+02,  0.00000e+00],\n",
      "       [-4.17020e+02,  2.94410e+02,  1.00000e+00],\n",
      "       [-5.80820e+02,  5.66240e+02,  0.00000e+00],\n",
      "       [-4.00600e+02,  3.08490e+02,  1.00000e+00],\n",
      "       [-6.36730e+02,  4.48430e+02,  0.00000e+00],\n",
      "       [-3.33280e+02,  3.89760e+02,  1.00000e+00],\n",
      "       [-7.48590e+02,  3.90020e+02,  0.00000e+00],\n",
      "       [-4.41710e+02,  2.61600e+02,  1.00000e+00],\n",
      "       [-6.12340e+02,  2.28030e+02,  1.00000e+00],\n",
      "       [-6.63410e+02,  4.38860e+02,  0.00000e+00],\n",
      "       [-5.87260e+02,  5.79640e+02,  0.00000e+00],\n",
      "       [-3.85100e+02,  3.95780e+02,  1.00000e+00],\n",
      "       [-3.93950e+02,  3.66390e+02,  1.00000e+00],\n",
      "       [-6.54420e+02,  4.41370e+02,  0.00000e+00],\n",
      "       [-4.32150e+02,  2.74020e+02,  1.00000e+00],\n",
      "       [-7.07040e+02,  4.27540e+02,  0.00000e+00],\n",
      "       [-6.42210e+02,  4.77830e+02,  0.00000e+00],\n",
      "       [-3.65080e+02,  3.42140e+02,  1.00000e+00]])\n",
      "--------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Layerno: 8\n",
      "Time 12.386755\n",
      "Time per LP neuron 1.238675\n",
      "LP used on 10 neurons.\n",
      "Median tigthness of hat bounds: 3101.921454 \n",
      "\n",
      "Min tigthness of hat bounds: 2308.694203 \n",
      "\n",
      "Max tigthness of hat bounds: 9193.431352 \n",
      "\n",
      "[LB_hat | UB_hat | use_LP]\n",
      "array([[-9.19343e+03,  0.00000e+00,  1.00000e+00],\n",
      "       [ 0.00000e+00,  2.75253e+03,  1.00000e+00],\n",
      "       [ 0.00000e+00,  3.61461e+03,  1.00000e+00],\n",
      "       [ 0.00000e+00,  3.62503e+03,  1.00000e+00],\n",
      "       [ 0.00000e+00,  3.11873e+03,  1.00000e+00],\n",
      "       [ 0.00000e+00,  2.85586e+03,  1.00000e+00],\n",
      "       [ 0.00000e+00,  3.08513e+03,  1.00000e+00],\n",
      "       [ 0.00000e+00,  2.30870e+03,  1.00000e+00],\n",
      "       [ 0.00000e+00,  3.05322e+03,  1.00000e+00],\n",
      "       [ 0.00000e+00,  3.23401e+03,  1.00000e+00]])\n",
      "--------------------------\n",
      "\n",
      "----------SUMMARY-----------\n",
      "\n",
      "Verification Margin (more positive better): -12818.452081 \n",
      "\n",
      "Margin per LP neuron (more positve is better): -18.054158\n",
      "\n",
      "Margin per second (more positve is better): -25.546375\n",
      "\n",
      "----------END SUMMARY--------\n",
      "\n",
      "Img 0 Margin (negative not verified) [Min] -12818.452081 , Time 501.771854 s\n"
     ]
    }
   ],
   "source": [
    "verbose = True\n",
    "write = True\n",
    "eps = 0.015\n",
    "\n",
    "numlayer = 9\n",
    "if numlayer == 4:\n",
    "    lp_list = [1]\n",
    "    influence_threshold = [0.5, 0.0]\n",
    "    \n",
    "if numlayer == 9 and eps>0.015:\n",
    "    lp_list = [i for i in range(1,numlayer-2)]\n",
    "    influence_threshold = [1.0, 0.0]\n",
    "else:\n",
    "    lp_list = [i for i in range(1,numlayer-1)]\n",
    "    influence_threshold = [1.0, 0.0]\n",
    "\n",
    "stats = analyse_nn_and_write('mnist_relu_9_200', [10] , eps, lp_list, verbose=verbose, write=write,\n",
    "                             influence_threshold=[0.5, 0.0])\n",
    "\n",
    "for img_nr, st in enumerate(stats):\n",
    "    print(\"Img %d Margin (negative not verified) [Min] %2f , Time %3f s\" %(img_nr, st['margin'][-1],\n",
    "                                                                                  sum(st['time'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_submission(LB_N0, UB_N0, nn, label, epsilon, verbose=False):\n",
    "    \"\"\"\n",
    "    Analyse neural network an return if it can be verified or not.\n",
    "    INPUT:\n",
    "        - LB_N0: Lower Bound of perturbed image input\n",
    "        - UB_N0: Upper Bound of perturbed image input\n",
    "        - nn: Preloaded neural network\n",
    "        - label: True predicted label of unperturbed image\n",
    "        - epsilon: Perturbation\n",
    "    OUTPUT:\n",
    "        - verified_flag: Verification flag. True if network was verified against perturbation.\n",
    "    \"\"\"\n",
    "    final_submission = False\n",
    "    save_stats=True\n",
    "    if final_submission:\n",
    "        save_stats=False\n",
    "        \n",
    "    # You heuristics come here:\n",
    "    numlayer = nn.numlayer\n",
    "    if numlayer == 4:\n",
    "        lp_list = [1]\n",
    "        influence_threshold = [0.5, 0.0]\n",
    "    else:\n",
    "        lp_list = [i for i in range(1,numlayer-1)]\n",
    "        influence_threshold = [1.0, 0.0]\n",
    "\n",
    "    # Get Bounds\n",
    "    LB_hidden_box_list, UB_hidden_box_list, LB_NN, UB_NN = perform_box_analysis(nn, LB_N0, UB_N0, verbose = False)\n",
    "    LB_NN, UB_NN, stats = perform_linear_layerwise(nn, numlayer, LB_N0, UB_N0, lp_list,\n",
    "                                               LB_hidden_box_list, UB_hidden_box_list, label, verbose=verbose, \n",
    "                                               save_stats=save_stats, influence_threshold=influence_threshold)\n",
    "    \n",
    "    if not final_submission:\n",
    "        print(\"Margin Final Layer: %3f\" % stats['margin'][-1])\n",
    "    \n",
    "    # Check if NN was verified\n",
    "    _, verified_flag = verify_network(LB_N0, UB_N0, LB_NN, UB_NN, label, num_input_pixels = len(LB_N0), num_out_pixels = 10)\n",
    "    \n",
    "    \n",
    "    return verified_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if __name__ == '__main__':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "#     from sys import argv\n",
    "    if len(argv) < 3 or len(argv) > 4:\n",
    "        print('usage: python3.6 ' + argv[0] + ' net.txt spec.txt [timeout]')\n",
    "        exit(1)\n",
    "\n",
    "    net_path = argv[1]\n",
    "    img_path = argv[2]\n",
    "    epsilon = float(argv[3])\n",
    "    #c_label = int(argv[4])\n",
    "    verbose = False\n",
    "    \n",
    "    # Load NN and perturbe image\n",
    "    LB_N0, UB_N0, nn, label, flag_wrong_label = load_nn(net_path, img_path, epsilon)\n",
    "    start = time.time()\n",
    "    \n",
    "    if not flag_wrong_label:\n",
    "        verified_flag = analyse_submission(LB_N0, UB_N0, nn, label, epsilon, verbose=verbose)\n",
    "        if(verified_flag):\n",
    "            print(\"verified\")\n",
    "        else:\n",
    "            print(\"can not be verified\")  \n",
    "        \n",
    "    else:\n",
    "        print(\"image not correctly classified by the network. expected label \",int(x0_low[0]), \" classified label: \", label)\n",
    "        end = time.time()\n",
    "        print(\"analysis time: \", (end-start), \" seconds\")\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"analysis time: \", (end-start), \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verified\n",
      "analysis time:  0.530709981918335  seconds\n"
     ]
    }
   ],
   "source": [
    "network = 'mnist_relu_6_20'\n",
    "img = 0\n",
    "eps = 0.01\n",
    "\n",
    "networkpath = '/home/riai2018/mnist_nets/' + network + '.txt'\n",
    "imgpath = '/home/riai2018/mnist_images/img' + str(img) + '.txt'\n",
    "argv = ['', networkpath, imgpath, eps]\n",
    "main(argv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
