{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../ELINA/python_interface/')\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "from elina_box import *\n",
    "from elina_interval import *\n",
    "from elina_abstract0 import *\n",
    "from elina_manager import *\n",
    "from elina_dimension import *\n",
    "from elina_scalar import *\n",
    "from elina_interval import *\n",
    "from elina_linexpr0 import *\n",
    "from elina_lincons0 import *\n",
    "import ctypes\n",
    "from ctypes.util import find_library\n",
    "from gurobipy import *\n",
    "import time\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for debugging in jupyter notebook\n",
    "from IPython.core.debugger import set_trace #TODO remove at end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "libc = CDLL(find_library('c'))\n",
    "cstdout = c_void_p.in_dll(libc, 'stdout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layers:\n",
    "    def __init__(self):\n",
    "        self.layertypes = []\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.numlayer = 0\n",
    "        self.ffn_counter = 0\n",
    "        self.rank = []\n",
    "        self.use_LP = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bias(text):\n",
    "    if len(text) < 1 or text[0] != '[':\n",
    "        raise Exception(\"expected '['\")\n",
    "    if text[-1] != ']':\n",
    "        raise Exception(\"expected ']'\")\n",
    "    v = np.array([*map(lambda x: np.double(x.strip()), text[1:-1].split(','))])\n",
    "    #return v.reshape((v.size,1))\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_vector(text):\n",
    "    if len(text) < 1 or text[0] != '[':\n",
    "        raise Exception(\"expected '['\")\n",
    "    if text[-1] != ']':\n",
    "        raise Exception(\"expected ']'\")\n",
    "    v = np.array([*map(lambda x: np.double(x.strip()), text[1:-1].split(','))])\n",
    "    return v.reshape((v.size,1))\n",
    "    #return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_split(text):\n",
    "    i = 0\n",
    "    bal = 0\n",
    "    start = 0\n",
    "    result = []\n",
    "    while i < len(text):\n",
    "        if text[i] == '[':\n",
    "            bal += 1\n",
    "        elif text[i] == ']':\n",
    "            bal -= 1\n",
    "        elif text[i] == ',' and bal == 0:\n",
    "            result.append(text[start:i])\n",
    "            start = i+1\n",
    "        i += 1\n",
    "    if start < i:\n",
    "        result.append(text[start:i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_matrix(text):\n",
    "    i = 0\n",
    "    if len(text) < 1 or text[0] != '[':\n",
    "        raise Exception(\"expected '['\")\n",
    "    if text[-1] != ']':\n",
    "        raise Exception(\"expected ']'\")\n",
    "    return np.array([*map(lambda x: parse_vector(x.strip()).flatten(), balanced_split(text[1:-1]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_net(text):\n",
    "    lines = [*filter(lambda x: len(x) != 0, text.split('\\n'))]\n",
    "    i = 0\n",
    "    res = layers()\n",
    "    while i < len(lines):\n",
    "        if lines[i] in ['ReLU', 'Affine']:\n",
    "            W = parse_matrix(lines[i+1])\n",
    "            b = parse_bias(lines[i+2])\n",
    "            res.layertypes.append(lines[i])\n",
    "            res.weights.append(W)\n",
    "            res.biases.append(b)\n",
    "            res.numlayer+= 1\n",
    "            res.rank.append(np.zeros((W.shape[0],1)))\n",
    "            res.use_LP.append(np.full((W.shape[0],1), False))\n",
    "            i += 3\n",
    "        else:\n",
    "            raise Exception('parse error: '+lines[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_spec(text):\n",
    "    text = text.replace(\"[\", \"\")\n",
    "    text = text.replace(\"]\", \"\")\n",
    "    with open('dummy', 'w') as my_file:\n",
    "        my_file.write(text)\n",
    "    data = np.genfromtxt('dummy', delimiter=',',dtype=np.double)\n",
    "    low = np.copy(data[:,0])\n",
    "    high = np.copy(data[:,1])\n",
    "    return low,high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perturbed_image(x, epsilon):\n",
    "    image = x[1:len(x)]\n",
    "    num_pixels = len(image)\n",
    "    LB_N0 = image - epsilon\n",
    "    UB_N0 = image + epsilon\n",
    "     \n",
    "    for i in range(num_pixels):\n",
    "        if(LB_N0[i] < 0):\n",
    "            LB_N0[i] = 0\n",
    "        if(UB_N0[i] > 1):\n",
    "            UB_N0[i] = 1\n",
    "    return LB_N0, UB_N0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_linexpr0(weights, bias, size):\n",
    "    linexpr0 = elina_linexpr0_alloc(ElinaLinexprDiscr.ELINA_LINEXPR_DENSE, size)\n",
    "    cst = pointer(linexpr0.contents.cst)\n",
    "    elina_scalar_set_double(cst.contents.val.scalar, bias)\n",
    "    for i in range(size):\n",
    "        elina_linexpr0_set_coeff_scalar_double(linexpr0,i,weights[i])\n",
    "    return linexpr0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(nn, LB_N0, UB_N0, label):   \n",
    "    num_pixels = len(LB_N0)\n",
    "    nn.ffn_counter = 0\n",
    "    numlayer = nn.numlayer \n",
    "    man = elina_box_manager_alloc()\n",
    "    itv = elina_interval_array_alloc(num_pixels)\n",
    "    for i in range(num_pixels):\n",
    "        elina_interval_set_double(itv[i],LB_N0[i],UB_N0[i])\n",
    "\n",
    "    ## construct input abstraction\n",
    "    element = elina_abstract0_of_box(man, 0, num_pixels, itv)\n",
    "    elina_interval_array_free(itv,num_pixels)\n",
    "    for layerno in range(numlayer):\n",
    "        if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "            weights = nn.weights[nn.ffn_counter]\n",
    "            biases = nn.biases[nn.ffn_counter]\n",
    "            dims = elina_abstract0_dimension(man,element)\n",
    "            num_in_pixels = dims.intdim + dims.realdim\n",
    "            num_out_pixels = len(weights)\n",
    "\n",
    "            dimadd = elina_dimchange_alloc(0,num_out_pixels)    \n",
    "            for i in range(num_out_pixels):\n",
    "                dimadd.contents.dim[i] = num_in_pixels\n",
    "            elina_abstract0_add_dimensions(man, True, element, dimadd, False)\n",
    "            elina_dimchange_free(dimadd)\n",
    "            np.ascontiguousarray(weights, dtype=np.double)\n",
    "            np.ascontiguousarray(biases, dtype=np.double)\n",
    "            var = num_in_pixels\n",
    "            # handle affine layer\n",
    "            for i in range(num_out_pixels):\n",
    "                tdim= ElinaDim(var)\n",
    "                linexpr0 = generate_linexpr0(weights[i],biases[i],num_in_pixels)\n",
    "                element = elina_abstract0_assign_linexpr_array(man, True, element, tdim, linexpr0, 1, None)\n",
    "                var+=1\n",
    "            dimrem = elina_dimchange_alloc(0,num_in_pixels)\n",
    "            for i in range(num_in_pixels):\n",
    "                dimrem.contents.dim[i] = i\n",
    "            elina_abstract0_remove_dimensions(man, True, element, dimrem)\n",
    "            elina_dimchange_free(dimrem)\n",
    "            # handle ReLU layer \n",
    "            if(nn.layertypes[layerno]=='ReLU'):\n",
    "                element = relu_box_layerwise(man,True,element,0, num_out_pixels)\n",
    "            nn.ffn_counter+=1 \n",
    "\n",
    "        else:\n",
    "            print(' net type not supported')\n",
    "   \n",
    "    dims = elina_abstract0_dimension(man,element)\n",
    "    output_size = dims.intdim + dims.realdim\n",
    "    # get bounds for each output neuron\n",
    "    bounds = elina_abstract0_to_box(man,element)\n",
    "\n",
    "           \n",
    "    # if epsilon is zero, try to classify else verify robustness \n",
    "    \n",
    "    verified_flag = True\n",
    "    predicted_label = 0\n",
    "    if(LB_N0[0]==UB_N0[0]):\n",
    "        for i in range(output_size):\n",
    "            inf = bounds[i].contents.inf.contents.val.dbl\n",
    "            flag = True\n",
    "            for j in range(output_size):\n",
    "                if(j!=i):\n",
    "                    sup = bounds[j].contents.sup.contents.val.dbl\n",
    "                    if(inf<=sup):\n",
    "                        flag = False\n",
    "                        break\n",
    "            if(flag):\n",
    "                predicted_label = i\n",
    "                break    \n",
    "    else:\n",
    "        inf = bounds[label].contents.inf.contents.val.dbl\n",
    "        for j in range(output_size):\n",
    "            if(j!=label):\n",
    "                sup = bounds[j].contents.sup.contents.val.dbl\n",
    "                if(inf<=sup):\n",
    "                    predicted_label = label\n",
    "                    verified_flag = False\n",
    "                    break\n",
    "\n",
    "    elina_interval_array_free(bounds,output_size)\n",
    "    elina_abstract0_free(man,element)\n",
    "    elina_manager_free(man)        \n",
    "    return predicted_label, verified_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main(netname, specname, esilon, c_label = None, method = 'box'):\n",
    "#     with open(netname, 'r') as netfile:\n",
    "#         netstring = netfile.read()\n",
    "#     with open(specname, 'r') as specfile:\n",
    "#         specstring = specfile.read()\n",
    "#     nn = parse_net(netstring)\n",
    "#     x0_low, x0_high = parse_spec(specstring)\n",
    "#     LB_N0, UB_N0 = get_perturbed_image(x0_low,0)\n",
    "    \n",
    "#     label, _ = analyze(nn,LB_N0,UB_N0,0) # Get label of unperturbed image, i.e. eps=0\n",
    "#     start = time.time()\n",
    "#     if method == 'box':\n",
    "#         if(label==int(x0_low[0])):\n",
    "#             LB_N0, UB_N0 = get_perturbed_image(x0_low,epsilon)\n",
    "#             _, verified_flag = analyze_box(nn,LB_N0,UB_N0,label)\n",
    "#             if(verified_flag):\n",
    "#                 print(\"verified\")\n",
    "#             else:\n",
    "#                 print(\"can not be verified\")  \n",
    "#         else:\n",
    "#             print(\"image not correctly classified by the network. expected label \",int(x0_low[0]), \" classified label: \", label)\n",
    "#     if method == 'linear':\n",
    "#         if(label==int(x0_low[0])):\n",
    "#             LB_N0, UB_N0 = get_perturbed_image(x0_low,epsilon)\n",
    "#             _, verified_flag = analyze_linear(nn,LB_N0,UB_N0,label)\n",
    "#             if(verified_flag):\n",
    "#                 print(\"verified\")\n",
    "#             else:\n",
    "#                 print(\"can not be verified\")  \n",
    "#         else:\n",
    "#             print(\"image not correctly classified by the network. expected label \",int(x0_low[0]), \" classified label: \", label)\n",
    "#     end = time.time()\n",
    "#     print(\"analysis time: \", (end-start), \" seconds\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_rank(nn, rank_threshold, norm=1, skip_first_layer=True, skip_last_layer=True):\n",
    "#     numlayer = nn.numlayer \n",
    "#     norms = np.zeros((nn.weights[1].shape[0], numlayer-2)) # TODO use list or similar if first and last layer are also used\n",
    "#     for layerno in range(numlayer):\n",
    "#         if skip_first_layer and layerno == 0:\n",
    "#             #TODO treat first layer\n",
    "#             continue\n",
    "#         if skip_last_layer and layerno == numlayer-1:\n",
    "#             continue\n",
    "#         if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "#             weights = nn.weights[layerno]\n",
    "#             biases = nn.biases[layerno]\n",
    "#             norms[:, layerno-1] = np.linalg.norm(weights, ord=norm, axis=1) + biases\n",
    "#         else:\n",
    "#             print(' net type not supported')\n",
    "    \n",
    "#     rank_idxs = np.argsort(-norms, axis=None)\n",
    "#     rank_idxs = rank_idxs.reshape(nn.weights[1].shape[0], int(len(rank_idxs)/ nn.weights[1].shape[0]))\n",
    "    \n",
    "#     for layerno in range(numlayer):\n",
    "#         if skip_first_layer and layerno == 0:\n",
    "#             continue\n",
    "#         if skip_last_layer and layerno == numlayer-1:\n",
    "#             continue\n",
    "#         if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "#             nn.rank[layerno] = rank_idxs[:, layerno-1]\n",
    "#             nn.use_LP[layerno] = nn.rank[layerno]  < rank_threshold\n",
    "#         else:\n",
    "#             print(' net type not supported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define operations on abstract domain using Box approximations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relu_hidden_bounds_using_box(man, weights, biases, input_LB, input_UB, num_in_pixels, verbose=False):\n",
    "    '''\n",
    "    This function calculates the bounds of a ReLU operation followed by a hidden layer. \n",
    "    INPUT:\n",
    "        - man: pointer to elina manager\n",
    "        - weights: weights of the hidden layer\n",
    "        - biases: biases of the hidden layer\n",
    "        - input_LB: lower bound of the inputs to the ReLU\n",
    "        - input_UB: upper bound of the inputs to the ReLU\n",
    "        - num_in_pixels: number of inputs to ReLU\n",
    "    \n",
    "    OUTPUT:\n",
    "        - output_LB: lower bound of the outputs from hidden layer\n",
    "        - output_UB: upper bound of the outputs from hidden layer\n",
    "        - num_out_pixels: number of outputs of hidden layer\n",
    "    '''\n",
    "    itv = elina_interval_array_alloc(num_in_pixels)\n",
    "\n",
    "    ## Populate the interval\n",
    "    for i in range(num_in_pixels):\n",
    "        elina_interval_set_double(itv[i], input_LB[i], input_UB[i])\n",
    "\n",
    "    ## construct input abstraction\n",
    "    element = elina_abstract0_of_box(man, 0, num_in_pixels, itv)\n",
    "    elina_interval_array_free(itv, num_in_pixels)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Handle ReLU Layer\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    element = relu_box_layerwise(man, True, element,0, num_in_pixels)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Handle Affine Layer\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    # calculate number of outputs\n",
    "    num_out_pixels = len(weights)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"[Network] Input pixels: \" + str(num_in_pixels))\n",
    "        print(\"[Network] Shape of weights: \" + str(np.shape(weights)))\n",
    "        print(\"[Network] Shape of biases: \" + str(np.shape(biases)))\n",
    "        print(\"[Network] Out pixels: \" + str(num_out_pixels))\n",
    "\n",
    "    # Create number of neurons in the layer and populate it\n",
    "    # with the number of inputs to each neuron in the layer\n",
    "    dimadd = elina_dimchange_alloc(0, num_out_pixels)    \n",
    "    for i in range(num_out_pixels):\n",
    "        dimadd.contents.dim[i] = num_in_pixels\n",
    "\n",
    "    # Add dimensions to an ElinaAbstract0 pointer i.e. element\n",
    "    elina_abstract0_add_dimensions(man, True, element, dimadd, False)\n",
    "    elina_dimchange_free(dimadd)\n",
    "\n",
    "    # Create the linear expression associated each neuron\n",
    "    var = num_in_pixels\n",
    "    for i in range(num_out_pixels):\n",
    "        tdim = ElinaDim(var)\n",
    "        linexpr0 = generate_linexpr0(weights[i], biases[i], num_in_pixels)\n",
    "        # Parallel assignment of several dimensions of an ElinaAbstract0 by using an ElinaLinexpr0Array\n",
    "        element = elina_abstract0_assign_linexpr_array(man, True, element, tdim, linexpr0, 1, None)\n",
    "        var += 1\n",
    "\n",
    "    # Pointer to which semantics we want to follow.\n",
    "    dimrem = elina_dimchange_alloc(0, num_in_pixels)\n",
    "    for i in range(num_in_pixels):\n",
    "        dimrem.contents.dim[i] = i\n",
    "        \n",
    "    # Remove dimensions from an ElinaAbstract0\n",
    "    elina_abstract0_remove_dimensions(man, True, element, dimrem)\n",
    "    elina_dimchange_free(dimrem)\n",
    "    \n",
    "    # get bounds for each output neuron\n",
    "    bounds = elina_abstract0_to_box(man,element)\n",
    "    \n",
    "    output_LB = np.zeros((num_out_pixels, 1), float)\n",
    "    output_UB = np.zeros((num_out_pixels, 1), float)\n",
    "    for j in range(num_out_pixels):\n",
    "        output_LB[j] = bounds[j].contents.inf.contents.val.dbl\n",
    "        output_UB[j] = bounds[j].contents.sup.contents.val.dbl\n",
    "    \n",
    "    # free out the memory allocations\n",
    "    elina_interval_array_free(bounds, num_out_pixels)\n",
    "    elina_abstract0_free(man, element)\n",
    "    \n",
    "    return output_LB, output_UB, num_out_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relu_bounds_using_box(man, input_LB, input_UB, num_in_pixels):\n",
    "    '''\n",
    "    This function calculates the bounds of a ReLU operation. \n",
    "    INPUT:\n",
    "        - man: pointer to elina manager\n",
    "        - input_LB: lower bound of the inputs to the ReLU\n",
    "        - input_UB: upper bound of the inputs to the ReLU\n",
    "        - num_in_pixels: number of inputs to ReLU\n",
    "    \n",
    "    OUTPUT:\n",
    "        - output_LB: lower bound of the outputs from ReLU layer\n",
    "        - output_UB: upper bound of the outputs from ReLU layer\n",
    "        - num_out_pixels: number of outputs of ReLI layer\n",
    "    '''\n",
    "    itv = elina_interval_array_alloc(num_in_pixels)\n",
    "\n",
    "    ## Populate the interval\n",
    "    for i in range(num_in_pixels):\n",
    "        elina_interval_set_double(itv[i], input_LB[i], input_UB[i])\n",
    "\n",
    "    ## construct input abstraction\n",
    "    element = elina_abstract0_of_box(man, 0, num_in_pixels, itv)\n",
    "    elina_interval_array_free(itv, num_in_pixels)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Handle ReLU Layer\n",
    "    # ------------------------------------------------------------------\n",
    "    num_out_pixels = num_in_pixels\n",
    "    \n",
    "    element = relu_box_layerwise(man, True, element,0, num_in_pixels)\n",
    "    \n",
    "    # get bounds for each output neuron\n",
    "    bounds = elina_abstract0_to_box(man,element)\n",
    "    \n",
    "    # get bounds for each output neuron\n",
    "    bounds = elina_abstract0_to_box(man,element)\n",
    "    \n",
    "    output_LB = np.zeros((num_out_pixels, 1), float)\n",
    "    output_UB = np.zeros((num_out_pixels, 1), float)\n",
    "    for j in range(num_out_pixels):\n",
    "        output_LB[j] = bounds[j].contents.inf.contents.val.dbl\n",
    "        output_UB[j] = bounds[j].contents.sup.contents.val.dbl\n",
    "    \n",
    "    # free out the memory allocations\n",
    "    elina_interval_array_free(bounds, num_out_pixels)\n",
    "    elina_abstract0_free(man, element)\n",
    "    \n",
    "    return output_LB, output_UB, num_out_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_bounds_using_box(man, weights, biases, input_LB, input_UB, num_in_pixels, verbose=False):\n",
    "    '''\n",
    "    This function calculates the bounds of a ReLU operation followed by a hidden layer. \n",
    "    INPUT:\n",
    "        - man: pointer to elina manager\n",
    "        - weights: weights of the hidden layer\n",
    "        - biases: biases of the hidden layer\n",
    "        - input_LB: lower bound of the inputs to the hidden layer\n",
    "        - input_UB: upper bound of the inputs to the hidden layer\n",
    "        - num_in_pixels: number of inputs to the input layer\n",
    "    \n",
    "    OUTPUT:\n",
    "        - output_LB: lower bound of the outputs from hidden layer\n",
    "        - output_UB: upper bound of the outputs from hidden layer\n",
    "        - num_out_pixels: number of outputs of hidden layer\n",
    "    '''\n",
    "    itv = elina_interval_array_alloc(num_in_pixels)\n",
    "\n",
    "    ## Populate the interval\n",
    "    for i in range(num_in_pixels):\n",
    "        elina_interval_set_double(itv[i], input_LB[i], input_UB[i])\n",
    "\n",
    "    ## construct input abstraction\n",
    "    element = elina_abstract0_of_box(man, 0, num_in_pixels, itv)\n",
    "    elina_interval_array_free(itv, num_in_pixels)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Handle Affine Layer\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    # calculate number of outputs\n",
    "    num_out_pixels = len(weights)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"[Network] Input pixels: \" + str(num_in_pixels))\n",
    "        print(\"[Network] Shape of weights: \" + str(np.shape(weights)))\n",
    "        print(\"[Network] Shape of biases: \" + str(np.shape(biases)))\n",
    "        print(\"[Network] Out pixels: \" + str(num_out_pixels))\n",
    "\n",
    "    # Create number of neurons in the layer and populate it\n",
    "    # with the number of inputs to each neuron in the layer\n",
    "    dimadd = elina_dimchange_alloc(0, num_out_pixels)    \n",
    "    for i in range(num_out_pixels):\n",
    "        dimadd.contents.dim[i] = num_in_pixels\n",
    "\n",
    "    # Add dimensions to an ElinaAbstract0 pointer i.e. element\n",
    "    elina_abstract0_add_dimensions(man, True, element, dimadd, False)\n",
    "    elina_dimchange_free(dimadd)\n",
    "\n",
    "    # Create the linear expression associated each neuron\n",
    "    var = num_in_pixels\n",
    "    for i in range(num_out_pixels):\n",
    "        tdim = ElinaDim(var)\n",
    "        linexpr0 = generate_linexpr0(weights[i], biases[i], num_in_pixels)\n",
    "        # Parallel assignment of several dimensions of an ElinaAbstract0 by using an ElinaLinexpr0Array\n",
    "        element = elina_abstract0_assign_linexpr_array(man, True, element, tdim, linexpr0, 1, None)\n",
    "        var += 1\n",
    "\n",
    "    # Pointer to which semantics we want to follow.\n",
    "    dimrem = elina_dimchange_alloc(0, num_in_pixels)\n",
    "    for i in range(num_in_pixels):\n",
    "        dimrem.contents.dim[i] = i\n",
    "        \n",
    "    # Remove dimensions from an ElinaAbstract0\n",
    "    elina_abstract0_remove_dimensions(man, True, element, dimrem)\n",
    "    elina_dimchange_free(dimrem)\n",
    "    \n",
    "    # get bounds for each output neuron\n",
    "    bounds = elina_abstract0_to_box(man,element)\n",
    "    \n",
    "    output_LB = np.zeros((num_out_pixels, 1), float)\n",
    "    output_UB = np.zeros((num_out_pixels, 1), float)\n",
    "    for j in range(num_out_pixels):\n",
    "        output_LB[j] = bounds[j].contents.inf.contents.val.dbl\n",
    "        output_UB[j] = bounds[j].contents.sup.contents.val.dbl    \n",
    "    \n",
    "    # free out the memory allocations\n",
    "    elina_interval_array_free(bounds, num_out_pixels)\n",
    "    elina_abstract0_free(man, element)\n",
    "    \n",
    "    return output_LB, output_UB, num_out_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define operations on abstract domain using linear approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_operation(input_LB, input_UB, num_in_pixels):\n",
    "    \"\"\"\n",
    "    This function computes ReLU.\n",
    "    INPUT\n",
    "        - input_LB: lower bound of the inputs to the ReLU\n",
    "        - input_UB: upper bound of the inputs to the ReLU\n",
    "        - num_in_pixels: number of inputs to ReLU    \n",
    "    OUTPUT:\n",
    "        - nontriv_relu: boolean array for locations where ReLU operation is non-trivial\n",
    "        - output_LB: lower bound of outputs \n",
    "        - output_UB: upper bound of outputs\n",
    "        - lamda_linear: slope of linear approximator line when ReLU non-trivial\n",
    "        - mu_linear: y-intercept of linear approximator line when ReLU non-trivial\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    output_LB = np.zeros((num_in_pixels), float)\n",
    "    output_UB = np.zeros((num_in_pixels), float)\n",
    "    lamda_linear = np.zeros((num_in_pixels), float)\n",
    "    mu_linear = np.zeros((num_in_pixels), float)\n",
    "    nontriv_relu = np.zeros((num_in_pixels), bool)\n",
    "\n",
    "    for j in range(num_in_pixels):\n",
    "        u = input_UB[j]\n",
    "        l = input_LB[j]\n",
    "        if u <= 0:\n",
    "            output_LB[j] = 0\n",
    "            output_UB[j] = 0\n",
    "        elif l >= 0:\n",
    "            output_LB[j] = l\n",
    "            output_UB[j] = u\n",
    "        else:\n",
    "            nontriv_relu[j] = True\n",
    "            lamda_linear[j] = u / (u - l)\n",
    "            mu_linear[j] = - lamda_linear[j] * l\n",
    "\n",
    "    return nontriv_relu, output_LB, output_UB, lamda_linear, mu_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relu_hidden_bounds_using_linear_MB(weights, biases, prev_lb, prev_ub, num_in_pixels, verbose=True, gur_verbose=False):\n",
    "    \"\"\"\n",
    "    RETURN: \n",
    "            - out_lb: Array of output lower bounds\n",
    "            - out_ub: Array of output upper bounds\n",
    "            - n_out: dimension of output\n",
    "    \"\"\"\n",
    "    debug = False\n",
    "    m = Model(\"LP\")\n",
    "    m.setParam( 'OutputFlag', gur_verbose )\n",
    "    # Preprocessing\n",
    "    prev_lb, prev_ub = prev_lb.squeeze(), prev_ub.squeeze()\n",
    "    # Get input and output dimensions\n",
    "    n_in, n_out = num_in_pixels, weights.shape[0]\n",
    "    # Create outputs\n",
    "    out_lb, out_ub = np.zeros(n_out), np.zeros(n_out)\n",
    "\n",
    "    # Check if Relu Operation is trivial and get bounds for that\n",
    "    nontriv_relu, trivial_lb, trivial_ub, lambdas_, mus_ = relu_operation(prev_lb, prev_ub, n_in)\n",
    "    \n",
    "    # Create input Variable and constrains\n",
    "    x = m.addVars(n_in, lb=prev_lb, ub=prev_ub, vtype=GRB.CONTINUOUS, name=\"x\")\n",
    "    \n",
    "    # Create Relu Output variable\n",
    "    relu_out = m.addVars(n_in, vtype=GRB.CONTINUOUS, name=\"relu_out\")\n",
    "    # Create Relu Output constrain\n",
    "    # Nontrivial cases\n",
    "    m.addConstrs((relu_out[j] >= 0 for j in range(len(relu_out)) if nontriv_relu[j]), name=\"nontrivial_zero_lb\")\n",
    "    m.addConstrs((relu_out[j] >= x[j] for j in range(len(relu_out)) if nontriv_relu[j]), name=\"nontrivial_variable_lb\")\n",
    "    m.addConstrs((relu_out[j] <= lambdas_[j] * x[j] + mus_[j] for j in range(len(relu_out))  if nontriv_relu[j]), name=\"nontrivial_line_ub\")\n",
    "    # Trivial cases\n",
    "    m.addConstrs((relu_out[j] >= trivial_lb[j] for j in range(len(relu_out)) if not nontriv_relu[j]), name=\"trivial_lb\")\n",
    "    m.addConstrs((relu_out[j] <= trivial_ub[j] for j in range(len(relu_out)) if not nontriv_relu[j]), name=\"trivial_ub\")\n",
    "    for i_out in range(n_out):\n",
    "        obj = LinExpr()\n",
    "        obj += biases[i_out]\n",
    "        for j_in in range(n_in):\n",
    "            obj +=  relu_out[j_in]*weights[i_out, j_in]\n",
    "        \n",
    "        # Find Lower Bound\n",
    "        m.setObjective(obj, GRB.MINIMIZE)\n",
    "        if debug:\n",
    "            m.write(\"file.lp\")\n",
    "        m.optimize()\n",
    "        out_lb[i_out] = m.objVal\n",
    "        m.reset()\n",
    "        # Find Upper Bound\n",
    "        m.setObjective(obj, GRB.MAXIMIZE)\n",
    "        m.optimize()\n",
    "        out_ub[i_out] = m.objVal\n",
    "        m.reset() \n",
    "            \n",
    "    return out_lb, out_ub, len(out_ub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relu_hidden_bounds_using_linear(weights, biases, input_LB, input_UB, num_in_pixels, verbose=False, gur_verbose=False):\n",
    "    '''\n",
    "    This function calculates the bounds of a ReLU operation followed by a hidden layer. \n",
    "    INPUT:\n",
    "        - man: pointer to elina manager\n",
    "        - weights: weights of the hidden layer\n",
    "        - biases: biases of the hidden layer\n",
    "        - input_LB: lower bound of the inputs to the ReLU\n",
    "        - input_UB: upper bound of the inputs to the ReLU\n",
    "        - num_in_pixels: number of inputs to ReLU\n",
    "    \n",
    "    OUTPUT:\n",
    "        - output_LB: lower bound of the outputs from hidden layer\n",
    "        - output_UB: upper bound of the outputs from hidden layer\n",
    "        - num_out_pixels: number of outputs of hidden layer\n",
    "    '''\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Handle ReLU Layer\n",
    "    # ------------------------------------------------------------------\n",
    "    relu_nontriv, relu_LB, relu_UB, lamda_linear, mu_linear = relu_operation(input_LB, input_UB, num_in_pixels)\n",
    "    count_nontriv = np.count_nonzero(relu_nontriv)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Handle Affine Layer\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    # calculate number of outputs\n",
    "    num_out_pixels = len(weights)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"[Network] Input pixels: \" + str(num_in_pixels))\n",
    "        print(\"[Network] Shape of weights: \" + str(np.shape(weights)))\n",
    "        print(\"[Network] Shape of biases: \" + str(np.shape(biases)))\n",
    "        print(\"[Network] Out pixels: \" + str(num_out_pixels))\n",
    "\n",
    "    # Create linear programming model \n",
    "    grbmodel = Model(\"LP\")\n",
    "    grbmodel.reset()\n",
    "    grbmodel.setParam( 'OutputFlag', gur_verbose )\n",
    "    \n",
    "    # Create input Variable and constrains\n",
    "    x = grbmodel.addVars(count_nontriv, vtype = GRB.CONTINUOUS, name = \"relu_input\")\n",
    "    r = grbmodel.addVars(num_in_pixels, vtype = GRB.CONTINUOUS, name = \"relu_output\")\n",
    "    \n",
    "    k = 0\n",
    "    # Add constraints over each relu output\n",
    "    for j in range(num_in_pixels):\n",
    "        if relu_nontriv[j] == False:\n",
    "            grbmodel.addConstr(r[j] <= relu_UB[j])\n",
    "            grbmodel.addConstr(r[j] >= relu_LB[j])\n",
    "        else:\n",
    "            grbmodel.addConstr(r[j] >= 0)\n",
    "            grbmodel.addConstr(r[j] >= x[k])           \n",
    "            grbmodel.addConstr(r[j] <= np.asscalar(lamda_linear[j]) * x[k] + np.asscalar(mu_linear[j]))\n",
    "            grbmodel.addConstr(x[k] >= input_LB[j])           \n",
    "            grbmodel.addConstr(x[k] <= input_UB[j])           \n",
    "            k = k + 1\n",
    "            \n",
    "    # Perform optimization\n",
    "    output_LB = np.zeros((num_out_pixels, 1), float)\n",
    "    output_UB = np.zeros((num_out_pixels, 1), float)\n",
    "    \n",
    "    for j in range(num_out_pixels):\n",
    "        obj = LinExpr();\n",
    "        obj += biases[j]\n",
    "        for i in range(num_in_pixels):\n",
    "            obj += weights[j, i] * r[i] \n",
    "        \n",
    "#         if verbose:\n",
    "#             grbmodel.write(\"sadness_\" + str(j) + \".lp\")\n",
    "            \n",
    "        # Get lower bound from neuron ouput\n",
    "        grbmodel.reset()\n",
    "        grbmodel.setObjective(obj, GRB.MINIMIZE)\n",
    "        grbmodel.optimize()\n",
    "        \n",
    "        if grbmodel.status == GRB.Status.OPTIMAL:\n",
    "            output_LB[j] = grbmodel.objVal\n",
    "            \n",
    "        # Get upper bound from neuron ouput\n",
    "        grbmodel.reset()\n",
    "        grbmodel.setObjective(obj, GRB.MAXIMIZE)\n",
    "        grbmodel.optimize()\n",
    "        \n",
    "        if grbmodel.status == GRB.Status.OPTIMAL:\n",
    "            output_UB[j] = grbmodel.objVal\n",
    "            \n",
    "    return output_LB, output_UB, num_out_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the problem variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_relu_3_10.txt    mnist_relu_6_100.txt  mnist_relu_9_100.txt\r\n",
      "mnist_relu_3_20.txt    mnist_relu_6_200.txt  mnist_relu_9_200.txt\r\n",
      "mnist_relu_3_50.txt    mnist_relu_6_20.txt\r\n",
      "mnist_relu_4_1024.txt  mnist_relu_6_50.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/riai2018/mnist_nets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netname = '/home/riai2018/mnist_nets/mnist_relu_3_10.txt'\n",
    "# specname = '/home/riai2018/mnist_images/img2.txt'\n",
    "# epsilon = 0.01072 NOT verified\n",
    "# epsilon = 0.01071 verified\n",
    "\n",
    "netname = '/home/riai2018/mnist_nets/mnist_relu_3_50.txt'\n",
    "specname = '/home/riai2018/mnist_images/img2.txt'\n",
    "epsilon = 0.01072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(netname, 'r') as netfile:\n",
    "    netstring = netfile.read()\n",
    "with open(specname, 'r') as specfile:\n",
    "    specstring = specfile.read()\n",
    "nn = parse_net(netstring)\n",
    "x0_low, x0_high = parse_spec(specstring)\n",
    "LB_N0, UB_N0 = get_perturbed_image(x0_low,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU\n",
      "ReLU\n"
     ]
    }
   ],
   "source": [
    "numlayer = nn.numlayer \n",
    "\n",
    "for layerno in range(numlayer):\n",
    "    if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "        print(nn.layertypes[layerno])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get perturbed label (provided prediction for unperturbed is true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test label: 1\n"
     ]
    }
   ],
   "source": [
    "label, _ = analyze(nn,LB_N0,UB_N0,0) # Get label of unperturbed image, i.e. eps=0\n",
    "print(\"Test label: \" + str(label))\n",
    "\n",
    "if(label == int(x0_low[0])):\n",
    "    LB_N0, UB_N0 = get_perturbed_image(x0_low,epsilon)\n",
    "else:\n",
    "    print(\"image not correctly classified by the network. expected label \",int(x0_low[0]), \" classified label: \", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Define element for the input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pixels = len(LB_N0)\n",
    "numlayer = nn.numlayer \n",
    "man = elina_box_manager_alloc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Iterate over each layer in the network and define the neural network function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For box approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Number: 0\n",
      "Layer Type: ReLU\n",
      "HIDDEN!\n",
      "[Network] Input pixels: 784\n",
      "[Network] Shape of weights: (50, 784)\n",
      "[Network] Shape of biases: (50,)\n",
      "[Network] Out pixels: 50\n",
      "[OUTPUT] Bounds: \n",
      "array([[ 0.83319018,  1.57522208],\n",
      "       [ 0.0118025 ,  0.82994602],\n",
      "       [-0.5880733 ,  0.20697346],\n",
      "       [-4.10615279, -3.26588305],\n",
      "       [-0.65968329,  0.07407208],\n",
      "       [-0.41135521,  0.24181839],\n",
      "       [ 0.90489138,  1.75625428],\n",
      "       [-2.10259551, -1.36300255],\n",
      "       [ 0.28810591,  1.04991141],\n",
      "       [-1.57479529, -0.86308058],\n",
      "       [ 0.54637667,  1.27788704],\n",
      "       [-0.18445045,  0.55714015],\n",
      "       [-0.11004858,  0.63969893],\n",
      "       [-0.21042102,  0.55742428],\n",
      "       [-0.90393497, -0.13793759],\n",
      "       [ 0.43737462,  1.1520092 ],\n",
      "       [-0.7403761 , -0.03936501],\n",
      "       [-0.72154081,  0.03271982],\n",
      "       [ 2.05176186,  2.74017523],\n",
      "       [-1.70158806, -0.87192849],\n",
      "       [ 1.09624133,  1.82885164],\n",
      "       [-1.09330789, -0.37011036],\n",
      "       [-0.74980702, -0.02487905],\n",
      "       [-1.59048417, -0.87888792],\n",
      "       [-0.9001294 , -0.24037162],\n",
      "       [-1.72084944, -0.94104345],\n",
      "       [-0.62538152,  0.14640399],\n",
      "       [ 0.64187558,  1.31295151],\n",
      "       [-0.42906531,  0.28433861],\n",
      "       [-1.33431375, -0.58784997],\n",
      "       [ 0.42369042,  1.1336494 ],\n",
      "       [-1.07422591, -0.3733273 ],\n",
      "       [-1.40508387, -0.65726761],\n",
      "       [-0.90818114, -0.11952839],\n",
      "       [-1.28383243, -0.52047748],\n",
      "       [ 0.9409878 ,  1.71702283],\n",
      "       [-1.58882435, -0.73317618],\n",
      "       [-3.6343762 , -2.92542129],\n",
      "       [-0.68736414,  0.11634641],\n",
      "       [ 0.70149431,  1.41684827],\n",
      "       [-1.49918992, -0.8120342 ],\n",
      "       [ 1.8070238 ,  2.66473385],\n",
      "       [-2.14776659, -1.40902838],\n",
      "       [-2.97146751, -2.23649414],\n",
      "       [ 1.28136692,  2.06458082],\n",
      "       [-1.00126378, -0.25478679],\n",
      "       [ 0.73456556,  1.51993522],\n",
      "       [-1.59340222, -0.77522246],\n",
      "       [-0.61667361,  0.06745618],\n",
      "       [-2.58888834, -1.85758978]])\n",
      "---------------\n",
      "Layer Number: 1\n",
      "Layer Type: ReLU\n",
      "RELU + HIDDEN!\n",
      "[Network] Input pixels: 50\n",
      "[Network] Shape of weights: (50, 50)\n",
      "[Network] Shape of biases: (50,)\n",
      "[Network] Out pixels: 50\n",
      "[OUTPUT] Bounds: \n",
      "array([[-0.99768863,  0.61246267],\n",
      "       [ 0.25781928,  1.53120346],\n",
      "       [-0.73537687,  0.65335567],\n",
      "       [-1.88287971, -0.22502295],\n",
      "       [-0.32669866,  1.56128911],\n",
      "       [ 0.53703754,  3.33375165],\n",
      "       [-2.36882164, -0.86723641],\n",
      "       [-2.41189825,  0.03407399],\n",
      "       [-0.98967343,  0.05244088],\n",
      "       [ 0.66890551,  2.8547316 ],\n",
      "       [-1.1689406 , -0.06778761],\n",
      "       [-2.61814187, -0.67047961],\n",
      "       [-0.47112275,  1.27353774],\n",
      "       [-2.02770288,  0.7260704 ],\n",
      "       [ 0.61043044,  2.98565948],\n",
      "       [-2.39966999, -0.29086489],\n",
      "       [ 0.50348494,  3.60600465],\n",
      "       [-1.1175763 ,  0.57499827],\n",
      "       [-0.84263456,  1.28992712],\n",
      "       [-0.00524689,  0.80654827],\n",
      "       [-0.96707915,  1.00299716],\n",
      "       [-0.70795187,  0.45423022],\n",
      "       [-1.57654093,  1.37963143],\n",
      "       [-0.6286412 ,  0.62951516],\n",
      "       [-1.04515682,  0.41023843],\n",
      "       [-0.46881453,  2.57339661],\n",
      "       [-0.2175182 ,  1.89483747],\n",
      "       [-0.21249663,  1.61463591],\n",
      "       [-0.70135083,  0.53216628],\n",
      "       [ 0.06867642,  1.64486107],\n",
      "       [ 1.60383836,  3.86629056],\n",
      "       [ 0.30385949,  1.68778674],\n",
      "       [-0.879527  ,  0.75892358],\n",
      "       [-0.0117569 ,  1.31304037],\n",
      "       [-1.60358115,  0.23460143],\n",
      "       [-2.24098255,  0.24133205],\n",
      "       [-1.3021335 ,  1.10065384],\n",
      "       [-0.54670044,  1.17483232],\n",
      "       [-0.51188022,  1.34731692],\n",
      "       [-0.53286054,  0.83346938],\n",
      "       [-1.28856989,  0.58702664],\n",
      "       [-0.96987546,  0.7755694 ],\n",
      "       [-0.52476418,  1.48101676],\n",
      "       [-2.05980731,  0.3535336 ],\n",
      "       [-1.1563897 ,  0.27718489],\n",
      "       [-0.16897511,  2.05018496],\n",
      "       [-0.88428627,  0.48105501],\n",
      "       [-0.23096979,  1.65813538],\n",
      "       [-0.16796752,  2.01945486],\n",
      "       [-0.43370977,  1.6962539 ]])\n",
      "---------------\n",
      "Layer Number: 2\n",
      "Layer Type: ReLU\n",
      "RELU + HIDDEN!\n",
      "[Network] Input pixels: 50\n",
      "[Network] Shape of weights: (10, 50)\n",
      "[Network] Shape of biases: (10,)\n",
      "[Network] Out pixels: 10\n",
      "[OUTPUT] Bounds: \n",
      "array([[-9.57988089,  1.10195037],\n",
      "       [-2.58615224, 13.2511222 ],\n",
      "       [-6.4243636 ,  8.37718904],\n",
      "       [-6.21697317,  6.39543007],\n",
      "       [-7.70077449,  6.46206566],\n",
      "       [-9.17041302,  5.98061365],\n",
      "       [-6.83939782,  6.13388701],\n",
      "       [-4.55706513,  7.35724822],\n",
      "       [-5.44619597,  6.41830464],\n",
      "       [-9.35782515,  6.03332542]])\n",
      "---------------\n",
      "RELU!\n",
      "[OUTPUT] Bounds: \n",
      "array([[-0.        ,  1.10195037],\n",
      "       [-0.        , 13.2511222 ],\n",
      "       [-0.        ,  8.37718904],\n",
      "       [-0.        ,  6.39543007],\n",
      "       [-0.        ,  6.46206566],\n",
      "       [-0.        ,  5.98061365],\n",
      "       [-0.        ,  6.13388701],\n",
      "       [-0.        ,  7.35724822],\n",
      "       [-0.        ,  6.41830464],\n",
      "       [-0.        ,  6.03332542]])\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "nn.ffn_counter = 0\n",
    "input_LB = LB_N0\n",
    "input_UB = UB_N0\n",
    "num_in_pixels = num_pixels\n",
    "\n",
    "use_box = True\n",
    "# use_MB = True\n",
    "verbose = True\n",
    "\n",
    "for layerno in range(numlayer):\n",
    "    print(\"Layer Number: \" + str(layerno))\n",
    "    if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "        if verbose:\n",
    "            print(\"Layer Type: %s\" % nn.layertypes[layerno])\n",
    "        # read the layer weights and biases\n",
    "        weights = nn.weights[nn.ffn_counter]\n",
    "        biases = nn.biases[nn.ffn_counter]\n",
    "        np.ascontiguousarray(weights, dtype=np.double)\n",
    "        np.ascontiguousarray(biases, dtype=np.double)\n",
    "        \n",
    "        # only hidden layer\n",
    "        if (layerno == 0):\n",
    "            print(\"HIDDEN!\")\n",
    "            output_LB, output_UB, num_out_pixels = get_hidden_bounds_using_box(man, weights, biases, input_LB, input_UB, num_in_pixels, verbose)\n",
    "        # ReLU + hidden layer\n",
    "        else:\n",
    "            print(\"RELU + HIDDEN!\")\n",
    "            if use_box:\n",
    "                output_LB, output_UB, num_out_pixels = get_relu_hidden_bounds_using_box(man, weights, biases, input_LB, input_UB, num_in_pixels, verbose)\n",
    "            else:\n",
    "                if use_MB:\n",
    "                    output_LB, output_UB, num_out_pixels = get_relu_hidden_bounds_using_linear_MB(weights, biases, input_LB, input_UB, num_in_pixels, verbose)\n",
    "                else:\n",
    "                    output_LB, output_UB, num_out_pixels = get_relu_hidden_bounds_using_linear(weights, biases, input_LB, input_UB, num_in_pixels, verbose)\n",
    "                   \n",
    "        # Iterate to next layer\n",
    "        input_LB = output_LB\n",
    "        input_UB = output_UB\n",
    "        num_in_pixels = num_out_pixels        \n",
    "        nn.ffn_counter+=1 \n",
    "        \n",
    "        # only ReLU layer\n",
    "        if(layerno + 1 == numlayer and not\n",
    "            nn.layertypes[layerno] == \"Affine\"):\n",
    "            if verbose:\n",
    "                print(\"[OUTPUT] Bounds: \")\n",
    "                pprint(np.concatenate([output_LB, output_UB], axis = 1))\n",
    "            print('---------------')\n",
    "            print(\"RELU!\")\n",
    "            output_LB, output_UB, num_out_pixels = get_relu_bounds_using_box(man, input_LB, input_UB, num_in_pixels)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"[OUTPUT] Bounds: \")\n",
    "            pprint(np.concatenate([output_LB, output_UB], axis = 1))\n",
    "            \n",
    "        print('---------------')\n",
    "            \n",
    "    else:\n",
    "        print(' net type not supported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the verifiability of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can not be verified\n"
     ]
    }
   ],
   "source": [
    "# if epsilon is zero, try to classify else verify robustness \n",
    "verified_flag = True\n",
    "predicted_label = 0\n",
    "if(LB_N0[0]==UB_N0[0]):\n",
    "    for i in range(num_out_pixels):\n",
    "        inf = output_LB[i]\n",
    "        flag = True\n",
    "        for j in range(num_out_pixels):\n",
    "            if(j!=i):\n",
    "                sup = output_UB[j]\n",
    "                if(inf<=sup):\n",
    "                    flag = False\n",
    "                    break\n",
    "        if(flag):\n",
    "            predicted_label = i\n",
    "            break    \n",
    "else:\n",
    "    inf = output_LB[label]\n",
    "    for j in range(num_out_pixels):\n",
    "        if(j!=label):\n",
    "            sup = output_UB[j]\n",
    "            if(inf<=sup):\n",
    "                predicted_label = label\n",
    "                verified_flag = False\n",
    "                break\n",
    "\n",
    "if(verified_flag):\n",
    "    print(\"verified\")\n",
    "else:\n",
    "    print(\"can not be verified\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Linear Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the verifiability of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Number: 0\n",
      "HIDDEN!\n",
      "---------------\n",
      "Layer Number: 1\n",
      "RELU + HIDDEN!\n",
      "Academic license - for non-commercial use only\n",
      "---------------\n",
      "Layer Number: 2\n",
      "RELU + HIDDEN!\n",
      "---------------\n",
      "RELU!\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "nn.ffn_counter = 0\n",
    "input_LB = LB_N0\n",
    "input_UB = UB_N0\n",
    "num_in_pixels = num_pixels\n",
    "\n",
    "use_box = False\n",
    "use_MB = True\n",
    "verbose = False\n",
    "\n",
    "for layerno in range(numlayer):\n",
    "    print(\"Layer Number: \" + str(layerno))\n",
    "    if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "        if verbose:\n",
    "            print(\"Layer Type: %s\" % nn.layertypes[layerno])\n",
    "        # read the layer weights and biases\n",
    "        weights = nn.weights[nn.ffn_counter]\n",
    "        biases = nn.biases[nn.ffn_counter]\n",
    "        np.ascontiguousarray(weights, dtype=np.double)\n",
    "        np.ascontiguousarray(biases, dtype=np.double)\n",
    "        \n",
    "        # only hidden layer\n",
    "        if (layerno == 0):\n",
    "            print(\"HIDDEN!\")\n",
    "            output_LB, output_UB, num_out_pixels = get_hidden_bounds_using_box(man, weights, biases, input_LB, input_UB, num_in_pixels, verbose)\n",
    "        # ReLU + hidden layer\n",
    "        else:\n",
    "            print(\"RELU + HIDDEN!\")\n",
    "            if use_box:\n",
    "                output_LB, output_UB, num_out_pixels = get_relu_hidden_bounds_using_box(man, weights, biases, input_LB, input_UB, num_in_pixels, verbose)\n",
    "            else:\n",
    "                if use_MB:\n",
    "                    output_LB, output_UB, num_out_pixels = get_relu_hidden_bounds_using_linear_MB(weights, biases, input_LB, input_UB, num_in_pixels, verbose=verbose)\n",
    "                else:\n",
    "                    output_LB, output_UB, num_out_pixels = get_relu_hidden_bounds_using_linear(weights, biases, input_LB, input_UB, num_in_pixels, verbose)\n",
    "                \n",
    "        # Iterate to next layer\n",
    "        input_LB = output_LB\n",
    "        input_UB = output_UB\n",
    "        num_in_pixels = num_out_pixels        \n",
    "        nn.ffn_counter+=1 \n",
    "        \n",
    "        # only ReLU layer\n",
    "        if(layerno + 1 == numlayer and not\n",
    "            nn.layertypes[layerno] == \"Affine\"):\n",
    "            if verbose:\n",
    "                print(\"[OUTPUT] Bounds: \")\n",
    "                output_LB, output_UB  = output_LB.squeeze(), output_UB.squeeze()\n",
    "                pprint(np.stack((output_LB, output_UB), axis=1))\n",
    "            print('---------------')\n",
    "            print(\"RELU!\")\n",
    "            output_LB, output_UB, num_out_pixels = get_relu_bounds_using_box(man, input_LB, input_UB, num_in_pixels)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"[OUTPUT] Bounds: \")\n",
    "            output_LB, output_UB  = output_LB.squeeze(), output_UB.squeeze()\n",
    "            pprint(np.stack((output_LB, output_UB), axis=1))\n",
    "            \n",
    "        print('---------------')\n",
    "\n",
    "    else:\n",
    "        print(' net type not supported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can not be verified\n"
     ]
    }
   ],
   "source": [
    "# if epsilon is zero, try to classify else verify robustness \n",
    "verified_flag = True\n",
    "predicted_label = 2\n",
    "if(LB_N0[0]==UB_N0[0]):\n",
    "    for i in range(num_out_pixels):\n",
    "        inf = output_LB[i]\n",
    "        flag = True\n",
    "        for j in range(num_out_pixels):\n",
    "            if(j!=i):\n",
    "                sup = output_UB[j]\n",
    "                if(inf<=sup):\n",
    "                    flag = False\n",
    "                    break\n",
    "        if(flag):\n",
    "            predicted_label = i\n",
    "            break    \n",
    "else:\n",
    "    inf = output_LB[label]\n",
    "    for j in range(num_out_pixels):\n",
    "        if(j!=label):\n",
    "            sup = output_UB[j]\n",
    "            if(inf<=sup):\n",
    "                predicted_label = label\n",
    "                verified_flag = False\n",
    "                break\n",
    "\n",
    "if(verified_flag):\n",
    "    print(\"verified\")\n",
    "else:\n",
    "    print(\"can not be verified\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "elina_manager_free(man)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Verifyability with forward propagating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Number: 0\n",
      "Layer Type: ReLU\n",
      "HIDDEN!\n",
      "[Network] Input pixels: 784\n",
      "[Network] Shape of weights: (50, 784)\n",
      "[Network] Shape of biases: (50,)\n",
      "[Network] Out pixels: 50\n",
      "[OUTPUT] Bounds: \n",
      "array([[ 0.83319018,  1.57522208],\n",
      "       [ 0.0118025 ,  0.82994602],\n",
      "       [-0.5880733 ,  0.20697346],\n",
      "       [-4.10615279, -3.26588305],\n",
      "       [-0.65968329,  0.07407208],\n",
      "       [-0.41135521,  0.24181839],\n",
      "       [ 0.90489138,  1.75625428],\n",
      "       [-2.10259551, -1.36300255],\n",
      "       [ 0.28810591,  1.04991141],\n",
      "       [-1.57479529, -0.86308058],\n",
      "       [ 0.54637667,  1.27788704],\n",
      "       [-0.18445045,  0.55714015],\n",
      "       [-0.11004858,  0.63969893],\n",
      "       [-0.21042102,  0.55742428],\n",
      "       [-0.90393497, -0.13793759],\n",
      "       [ 0.43737462,  1.1520092 ],\n",
      "       [-0.7403761 , -0.03936501],\n",
      "       [-0.72154081,  0.03271982],\n",
      "       [ 2.05176186,  2.74017523],\n",
      "       [-1.70158806, -0.87192849],\n",
      "       [ 1.09624133,  1.82885164],\n",
      "       [-1.09330789, -0.37011036],\n",
      "       [-0.74980702, -0.02487905],\n",
      "       [-1.59048417, -0.87888792],\n",
      "       [-0.9001294 , -0.24037162],\n",
      "       [-1.72084944, -0.94104345],\n",
      "       [-0.62538152,  0.14640399],\n",
      "       [ 0.64187558,  1.31295151],\n",
      "       [-0.42906531,  0.28433861],\n",
      "       [-1.33431375, -0.58784997],\n",
      "       [ 0.42369042,  1.1336494 ],\n",
      "       [-1.07422591, -0.3733273 ],\n",
      "       [-1.40508387, -0.65726761],\n",
      "       [-0.90818114, -0.11952839],\n",
      "       [-1.28383243, -0.52047748],\n",
      "       [ 0.9409878 ,  1.71702283],\n",
      "       [-1.58882435, -0.73317618],\n",
      "       [-3.6343762 , -2.92542129],\n",
      "       [-0.68736414,  0.11634641],\n",
      "       [ 0.70149431,  1.41684827],\n",
      "       [-1.49918992, -0.8120342 ],\n",
      "       [ 1.8070238 ,  2.66473385],\n",
      "       [-2.14776659, -1.40902838],\n",
      "       [-2.97146751, -2.23649414],\n",
      "       [ 1.28136692,  2.06458082],\n",
      "       [-1.00126378, -0.25478679],\n",
      "       [ 0.73456556,  1.51993522],\n",
      "       [-1.59340222, -0.77522246],\n",
      "       [-0.61667361,  0.06745618],\n",
      "       [-2.58888834, -1.85758978]])\n",
      "---------------\n",
      "Layer Number: 1\n",
      "Layer Type: ReLU\n",
      "RELU + HIDDEN!\n",
      "[Network] Input pixels: 50\n",
      "[Network] Shape of weights: (50, 50)\n",
      "[Network] Shape of biases: (50,)\n",
      "[Network] Out pixels: 50\n",
      "[OUTPUT] Bounds: \n",
      "array([[-0.99768863,  0.61246267],\n",
      "       [ 0.25781928,  1.53120346],\n",
      "       [-0.73537687,  0.65335567],\n",
      "       [-1.88287971, -0.22502295],\n",
      "       [-0.32669866,  1.56128911],\n",
      "       [ 0.53703754,  3.33375165],\n",
      "       [-2.36882164, -0.86723641],\n",
      "       [-2.41189825,  0.03407399],\n",
      "       [-0.98967343,  0.05244088],\n",
      "       [ 0.66890551,  2.8547316 ],\n",
      "       [-1.1689406 , -0.06778761],\n",
      "       [-2.61814187, -0.67047961],\n",
      "       [-0.47112275,  1.27353774],\n",
      "       [-2.02770288,  0.7260704 ],\n",
      "       [ 0.61043044,  2.98565948],\n",
      "       [-2.39966999, -0.29086489],\n",
      "       [ 0.50348494,  3.60600465],\n",
      "       [-1.1175763 ,  0.57499827],\n",
      "       [-0.84263456,  1.28992712],\n",
      "       [-0.00524689,  0.80654827],\n",
      "       [-0.96707915,  1.00299716],\n",
      "       [-0.70795187,  0.45423022],\n",
      "       [-1.57654093,  1.37963143],\n",
      "       [-0.6286412 ,  0.62951516],\n",
      "       [-1.04515682,  0.41023843],\n",
      "       [-0.46881453,  2.57339661],\n",
      "       [-0.2175182 ,  1.89483747],\n",
      "       [-0.21249663,  1.61463591],\n",
      "       [-0.70135083,  0.53216628],\n",
      "       [ 0.06867642,  1.64486107],\n",
      "       [ 1.60383836,  3.86629056],\n",
      "       [ 0.30385949,  1.68778674],\n",
      "       [-0.879527  ,  0.75892358],\n",
      "       [-0.0117569 ,  1.31304037],\n",
      "       [-1.60358115,  0.23460143],\n",
      "       [-2.24098255,  0.24133205],\n",
      "       [-1.3021335 ,  1.10065384],\n",
      "       [-0.54670044,  1.17483232],\n",
      "       [-0.51188022,  1.34731692],\n",
      "       [-0.53286054,  0.83346938],\n",
      "       [-1.28856989,  0.58702664],\n",
      "       [-0.96987546,  0.7755694 ],\n",
      "       [-0.52476418,  1.48101676],\n",
      "       [-2.05980731,  0.3535336 ],\n",
      "       [-1.1563897 ,  0.27718489],\n",
      "       [-0.16897511,  2.05018496],\n",
      "       [-0.88428627,  0.48105501],\n",
      "       [-0.23096979,  1.65813538],\n",
      "       [-0.16796752,  2.01945486],\n",
      "       [-0.43370977,  1.6962539 ]])\n",
      "---------------\n",
      "Layer Number: 2\n",
      "Layer Type: ReLU\n",
      "RELU + HIDDEN!\n",
      "[Network] Input pixels: 50\n",
      "[Network] Shape of weights: (10, 50)\n",
      "[Network] Shape of biases: (10,)\n",
      "[Network] Out pixels: 10\n",
      "[OUTPUT] Bounds: \n",
      "array([[-9.57988089,  1.10195037],\n",
      "       [-2.58615224, 13.2511222 ],\n",
      "       [-6.4243636 ,  8.37718904],\n",
      "       [-6.21697317,  6.39543007],\n",
      "       [-7.70077449,  6.46206566],\n",
      "       [-9.17041302,  5.98061365],\n",
      "       [-6.83939782,  6.13388701],\n",
      "       [-4.55706513,  7.35724822],\n",
      "       [-5.44619597,  6.41830464],\n",
      "       [-9.35782515,  6.03332542]])\n",
      "---------------\n",
      "RELU!\n",
      "[OUTPUT] Bounds: \n",
      "array([[-0.        ,  1.10195037],\n",
      "       [-0.        , 13.2511222 ],\n",
      "       [-0.        ,  8.37718904],\n",
      "       [-0.        ,  6.39543007],\n",
      "       [-0.        ,  6.46206566],\n",
      "       [-0.        ,  5.98061365],\n",
      "       [-0.        ,  6.13388701],\n",
      "       [-0.        ,  7.35724822],\n",
      "       [-0.        ,  6.41830464],\n",
      "       [-0.        ,  6.03332542]])\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "nn.ffn_counter = 0\n",
    "input_LB = LB_N0\n",
    "input_UB = UB_N0\n",
    "num_in_pixels = num_pixels\n",
    "\n",
    "use_box = True\n",
    "use_MB = True\n",
    "verbose = True\n",
    "LB_list = [input_LB]\n",
    "UB_list = [input_UB]\n",
    "\n",
    "for layerno in range(numlayer):\n",
    "    print(\"Layer Number: \" + str(layerno))\n",
    "    if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "        if verbose:\n",
    "            print(\"Layer Type: %s\" % nn.layertypes[layerno])\n",
    "        # read the layer weights and biases\n",
    "        weights = nn.weights[nn.ffn_counter]\n",
    "        biases = nn.biases[nn.ffn_counter]\n",
    "        np.ascontiguousarray(weights, dtype=np.double)\n",
    "        np.ascontiguousarray(biases, dtype=np.double)\n",
    "        \n",
    "        # only hidden layer\n",
    "        if (layerno == 0):\n",
    "            print(\"HIDDEN!\")\n",
    "            output_LB, output_UB, num_out_pixels = get_hidden_bounds_using_box(man, weights, biases, input_LB, input_UB, num_in_pixels, verbose)\n",
    "        # ReLU + hidden layer\n",
    "        else:\n",
    "            print(\"RELU + HIDDEN!\")\n",
    "            if use_box:\n",
    "                output_LB, output_UB, num_out_pixels = get_relu_hidden_bounds_using_box(man, weights, biases, input_LB, input_UB, num_in_pixels, verbose)\n",
    "            else:\n",
    "                if use_MB:\n",
    "                    output_LB, output_UB, num_out_pixels = get_relu_hidden_bounds_using_linear_MB(weights, biases, input_LB, input_UB, num_in_pixels, verbose=verbose)\n",
    "                else:\n",
    "                    output_LB, output_UB, num_out_pixels = get_relu_hidden_bounds_using_linear(weights, biases, input_LB, input_UB, num_in_pixels, verbose)\n",
    "                \n",
    "        # Iterate to next layer\n",
    "        input_LB = output_LB\n",
    "        input_UB = output_UB\n",
    "        LB_list.append(input_LB)\n",
    "        UB_list.append(input_UB)\n",
    "\n",
    "        num_in_pixels = num_out_pixels        \n",
    "        nn.ffn_counter+=1 \n",
    "        \n",
    "        # only ReLU layer\n",
    "        if(layerno + 1 == numlayer and not\n",
    "            nn.layertypes[layerno] == \"Affine\"):\n",
    "            if verbose:\n",
    "                print(\"[OUTPUT] Bounds: \")\n",
    "                output_LB, output_UB  = output_LB.squeeze(), output_UB.squeeze()\n",
    "                pprint(np.stack((output_LB, output_UB), axis=1))\n",
    "            print('---------------')\n",
    "            print(\"RELU!\")\n",
    "            output_LB, output_UB, num_out_pixels = get_relu_bounds_using_box(man, input_LB, input_UB, num_in_pixels)\n",
    "            LB_list.append(output_LB)\n",
    "            UB_list.append(output_UB)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"[OUTPUT] Bounds: \")\n",
    "            output_LB, output_UB  = output_LB.squeeze(), output_UB.squeeze()\n",
    "            pprint(np.stack((output_LB, output_UB), axis=1))\n",
    "            \n",
    "        print('---------------')\n",
    "\n",
    "    else:\n",
    "        print(' net type not supported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we have the list of the bounds. Forwards propagate it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relu_hidden_bounds_using_linear_propagate(weights, biases, lb_box, ub_box, num_in_pixels, \n",
    "          layerno, in_vars=None, model=None, verbose=True, gur_verbose=True, last_layer=False):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "        - weights: weights of the hidden layer\n",
    "        - biases: biases of the hidden layer\n",
    "        - input_LB: lower bound of the inputs to the ReLU\n",
    "        - input_UB: upper bound of the inputs to the ReLU\n",
    "        - num_in_pixels: number of inputs to ReLU\n",
    "    \n",
    "    RETURN: \n",
    "            - m: Gurobi model\n",
    "            - out: Gurobi variable of output of layer\n",
    "            - n_out: dimension of output\n",
    "            - out_lb: Lower Bounds if model was optimized (last layer)\n",
    "            - out_ub: Upper Bounds if model was optimized (last layer), \n",
    "\n",
    "    \"\"\"\n",
    "    debug = True\n",
    "    \n",
    "    # Preprocessing\n",
    "    ub_box, lb_box = ub_box.squeeze(), lb_box.squeeze()\n",
    "    \n",
    "    # Get input and output dimensions\n",
    "    n_in, n_out = num_in_pixels, weights.shape[0]\n",
    "    \n",
    "    # Create dummy variables to store bounds of output layer\n",
    "    out_lb, out_ub = np.zeros(n_out, float), np.zeros(n_out, float)\n",
    "    \n",
    "    #----------------------------------------------------\n",
    "    # Create model if non existing (At very first layer)\n",
    "    #----------------------------------------------------\n",
    "    if (layerno==0):\n",
    "        # Affine Layer out = W*in_vars + b\n",
    "        out_vars = model.addVars(n_out, vtype=GRB.CONTINUOUS, name=\"hidden_out_\" + str(layerno))\n",
    "\n",
    "        for i_out in range(n_out):\n",
    "            constr = LinExpr()\n",
    "            constr += biases[i_out]\n",
    "            for j_in in range(n_in):\n",
    "                constr +=  in_vars[j_in] * weights[i_out, j_in]\n",
    "                \n",
    "            # add constraint to model\n",
    "            model.addConstr(out_vars[i_out] == constr, name=\"hidden_layer_\" + str(layerno) + \"_neuron_\" + str(i_out))\n",
    "            \n",
    "        return model, out_vars, n_out, out_lb, out_ub\n",
    "    \n",
    "    \n",
    "    #----------------------------------------------------\n",
    "    # For other layers\n",
    "    #----------------------------------------------------\n",
    "\n",
    "    # Create Relu Output variable\n",
    "    # relu_out = ReLU(in_vars)\n",
    "    relu_out = model.addVars(n_in, vtype=GRB.CONTINUOUS, name=\"relu_out_\" + str(layerno))\n",
    "\n",
    "    # Check if Relu Operation is trivial and get bounds for that\n",
    "    nontriv_relu, trivial_lb, trivial_ub, lambdas_, mus_ = relu_operation(lb_box, ub_box, n_in)\n",
    "    \n",
    "    # Nontrivial cases\n",
    "    model.addConstrs((relu_out[j] >= 0 for j in range(len(relu_out)) if nontriv_relu[j]), \n",
    "                 name=\"relu_nontrivial_zero_lb_\" + str(layerno))\n",
    "    model.addConstrs((relu_out[j] >= in_vars[j] for j in range(len(relu_out)) if nontriv_relu[j]), \n",
    "                 name=\"relu_nontrivial_variable_lb_\" + str(layerno))\n",
    "    model.addConstrs((relu_out[j] <= lambdas_[j] * in_vars[j] + mus_[j] for j in range(len(relu_out))  if nontriv_relu[j]), \n",
    "                 name=\"relu_nontrivial_line_ub_\" + str(layerno))\n",
    "\n",
    "    # Trivial case: when it is clear that ReLU only actiavtes or deactiavtes\n",
    "    model.addConstrs((relu_out[j] >= trivial_lb[j] for j in range(len(relu_out)) if not nontriv_relu[j]), \n",
    "                 name=\"relu_trivial_lb_\" + str(layerno))\n",
    "    model.addConstrs((relu_out[j] <= trivial_ub[j] for j in range(len(relu_out)) if not nontriv_relu[j]), \n",
    "                 name=\"relu_trivial_ub_\" + str(layerno))\n",
    "        \n",
    "    if not last_layer:\n",
    "        # Affine Layer out = W*relu_out + b\n",
    "        out_vars = model.addVars(n_out, vtype=GRB.CONTINUOUS, name=\"hidden_out_\" + str(layerno))\n",
    "        \n",
    "        for i_out in range(n_out):\n",
    "            constr = LinExpr()\n",
    "            constr += biases[i_out]\n",
    "            for j_in in range(n_in):\n",
    "                constr +=  relu_out[j_in] * weights[i_out, j_in]\n",
    "\n",
    "            model.addConstr(out_vars[i_out] == constr, name=\"hidden_layer_\" + str(layerno) + \"_neuron_\" + str(i_out))\n",
    "            \n",
    "        return model, out_vars, n_out, out_lb, out_ub\n",
    "    \n",
    "    else:\n",
    "        for i_out in range(n_out):\n",
    "            # Find Lower Bound\n",
    "            model.update()\n",
    "            model.setObjective(relu_out[i_out], GRB.MINIMIZE)\n",
    "            model.optimize()\n",
    "            if debug:\n",
    "                model.write(\"file_\" + str(layerno) + \".lp\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"file_\" + str(layerno) + \".ilp\")\n",
    "                \n",
    "            if model.status == GRB.Status.OPTIMAL:\n",
    "                out_lb[i_out] = m.objVal\n",
    "            else:\n",
    "                print('[Min] Error. Not Able to retrieve bound. Gurobi Model. Not Optimal.')\n",
    "                sys.exit(0)\n",
    "            model.reset()\n",
    "            \n",
    "            # Find Upper Bound\n",
    "            model.setObjective(relu_out[i_out], GRB.MAXIMIZE)\n",
    "            model.optimize()\n",
    "            if debug:\n",
    "                model.write(\"file_\" + str(layerno) + \".lp\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"file_\" + str(layerno) + \".ilp\")\n",
    "                \n",
    "            if model.status == GRB.Status.OPTIMAL:\n",
    "                out_ub[i_out] = model.objVal\n",
    "            else:\n",
    "                print('[Max] Error. Not Able to retrieve bound. Gurobi Model. Not Optimal.')\n",
    "                sys.exit(0)\n",
    "            model.reset()\n",
    "            \n",
    "        return model, None, n_out, out_lb, out_ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter OutputFlag unchanged\n",
      "   Value: 1  Min: 0  Max: 1  Default: 1\n"
     ]
    }
   ],
   "source": [
    "nn.ffn_counter = 0\n",
    "num_in_pixels = num_pixels\n",
    "\n",
    "verbose = True\n",
    "gurobi_model = Model(\"LP\")\n",
    "gurobi_model.setParam( 'OutputFlag', True)\n",
    "\n",
    "# Create variables for input\n",
    "image_vars = gurobi_model.addVars(num_in_pixels, lb=LB_N0, ub=UB_N0, vtype=GRB.CONTINUOUS, name=\"image\")\n",
    "gurobi_model.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.138300, upper bound: 0.159740\n",
      "lower bound: 0.985358, upper bound: 1.000000\n",
      "lower bound: 0.416731, upper bound: 0.438171\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.330456, upper bound: 0.351896\n",
      "lower bound: 0.977515, upper bound: 0.998955\n",
      "lower bound: 0.310849, upper bound: 0.332289\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.518692, upper bound: 0.540132\n",
      "lower bound: 0.934378, upper bound: 0.955818\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.165751, upper bound: 0.187191\n",
      "lower bound: 0.946143, upper bound: 0.967583\n",
      "lower bound: 0.577515, upper bound: 0.598955\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.318692, upper bound: 0.340132\n",
      "lower bound: 0.985358, upper bound: 1.000000\n",
      "lower bound: 0.236339, upper bound: 0.257779\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.781437, upper bound: 0.802877\n",
      "lower bound: 0.863790, upper bound: 0.885230\n",
      "lower bound: 0.032417, upper bound: 0.053857\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.114770, upper bound: 0.136210\n",
      "lower bound: 0.985358, upper bound: 1.000000\n",
      "lower bound: 0.836339, upper bound: 0.857779\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.361829, upper bound: 0.383269\n",
      "lower bound: 0.985358, upper bound: 1.000000\n",
      "lower bound: 0.753986, upper bound: 0.775426\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.538300, upper bound: 0.559740\n",
      "lower bound: 0.985358, upper bound: 1.000000\n",
      "lower bound: 0.291241, upper bound: 0.312681\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.212809, upper bound: 0.234249\n",
      "lower bound: 0.918692, upper bound: 0.940132\n",
      "lower bound: 0.793202, upper bound: 0.814642\n",
      "lower bound: 0.020653, upper bound: 0.042093\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.475555, upper bound: 0.496995\n",
      "lower bound: 0.989280, upper bound: 1.000000\n",
      "lower bound: 0.636339, upper bound: 0.657779\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.659868, upper bound: 0.681308\n",
      "lower bound: 0.985358, upper bound: 1.000000\n",
      "lower bound: 0.306927, upper bound: 0.328367\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.083398, upper bound: 0.104838\n",
      "lower bound: 0.899084, upper bound: 0.920524\n",
      "lower bound: 0.832417, upper bound: 0.853857\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.459868, upper bound: 0.481308\n",
      "lower bound: 0.985358, upper bound: 1.000000\n",
      "lower bound: 0.612809, upper bound: 0.634249\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.581437, upper bound: 0.602877\n",
      "lower bound: 0.985358, upper bound: 1.000000\n",
      "lower bound: 0.546143, upper bound: 0.567583\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.883398, upper bound: 0.904838\n",
      "lower bound: 0.985358, upper bound: 1.000000\n",
      "lower bound: 0.248104, upper bound: 0.269544\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.228496, upper bound: 0.249936\n",
      "lower bound: 0.973594, upper bound: 0.995034\n",
      "lower bound: 0.985358, upper bound: 1.000000\n",
      "lower bound: 0.248104, upper bound: 0.269544\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.542221, upper bound: 0.563661\n",
      "lower bound: 0.985358, upper bound: 1.000000\n",
      "lower bound: 0.793202, upper bound: 0.814642\n",
      "lower bound: 0.001045, upper bound: 0.022485\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.028496, upper bound: 0.049936\n",
      "lower bound: 0.832417, upper bound: 0.853857\n",
      "lower bound: 0.985358, upper bound: 1.000000\n",
      "lower bound: 0.463790, upper bound: 0.485230\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.008888, upper bound: 0.030328\n",
      "lower bound: 0.765751, upper bound: 0.787191\n",
      "lower bound: 0.679476, upper bound: 0.700916\n",
      "lower bound: 0.028496, upper bound: 0.049936\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n",
      "lower bound: 0.000000, upper bound: 0.010720\n"
     ]
    }
   ],
   "source": [
    "for i in range(700):\n",
    "    print(\"lower bound: %f, upper bound: %f\" % (image_vars[i].getAttr(GRB.Attr.LB), image_vars[i].getAttr(GRB.Attr.UB)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "Layer Number: 0\n",
      "Layer Type: ReLU\n",
      "HIDDEN!\n",
      "---------------\n",
      "Layer Number: 1\n",
      "Layer Type: ReLU\n",
      "RELU + HIDDEN!\n",
      "---------------\n",
      "Layer Number: 2\n",
      "Layer Type: ReLU\n",
      "RELU + HIDDEN!\n",
      "[OUTPUT] Bounds: \n",
      "---------------\n",
      "RELU!\n",
      "Optimize a model with 383 rows, 1004 columns and 42689 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-06, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [2e-03, 1e+00]\n",
      "  RHS range        [2e-04, 4e+00]\n",
      "Presolve removed 182 rows and 91 columns\n",
      "Presolve time: 0.04s\n",
      "\n",
      "Solved in 0 iterations and 0.04 seconds\n",
      "Infeasible model\n",
      "\n",
      "IIS computed: 1 constraints and 785 bounds\n",
      "IIS runtime: 0.01 seconds\n",
      "[Min] Error. Not Able to retrieve bound. Gurobi Model. Not Optimal.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "print('---------------')\n",
    "\n",
    "for layerno in range(numlayer):\n",
    "    print(\"Layer Number: \" + str(layerno))\n",
    "    if(nn.layertypes[layerno] in ['ReLU', 'Affine']):\n",
    "        if verbose:\n",
    "            print(\"Layer Type: %s\" % nn.layertypes[layerno])\n",
    "        # read the layer weights and biases\n",
    "        weights = nn.weights[nn.ffn_counter]\n",
    "        biases = nn.biases[nn.ffn_counter]\n",
    "        lb_box = LB_list[layerno]\n",
    "        ub_box = UB_list[layerno]\n",
    "        np.ascontiguousarray(weights, dtype=np.double)\n",
    "        np.ascontiguousarray(biases, dtype=np.double)\n",
    "        \n",
    "        # only hidden layer\n",
    "        if (layerno == 0):\n",
    "            print(\"HIDDEN!\")\n",
    "            gurobi_model, out_vars, num_out_pixels,_ ,_ = get_relu_hidden_bounds_using_linear_propagate(weights, biases,\n",
    "                                                                 lb_box, ub_box, num_in_pixels, layerno, \n",
    "                                                                 in_vars=image_vars, model=gurobi_model, \n",
    "                                                                 verbose=verbose)\n",
    "        # ReLU + hidden layer\n",
    "        else:\n",
    "            print(\"RELU + HIDDEN!\")\n",
    "            gurobi_model, out_vars, num_out_pixels,_ ,_ = get_relu_hidden_bounds_using_linear_propagate(weights, biases,\n",
    "                                                                  lb_box, ub_box, num_in_pixels, layerno, \n",
    "                                                                  in_vars=out_vars, model=gurobi_model, \n",
    "                                                                  verbose=verbose)\n",
    "\n",
    "        num_in_pixels = num_out_pixels        \n",
    "        nn.ffn_counter+=1 \n",
    "        gurobi_model.update()\n",
    "\n",
    "        \n",
    "        # only ReLU layer\n",
    "        if(layerno + 1 == numlayer and not nn.layertypes[layerno] == \"Affine\"):\n",
    "            if verbose:\n",
    "                print(\"[OUTPUT] Bounds: \")\n",
    "            print('---------------')\n",
    "            print(\"RELU!\")\n",
    "            gurobi_model, _, num_out_pixels, output_LB, output_UB = \\\n",
    "                                                         get_relu_hidden_bounds_using_linear_propagate(weights, biases, \n",
    "                                                                 lb_box, ub_box, num_in_pixels, layerno + 1, \n",
    "                                                                 in_vars=out_vars, model=gurobi_model, \n",
    "                                                                 verbose=verbose, last_layer=True)\n",
    "            \n",
    "        print('---------------')\n",
    "\n",
    "    else:\n",
    "        print(' net type not supported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_layer_bound_LP(Ws,bs,UBs,LBs,x0,eps,p,neuron_states,\n",
    "### nlayer,pred_label,target_label,compute_full_bounds=False,untargeted=False):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_activations_checker(LBs, UBs):\n",
    "    \"\"\"\n",
    "    This function computes ReLU.\n",
    "    INPUT\n",
    "        - LBs: list of lower bound of inputs to all the layers\n",
    "        - UBs: list of upper bound of inputs to all the layers\n",
    "    OUTPUT:\n",
    "        - neuron_states: neuron actiavtion information    \n",
    "    \"\"\"\n",
    "    \n",
    "    neuron_states = UBs.copy()\n",
    "    \n",
    "    output_LB = np.zeros((num_in_pixels), float)\n",
    "    output_UB = np.zeros((num_in_pixels), float)\n",
    "    lamda_linear = np.zeros((num_in_pixels), float)\n",
    "    mu_linear = np.zeros((num_in_pixels), float)\n",
    "    nontriv_relu = np.zeros((num_in_pixels), bool)\n",
    "    \n",
    "    for i in range(len(UBs)):\n",
    "        for j in range(len(UBs[i])):\n",
    "            u = UBs[i][j]\n",
    "            l = LBs[i][j]\n",
    "            if u <= 0:\n",
    "                neuron_states[i][j] = -1\n",
    "            elif l >= 0:\n",
    "                neuron_states[i][j] = 1\n",
    "            else:\n",
    "                neuron_states[i][j] = 0\n",
    "\n",
    "    return neuron_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ws = nn.weights\n",
    "bs = nn.biases\n",
    "p = 1\n",
    "nlayer = numlayer\n",
    "\n",
    "LBs = LB_list\n",
    "UBs = UB_list\n",
    "\n",
    "neuron_states = relu_activations_checker(LBs, UBs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as grb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing upper and lower bounds for last layer\n",
    "UB = np.empty_like(bs[-1])\n",
    "LB = np.empty_like(bs[-1])\n",
    "\n",
    "# neuron_state is an array: neurons never activated set to -1, neurons always activated set to +1, indefinite set to 0    \n",
    "# indices\n",
    "alphas = []\n",
    "# for n layer network, we have n-1 layers of relu\n",
    "for i in range(nlayer-1):\n",
    "    idx_unsure = (neuron_states[i] == 0).nonzero()[0]\n",
    "    # neuron_state is an integer array for efficiency reasons. We should convert it to float\n",
    "    alpha = neuron_states[i].astype(np.float32)\n",
    "    for j in idx_unsure:\n",
    "        alpha[j] = UBs[i+1][j]/(UBs[i+1][j]-LBs[i+1][j])\n",
    "    alphas.append(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "m = grb.Model(\"LP\")\n",
    "m.setParam(\"outputflag\",0)\n",
    "# disable parallel Gurobi solver, using 1 thread only\n",
    "m.setParam(\"Method\",1) # dual simplex\n",
    "m.setParam(\"Threads\", 1) # only 1 thread\n",
    "# z and zh are list of lists, each list for one layer of variables\n",
    "# z starts from 1, matching Zico's notation\n",
    "z = []\n",
    "z.append(None)\n",
    "# z hat starts from 2\n",
    "zh = []\n",
    "zh.append(None)\n",
    "zh.append(None)\n",
    "\n",
    "if p == \"2\" or p == \"1\":\n",
    "    # ztrans (transformation of z1 only for lp norm), starts from 1 matching z\n",
    "    ztrans = []\n",
    "    ztrans.append(None)\n",
    "\n",
    "## LP codes: \n",
    "\n",
    "# we start our label from 1 to nlayer+1 (the last one is the final objective layer)\n",
    "# valid range for z: 1 to nlayer (z_1 is just input, z_{nlayer} is the last relu layer output)\n",
    "# valid range for z_hat: 2 to nlayer+1 (there is no z_hat_1 as it is the input, z_{nlayer+1} is final output)\n",
    "for i in range(1,nlayer+2):\n",
    "    if i == 1: # first layer\n",
    "        # first layer, only z exists, no z hat\n",
    "        zzs = []\n",
    "        zzts = []\n",
    "        # UBs[0] is for input x. Create a variable for each input\n",
    "        # and set its lower and upper bounds\n",
    "        for j in range(1,len(UBs[0])+1):\n",
    "            zij = m.addVar(vtype=grb.GRB.CONTINUOUS, lb=LBs[0][j-1], ub=UBs[0][j-1], name=\"z_\"+str(i)+\"_\"+str(j))\n",
    "            zzs.append(zij)\n",
    "            if p == \"2\" or p == \"1\":                \n",
    "                # transformation variable at z1 only\n",
    "                if p == \"2\":\n",
    "                    ztij = m.addVar(vtype=grb.GRB.CONTINUOUS, name=\"zt_\"+str(i)+\"_\"+str(j))\n",
    "                elif p == \"1\":\n",
    "                    ztij = m.addVar(vtype=grb.GRB.CONTINUOUS, lb=0, name=\"zt_\"+str(i)+\"_\"+str(j))\n",
    "                zzts.append(ztij)  \n",
    "        z.append(zzs)\n",
    "        if p == \"2\" or p == \"1\":\n",
    "            ztrans.append(zzts)\n",
    "    elif i< nlayer+1:\n",
    "        # middle layer, has both z and z hat\n",
    "        zzs = []\n",
    "        zzhs = []\n",
    "        for j in range(1,len(UBs[i-1])+1):\n",
    "            zij = m.addVar(vtype=grb.GRB.CONTINUOUS, name=\"z_\"+str(i)+\"_\"+str(j))\n",
    "            zzs.append(zij)\n",
    "\n",
    "            zhij = m.addVar(vtype=grb.GRB.CONTINUOUS,lb=-np.inf,name=\"zh_\"+str(i)+\"_\"+str(j))\n",
    "            zzhs.append(zhij)\n",
    "        z.append(zzs)\n",
    "        zh.append(zzhs)\n",
    "    else: # last layer, i == nlayer + 1\n",
    "        # only has z hat, length is the same as the output\n",
    "        # there is no relu, so no z\n",
    "        zzhs = []\n",
    "        for j in range(1,len(bs[-1])+1):\n",
    "            zhij = m.addVar(vtype=grb.GRB.CONTINUOUS,lb=-np.inf,name=\"zh_\"+str(i)+\"_\"+str(j))\n",
    "            zzhs.append(zhij)\n",
    "        zh.append(zzhs)\n",
    "\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[L2][LP solver initialized] time_lp_init = 2.4567\n",
      "[L2][upper bound solved] j = 0, time_lp_solve = 0.0686\n",
      "[L2][upper bound solved] j = 1, time_lp_solve = 0.0516\n",
      "[L2][upper bound solved] j = 2, time_lp_solve = 0.0254\n",
      "[L2][upper bound solved] j = 3, time_lp_solve = 0.0304\n",
      "[L2][upper bound solved] j = 4, time_lp_solve = 0.0297\n",
      "[L2][upper bound solved] j = 5, time_lp_solve = 0.0502\n",
      "[L2][upper bound solved] j = 6, time_lp_solve = 0.0465\n",
      "[L2][upper bound solved] j = 7, time_lp_solve = 0.0288\n",
      "[L2][upper bound solved] j = 8, time_lp_solve = 0.0296\n",
      "[L2][upper bound solved] j = 9, time_lp_solve = 0.0311\n",
      "[L2][lower bound solved] j = 0, time_lp_solve = 0.0337\n",
      "[L2][lower bound solved] j = 1, time_lp_solve = 0.0504\n",
      "[L2][lower bound solved] j = 2, time_lp_solve = 0.0325\n",
      "[L2][lower bound solved] j = 3, time_lp_solve = 0.0314\n",
      "[L2][lower bound solved] j = 4, time_lp_solve = 0.0268\n",
      "[L2][lower bound solved] j = 5, time_lp_solve = 0.0299\n",
      "[L2][lower bound solved] j = 6, time_lp_solve = 0.0272\n",
      "[L2][lower bound solved] j = 7, time_lp_solve = 0.0394\n",
      "[L2][lower bound solved] j = 8, time_lp_solve = 0.0384\n",
      "[L2][lower bound solved] j = 9, time_lp_solve = 0.0311\n"
     ]
    }
   ],
   "source": [
    "# Adding weights constraints for all layers\n",
    "for i in range(1,nlayer+1):\n",
    "    W = Ws[i-1] # weights of layer i\n",
    "    for j in range(W.shape[0]):\n",
    "        \"\"\"\n",
    "        sum_term = bs[i-1][j]\n",
    "        for s in range(W.shape[1]):\n",
    "            # z start from 1\n",
    "            sum_term += z[i][s]*W[j,s]\n",
    "        \"\"\"\n",
    "        sum_term = grb.LinExpr(W[j], z[i]) + bs[i-1][j]\n",
    "        # this is the output of layer i, and let z_hat_{i+1} equal to it\n",
    "        # z_hat_{nlayer+1} is the final output (logits)\n",
    "        m.addConstr(sum_term == zh[i+1][j], \"weights==_\"+str(i)+\"_\"+str(j))\n",
    "        # m.addConstr(sum_term <= zh[i+1][j], \"weights<=_\"+str(i)+\"_\"+str(j))\n",
    "        # m.addConstr(sum_term >= zh[i+1][j], \"weights>=_\"+str(i)+\"_\"+str(j))\n",
    "\n",
    "# nlayer network only has nlayer - 1 activations\n",
    "for i in range(1, nlayer):\n",
    "    # UBs[0] is the bounds for input x, so start from 1\n",
    "    for j in range(len(UBs[i])):\n",
    "        # neuron_states starts from 0\n",
    "        if neuron_states[i-1][j] == 1:\n",
    "            m.addConstr(z[i+1][j] == zh[i+1][j], \"LPposr==_\"+str(j))\n",
    "            # m.addConstr(z[i+1][j] <= zh[i+1][j], \"LPpos<=_\"+str(j))\n",
    "            # m.addConstr(z[i+1][j] >= zh[i+1][j], \"LPpos>=_\"+str(j))\n",
    "        elif neuron_states[i-1][j] == -1:\n",
    "            m.addConstr(z[i+1][j] == 0, \"LPneg==_\"+str(j))\n",
    "            # m.addConstr(z[i+1][j] <= 0, \"LPneg<=_\"+str(j))\n",
    "            # m.addConstr(z[i+1][j] >= 0, \"LPneg>=_\"+str(j))\n",
    "        elif neuron_states[i-1][j] == 0:\n",
    "            # m.addConstr(z[i+1][j] >= 0, \"LPunsure>=0_\"+str(j))\n",
    "            m.addConstr(z[i+1][j] >= zh[i+1][j], \"LPunsure>=_\"+str(j))\n",
    "            m.addConstr(z[i+1][j] <= np.asscalar(alphas[i-1][j])*(zh[i+1][j]-np.asscalar(LBs[i][j])), \"LPunsure<=_\"+str(j))\n",
    "        else:\n",
    "            raise(RuntimeError(\"unknown neuron_state: \"+neuron_states[i])) \n",
    "\n",
    "\n",
    "#    #finally, add constraints for z[1], the input -> For p == \"i\", this is already added in the input variable range zij\n",
    "#    for i in range(len(UBs[0])):\n",
    "#         m.addConstr(z[1][i] <= UBs[0][i], \"inputs+_\"+str(i))\n",
    "#         m.addConstr(z[1][i] >= LBs[0][i], \"inputs-_\"+str(i))         \n",
    "\n",
    "if p == \"2\": \n",
    "    #finally, add constraints for z[1] and ztrans[1], the input\n",
    "    for i in range(len(UBs[0])):\n",
    "        m.addConstr(ztrans[1][i] == z[1][i] - x0[i], \"INPUTtrans_\"+str(i))\n",
    "    # quadratic constraints\n",
    "    m.addConstr(grb.quicksum(ztrans[1][i]*ztrans[1][i] for i in range(len(UBs[0]))) <= eps*eps, \"INPUT L2 norm QCP\")\n",
    "elif p == \"1\":\n",
    "     #finally, add constraints for z[1] and ztrans[1], the input\n",
    "    temp = []\n",
    "    for i in range(len(UBs[0])):\n",
    "        tempi = m.addVar(vtype=grb.GRB.CONTINUOUS)\n",
    "        temp.append(tempi)\n",
    "\n",
    "    for i in range(len(UBs[0])):\n",
    "        # absolute constraints: seem that option1 and 2a, 2c are the right answer (compared to p = 2 result) \n",
    "        # option 1\n",
    "        #m.addConstr(ztrans[1][i] >= z[1][i] - x0[i], \"INPUTtransPOS_\"+str(i))\n",
    "        #m.addConstr(ztrans[1][i] >= -z[1][i] + x0[i], \"INPUTtransNEG_\"+str(i))\n",
    "\n",
    "        # option 2a: same answer as option 1\n",
    "        # note if we write , the result is different\n",
    "        #zzz = m.addVar(vtype=grb.GRB.CONTINUOUS)\n",
    "        #m.addConstr(zzz == z[1][i]-x0[i])\n",
    "        #m.addConstr(ztrans[1][i] == grb.abs_(zzz), \"INPUTtransABS_\"+str(i))\n",
    "\n",
    "        # option 2b: gives different sol as 2a and 2c, guess it's because abs_() has to take a variable,\n",
    "        # and that's why 2a and 2c use additional variable zzz or temp\n",
    "        # but now it gives Attribute error on \"gurobipy.LinExpr\", so can't use this anymore\n",
    "        #m.addConstr(ztrans[1][i] == grb.abs_(z[1][i]-x0[i]), \"INPUTtransABS_\"+str(i))\n",
    "\n",
    "        # option 2c: same answer as 2a\n",
    "        m.addConstr(temp[i] == z[1][i]-x0[i])\n",
    "        m.addConstr(ztrans[1][i] == grb.abs_(temp[i]), \"INPUTtransABS_\"+str(i))    \n",
    "\n",
    "        # option 3: same answer as 2b\n",
    "        #m.addConstr(ztrans[1][i] <= z[1][i] - x0[i], \"INPUTtransPOS_\"+str(i))\n",
    "        #m.addConstr(ztrans[1][i] >= -z[1][i] + x0[i], \"INPUTtransNEG_\"+str(i))\n",
    "\n",
    "\n",
    "    # L1 constraints\n",
    "    m.addConstr(grb.quicksum(ztrans[1][i] for i in range(len(UBs[0]))) <= eps, \"INPUT L1 norm\")\n",
    "\n",
    "\n",
    "\n",
    "# another way to write quadratic constraints\n",
    "###expr = grb.QuadExpr()\n",
    "###expr.addTerms(np.ones(len(UBs[0])), z[1], z[1])\n",
    "###m.addConstr(expr <= eps*eps)\n",
    "\n",
    "m.update()\n",
    "\n",
    "print(\"[L2][LP solver initialized] time_lp_init = {:.4f}\".format(time.time() - start))\n",
    "# for middle layers, need to compute full bounds\n",
    "\n",
    "# compute upper bounds        \n",
    "# z_hat_{nlayer+1} is the logits (final output, or inputs for layer nlayer+1)\n",
    "##for j in [pred_label,target_label]:\n",
    "for j in range(Ws[nlayer-1].shape[0]):\n",
    "    m.setObjective(zh[nlayer+1][j], grb.GRB.MAXIMIZE)    \n",
    "    # m.write('grbtest_LP_2layer_'+str(j)+'.lp')    \n",
    "    start = time.time()\n",
    "    m.optimize()\n",
    "    UB[j] = m.objVal\n",
    "    m.reset()\n",
    "    print(\"[L2][upper bound solved] j = {}, time_lp_solve = {:.4f}\".format(j, time.time() - start))\n",
    "\n",
    "# compute lower bounds        \n",
    "##for j in [pred_label,target_label]:\n",
    "for j in range(Ws[nlayer-1].shape[0]):\n",
    "    m.setObjective(zh[nlayer+1][j], grb.GRB.MINIMIZE)    \n",
    "    # m.write('grbtest_LP_2layer_'+str(j)+'.lp')    \n",
    "    start = time.time()\n",
    "    m.optimize()\n",
    "    LB[j] = m.objVal\n",
    "    m.reset()\n",
    "    print(\"[L2][lower bound solved] j = {}, time_lp_solve = {:.4f}\".format(j, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OUTPUT] Bounds: \n",
      "array([[ -4.44226023,   8.29007468],\n",
      "       [ -5.24450696,   7.21908945],\n",
      "       [ -0.67532606,   9.53610428],\n",
      "       [-11.6291616 ,   2.07611908],\n",
      "       [-11.01252342,   3.29074687],\n",
      "       [ -3.63239346,   4.96599179],\n",
      "       [ -2.87692735,  20.99791573],\n",
      "       [-10.05206823,   1.0749879 ],\n",
      "       [ -0.76651347,   5.35888263],\n",
      "       [ -9.72238622,   3.75802351]])\n"
     ]
    }
   ],
   "source": [
    "print(\"[OUTPUT] Bounds: \")\n",
    "pprint(np.stack([LB, UB], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OUTPUT] Bounds: \n",
      "array([[-9.57988089,  0.        ],\n",
      "       [-2.58615224,  0.        ],\n",
      "       [-6.4243636 ,  0.        ],\n",
      "       [-6.21697317,  0.        ],\n",
      "       [-7.70077449,  0.        ],\n",
      "       [-9.17041302,  0.        ],\n",
      "       [-6.83939782,  0.        ],\n",
      "       [-4.55706513,  0.        ],\n",
      "       [-5.44619597,  0.        ],\n",
      "       [-9.35782515,  0.        ]])\n"
     ]
    }
   ],
   "source": [
    "print(\"[OUTPUT] Bounds: \")\n",
    "pprint(np.concatenate([LB_list[3], UB_list[3]], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.]), array([[ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [-1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [-1.],\n",
      "       [ 1.],\n",
      "       [-1.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [-1.],\n",
      "       [ 1.],\n",
      "       [-1.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [-1.],\n",
      "       [ 1.],\n",
      "       [-1.],\n",
      "       [-1.],\n",
      "       [-1.],\n",
      "       [-1.],\n",
      "       [-1.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [-1.],\n",
      "       [ 1.],\n",
      "       [-1.],\n",
      "       [-1.],\n",
      "       [-1.],\n",
      "       [-1.],\n",
      "       [ 1.],\n",
      "       [-1.],\n",
      "       [-1.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [-1.],\n",
      "       [ 1.],\n",
      "       [-1.],\n",
      "       [-1.],\n",
      "       [ 1.],\n",
      "       [-1.],\n",
      "       [ 1.],\n",
      "       [-1.],\n",
      "       [ 0.],\n",
      "       [-1.]]), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [-1.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [-1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [-1.],\n",
      "       [-1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [-1.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.]]), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]), array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]])]\n"
     ]
    }
   ],
   "source": [
    "print(UB_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
